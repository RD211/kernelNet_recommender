{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdR9O_QD-ifC"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y1cbvefD-p0x"
      },
      "source": [
        "We just get the data from our source. In this case we used google colab to train our model so the path represents a path in our shared drive folder. When running it on your own make sure to set the right path here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apEyWIjD8Bkb",
        "outputId": "f95a3780-b649-41b3-f882-59a96d741823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "movies_df = pd.read_csv(\"drive/MyDrive/data_mining/netflix/data/movies.csv\", sep =';', error_bad_lines = False, names = [\"movie_id\", \"year\", \"name\"], header = None)\n",
        "users_df = pd.read_csv(\"drive/MyDrive/data_mining/netflix/data/users.csv\", sep =';', error_bad_lines = False, names = [\"user_id\", \"gender\", \"age\", \"work\"], header = None)\n",
        "ratings_df = pd.read_csv(\"drive/MyDrive/data_mining/netflix/data/ratings.csv\", sep =';', error_bad_lines = False, names = [\"user_id\", \"movie_id\", \"rating\"], header = None)\n",
        "output_df = pd.read_csv(\"drive/MyDrive/data_mining/netflix/data/predictions.csv\", sep =';', error_bad_lines = False, names = [\"user_id\", \"movie_id\"], header = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUSWJEjE-zks"
      },
      "source": [
        "We convert the data to numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "slObfwrk8Hle"
      },
      "outputs": [],
      "source": [
        "movies_data = movies_df.to_numpy()\n",
        "users_data = users_df.to_numpy()\n",
        "ratings_data = ratings_df.to_numpy()\n",
        "output_data = output_df.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yXBSTCn-2BT"
      },
      "source": [
        "We now create our train, valid and test matrices. We will use these to train and test our model.\n",
        "\n",
        "For the best submission we have used a very small validation set leaving as much data as possible for the training. This gave us a bad estimate of performance so a larger validation set is recommended for reliable results.\n",
        "\n",
        "Using the below ratio we can easily achieve an RMSE score of around 0.828\n",
        "Making the validation smaller we can achieve 0.825\n",
        "The scores are from the public leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UHz2Ge0l8RAt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Shuffling the data so we do not have the same validation set every time.\n",
        "np.random.shuffle(ratings_data)\n",
        "\n",
        "# The reviews we will use for training.\n",
        "train_reviews = ratings_data[:890190]\n",
        "# The reviews we will use for validation.\n",
        "valid_reviews = ratings_data[890190:908190]\n",
        "# The reviews we will use for test.\n",
        "test_reviews = ratings_data[908190:]\n",
        "\n",
        "# The 3 different reviews matrices\n",
        "train_matrix = np.zeros((3706,6040))\n",
        "valid_matrix = np.zeros((3706,6040))\n",
        "test_matrix = np.zeros((3706,6040))\n",
        "\n",
        "# We initialize each with only the corresponding reviews. Having a value of 0 on a entry would mean missing review.\n",
        "for user_id, movie_id, rating in train_reviews:\n",
        "  train_matrix[movie_id - 1, user_id - 1] = rating\n",
        "for user_id, movie_id, rating in valid_reviews:\n",
        "  valid_matrix[movie_id - 1, user_id - 1] = rating\n",
        "for user_id, movie_id, rating in test_reviews:\n",
        "  test_matrix[movie_id - 1, user_id - 1] = rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huobyBT0-8YT"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ-_j_KCAa5j"
      },
      "source": [
        "**Model Hyper Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2-iQNXjXAapM"
      },
      "outputs": [],
      "source": [
        "# The number of kernel dimensions we will use.\n",
        "kernel_dimensions = 5\n",
        "\n",
        "# Regularization parameters\n",
        "lambda_w = 84.\n",
        "lambda_w_kernelized = 0.0182\n",
        "\n",
        "# The architecture of the model.\n",
        "architecture = [\n",
        "    6040,\n",
        "    500,\n",
        "    500,\n",
        "    6040\n",
        "]\n",
        "\n",
        "# The activation functions that will be used.\n",
        "activations = [\n",
        "    tf.nn.sigmoid,\n",
        "    tf.nn.sigmoid,\n",
        "    tf.identity,\n",
        "]\n",
        "\n",
        "# Just to check we don't mess up the number of activations and the architecture\n",
        "assert len(activations) + 1 == len(architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72m3VPOjAlmI"
      },
      "source": [
        "We will use tensorflow to optimize our model. We we will make each trainable variable from our model as a tf.Variable. Below is the creation of said variables.\n",
        "\n",
        "\n",
        "\n",
        "*   **weights** - will represent the classic neural network weights of our model. Each will have size (node_in, node_out).\n",
        "*   **in_vectors** - will represent the vectors used for distance. Each entry in the list will represent the position of the input of the layer with index i. Of size (nodes_in, 1, kernel_dimensions).\n",
        "*   **out_vectors** - will represent the vectors used for distance. Each entry in the list will represent the position of the output of the layer with index i. Of size (1, nodes_out, kernel_dimensions).\n",
        "*   **biases** - will represent simple neural network biases that will be applied for each neuron.\n",
        "\n",
        "Note: It's important to initialize the in and out vectors to small values as large values will produce a gradient that is hard to escape from using our optimization function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rARi-NRuO5Ir"
      },
      "outputs": [],
      "source": [
        "# Creates the weight variables\n",
        "weights = []\n",
        "for i in range(len(architecture) - 1):\n",
        "  # We take the amount of nodes in and out\n",
        "  nodes_in = architecture[i]\n",
        "  nodes_out = architecture[i + 1]\n",
        "  # The normal\n",
        "  W = tf.Variable(np.zeros((nodes_in, nodes_out)))\n",
        "  weights.append(W)\n",
        "\n",
        "# Creates the node vector positions\n",
        "in_vectors = []\n",
        "out_vectors = []\n",
        "for i in range(len(architecture) - 1):\n",
        "  # We take the amount of nodes in and out\n",
        "  nodes_in = architecture[i]\n",
        "  nodes_out = architecture[i + 1]\n",
        "  # We create the in and out vectors for this layer.\n",
        "  # These vectors represent the position in the space.\n",
        "  in_vector = tf.Variable(np.random.uniform(0,1e-3, size = (nodes_in, 1, kernel_dimensions)))\n",
        "  out_vector = tf.Variable(np.random.uniform(0,1e-3, size = (1, nodes_out, kernel_dimensions)))\n",
        "  in_vectors.append(in_vector)\n",
        "  out_vectors.append(out_vector)\n",
        "\n",
        "# Creates the biases\n",
        "biases = []\n",
        "for i in range(len(architecture) - 1):\n",
        "  # We take the amount of nodes out.\n",
        "  nodes_out = architecture[i + 1]\n",
        "  # The biases are initialized to 0 by default.\n",
        "  b = tf.Variable(np.zeros((nodes_out)))\n",
        "  biases.append(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh2Ou8mvCDP0"
      },
      "source": [
        "# Loss function and helper methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D4DqL4B_CCjg"
      },
      "outputs": [],
      "source": [
        "# The kernel method we will use.\n",
        "# Small values mean less importance and larger values mean more importance.\n",
        "def kernel(u, v):\n",
        "    distance = tf.norm(u - v, ord=2, axis=2)\n",
        "\n",
        "    # We cast here because our u,v will be float64.\n",
        "    importance = tf.maximum(tf.cast(0., tf.float64), 1. - distance**2)\n",
        "    return importance\n",
        "\n",
        "# The layer function. Takes the input from the previous layer and the index of the current layer.\n",
        "def layer(x, index):\n",
        "\n",
        "  # Getting the variables for this specific layer.\n",
        "  W = weights[index]\n",
        "  in_vector = in_vectors[index]\n",
        "  out_vector = out_vectors[index]\n",
        "  bias = biases[index]\n",
        "  activation = activations[index]\n",
        "\n",
        "  # We perform the kernel function on the vectors\n",
        "  w_kernelized = kernel(in_vector, out_vector)\n",
        "\n",
        "  # We compute the regularizations for the w_kernelized and for W.\n",
        "  # We compute the regularization for w_kernelized s. t. the model is pushed towards choosing a small number of really close neurons.\n",
        "  # We compute the regularization for W as we would in normal neural networks.\n",
        "  reg_w_kernelized = tf.keras.regularizers.L2(lambda_w_kernelized)([w_kernelized])\n",
        "  reg_w = tf.keras.regularizers.L2(lambda_w)([W])\n",
        "\n",
        "  # We now use the importance to scale our weights\n",
        "  W_final = W * w_kernelized\n",
        "\n",
        "  # We now just compute the outputs as we would normally.\n",
        "  M = x @ W_final + bias\n",
        "  M = activation(M)\n",
        "\n",
        "  # Returns both the outputs and the regularization values summed.\n",
        "  return M, reg_w_kernelized + reg_w\n",
        "\n",
        "\n",
        "# This function predicts the output using the model given an input matrix\n",
        "def predict(matrix):\n",
        "  for i in range(len(architecture) - 1):\n",
        "    matrix, _ = layer(matrix, i)\n",
        "  return matrix\n",
        "\n",
        "# This function predicts the output using the model given an input matrix\n",
        "# But also gives the regularization loss.\n",
        "def predict_with_loss(matrix):\n",
        "  loss_sum = 0\n",
        "  for i in range(len(architecture) - 1):\n",
        "    matrix, loss = layer(matrix, i)\n",
        "    loss_sum += loss\n",
        "  return matrix, loss_sum\n",
        "\n",
        "# This function calculates the loss in a general way.\n",
        "# It has the input and output matrixes configurable.\n",
        "def calc_loss(in_matrix = train_matrix, out_matrix = train_matrix):\n",
        "  matrix, reg_loss = predict_with_loss(in_matrix)\n",
        "  dist = (out_matrix > 0) * (matrix - out_matrix)\n",
        "  loss = tf.sqrt(tf.reduce_sum(tf.pow(dist, 2)) / tf.reduce_sum((out_matrix > 0) * 1.0))\n",
        "  return loss\n",
        "\n",
        "# This is the actual loss function that will be used in the training procedure.\n",
        "def loss_train():\n",
        "  loss_sum = 0\n",
        "  matrix = train_matrix\n",
        "  for i in range(len(architecture) - 1):\n",
        "    matrix, loss = layer(matrix, i)\n",
        "    loss_sum += loss\n",
        "  dist = (train_matrix > 0.1) * (matrix - train_matrix)\n",
        "  loss_sum += tf.reduce_sum(tf.pow(dist, 2))\n",
        "  return loss_sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNcBjKhDCMCE"
      },
      "source": [
        "This code is just to be able to save our model with every parameter and load it again later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hd_N0US8eZ2R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def save_model(name):\n",
        "  os.makedirs('drive/MyDrive/data_mining/netflix/saved/' + name, exist_ok=True)\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/weights', 'wb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      np.save(f, weights[i].numpy())\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/in_vectors', 'wb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      np.save(f, in_vectors[i].numpy())\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/out_vectors', 'wb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      np.save(f, out_vectors[i].numpy())\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/biases', 'wb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      np.save(f, biases[i].numpy())\n",
        "def load_model(name):\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/weights', 'rb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      weights[i] = tf.Variable(np.load(f))\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/in_vectors', 'rb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      in_vectors[i] = tf.Variable(np.load(f))\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/out_vectors', 'rb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      out_vectors[i] = tf.Variable(np.load(f))\n",
        "  with open('drive/MyDrive/data_mining/netflix/saved/' + name + '/biases', 'rb') as f:\n",
        "    for i in range(len(architecture)-1):\n",
        "      biases[i] = tf.Variable(np.load(f))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcjWLd2ZDdGw"
      },
      "source": [
        "# Our Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnAIWnmnEDlj"
      },
      "source": [
        "As our optimizer we decided to go with **BFGS**. We opted for this algorithm as a lot of papers in the space use it and the creator of the paper this algorithm is based on also suggested it.\n",
        "\n",
        "**BFGS** is an optimization algorithm that employs the use of second order derivatives. It uses a **Hessian Matrix** to calculate the next step in the optimization. **BFGS** uses line search to ensure the stability of the optimization. **Line search** requires a higher precission so we will use **float64** throughout our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBxfuBvZDXRY"
      },
      "source": [
        "## L-BFGS adapter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khg27u0tDFah"
      },
      "source": [
        "This is some code we found on github to help us use the L-BFGS optimizer in tensorflow 2.0 with trainable variables. It packs and unpacks our parameters accordingly to satisfy the parameters of the optimizer function.\n",
        "\n",
        "It uses the L-BFGS optimizer found in the tensorflow probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iuWM0Db7C4Ay"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence, Union, List\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def pack_tensors(tensors: Sequence[Union[tf.Tensor, tf.Variable]]) -> tf.Tensor:\n",
        "    flats = [tf.reshape(tensor, (-1,)) for tensor in tensors]\n",
        "    tensors_vector = tf.concat(flats, axis=0)\n",
        "    return tensors_vector\n",
        "\n",
        "\n",
        "def unpack_tensors(\n",
        "    to_tensors: Sequence[Union[tf.Tensor, tf.Variable]], from_vector: tf.Tensor\n",
        ") -> List[tf.Tensor]:\n",
        "    s = 0\n",
        "    values = []\n",
        "    for target_tensor in to_tensors:\n",
        "        shape = tf.shape(target_tensor)\n",
        "        dtype = target_tensor.dtype\n",
        "        tensor_size = tf.reduce_prod(shape)\n",
        "        tensor_vector = from_vector[s : s + tensor_size]\n",
        "        tensor = tf.reshape(tf.cast(tensor_vector, tf.float64), shape)\n",
        "        values.append(tensor)\n",
        "        s += tensor_size\n",
        "    return values\n",
        "\n",
        "\n",
        "def assign_tensors(to_tensors: Sequence[tf.Variable], values: Sequence[tf.Tensor]) -> None:\n",
        "    if len(to_tensors) != len(values):\n",
        "        raise ValueError(\"to_tensors and values should have same length\")\n",
        "    for target, value in zip(to_tensors, values):\n",
        "        target.assign(value)\n",
        "\n",
        "\n",
        "def create_value_and_gradient_function(loss_closure, trainable_variables, verbose=1):\n",
        "    \"\"\"A factory to create a function required by tfp.optimizer.lbfgs_minimize.\n",
        "    Args:\n",
        "        loss_closure:\n",
        "        trainable_variables:\n",
        "    Returns:\n",
        "        A function that has a signature of:\n",
        "            loss_value, gradients = f(model_parameters).\n",
        "    \"\"\"\n",
        "    i = tf.Variable(0)\n",
        "\n",
        "    def assign_param_values_to_variables(x):\n",
        "        values = unpack_tensors(trainable_variables, x)\n",
        "        assign_tensors(trainable_variables, values)\n",
        "\n",
        "    @tf.function\n",
        "    def f_value_and_gradients(x):\n",
        "        \"\"\"A function that can be used by tfp.optimizer.lbfgs_minimize\"\"\"\n",
        "        # update params\n",
        "        assign_param_values_to_variables(x)\n",
        "        # compute loss value and gradients w.r.t. trainable variables\n",
        "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "            tape.watch(trainable_variables)\n",
        "            loss_value = loss_closure()\n",
        "        grads = tape.gradient(loss_value, trainable_variables)\n",
        "\n",
        "        i.assign_add(1)\n",
        "        if verbose > 0:\n",
        "            tf.print(\"Iter:\", i, \"loss:\", loss_value)\n",
        "\n",
        "        # return loss and flattened gradients\n",
        "        return loss_value, pack_tensors(grads)\n",
        "\n",
        "    return f_value_and_gradients, assign_param_values_to_variables\n",
        "\n",
        "class LBFGSOptimizer():\n",
        "\n",
        "    def __init__(self, loss_closure, trainable_variables, steps=50):\n",
        "        tf.keras.backend.set_floatx(\"float64\")\n",
        "        self.initial_position = pack_tensors(trainable_variables)\n",
        "        self.results = None\n",
        "        func, assign = create_value_and_gradient_function(\n",
        "            loss_closure=loss_closure,\n",
        "            trainable_variables=trainable_variables\n",
        "        )\n",
        "        self.func = func\n",
        "        self.assign = assign\n",
        "        self.steps = steps\n",
        "\n",
        "    @property\n",
        "    def epoch(self):\n",
        "        if self.results is None:\n",
        "            return 0\n",
        "        return int(self.results.num_iterations.numpy())\n",
        "    \n",
        "    @property\n",
        "    def loss(self):\n",
        "        if self.results is None:\n",
        "            return None\n",
        "        return float(self.results.objective_value.numpy())\n",
        "\n",
        "    def minimize(self):\n",
        "        if self.results is None:\n",
        "            initial_position = self.initial_position\n",
        "        else:\n",
        "            initial_position = None\n",
        "        self.results = tfp.optimizer.lbfgs_minimize(\n",
        "            value_and_gradients_function=self.func,\n",
        "            initial_position=initial_position,\n",
        "            previous_optimizer_results=self.results,\n",
        "            max_iterations=tf.cast(self.epoch + self.steps, dtype=tf.int32)\n",
        "        )\n",
        "        print(self.results.position)\n",
        "        self.assign(self.results.position)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkrMS9yFc08"
      },
      "source": [
        "# Training the algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTr5MTqCFhOV"
      },
      "source": [
        "Having defined all the necessary steps before, the training of the algorithm is very easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XM0niUp3R-sG",
        "outputId": "fcc179ff-ae0b-4c24-b4c2-af46fd5abc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jan 13 15:14:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    51W / 400W |    760MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Iter: 1 loss: 12642412.808868932\n",
            "Iter: 2 loss: 1.1475862152553314e+17\n",
            "Iter: 3 loss: 7234005.2103277594\n",
            "Iter: 4 loss: 8327556.1549703777\n",
            "Iter: 5 loss: 6412492.9884729991\n",
            "Iter: 6 loss: 4665884.3640901037\n",
            "Iter: 7 loss: 4266940.21372668\n",
            "Iter: 8 loss: 7298762.20215776\n",
            "Iter: 9 loss: 3936601.4093996854\n",
            "Iter: 10 loss: 3536911.4830532093\n",
            "Iter: 11 loss: 3466378.9503572029\n",
            "Iter: 12 loss: 3190986.8745297613\n",
            "Iter: 13 loss: 2457965.27621629\n",
            "Iter: 14 loss: 4417405.6884656847\n",
            "Iter: 15 loss: 2203134.7475691456\n",
            "tf.Tensor(\n",
            "[-0.00233416 -0.00233416 -0.00233416 ...  0.00517113  0.0237971\n",
            "  0.03778346], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 1.5167788514583216\n",
            "Validation loss: 1.5439836335356827\n",
            "Iter: 16 loss: 1848179.6949835052\n",
            "Iter: 17 loss: 1783968.4361488046\n",
            "Iter: 18 loss: 1557950.7650776503\n",
            "Iter: 19 loss: 3605196.7557089729\n",
            "Iter: 20 loss: 1545967.6256855438\n",
            "Iter: 21 loss: 1424885.3623410317\n",
            "Iter: 22 loss: 1653120.354169216\n",
            "Iter: 23 loss: 1372301.3430756489\n",
            "Iter: 24 loss: 1281811.2989331654\n",
            "Iter: 25 loss: 2010172.6473551269\n",
            "Iter: 26 loss: 1274898.2743105928\n",
            "Iter: 27 loss: 1217958.6738466818\n",
            "Iter: 28 loss: 1747296.1540603903\n",
            "Iter: 29 loss: 1214919.2321283922\n",
            "tf.Tensor(\n",
            "[-0.00229909 -0.00229909 -0.00229909 ...  0.01621785  0.03528284\n",
            "  0.03443253], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 1.0824772112714762\n",
            "Validation loss: 1.0988581926906615\n",
            "Iter: 30 loss: 1177317.6813826652\n",
            "Iter: 31 loss: 1327130.3466624706\n",
            "Iter: 32 loss: 1168286.7955463743\n",
            "Iter: 33 loss: 1142676.3399062327\n",
            "Iter: 34 loss: 1242140.5984186074\n",
            "Iter: 35 loss: 1136298.8463839879\n",
            "Iter: 36 loss: 1119052.5178834472\n",
            "Iter: 37 loss: 1231803.6560432217\n",
            "Iter: 38 loss: 1117032.8007555921\n",
            "Iter: 39 loss: 1106163.9117529688\n",
            "Iter: 40 loss: 1168763.5608677459\n",
            "Iter: 41 loss: 1104614.574721311\n",
            "Iter: 42 loss: 1097779.0745638211\n",
            "Iter: 43 loss: 1131505.6584561642\n",
            "Iter: 44 loss: 1096568.3113352137\n",
            "tf.Tensor(\n",
            "[-0.00217343 -0.00217343 -0.00217343 ...  0.02414519  0.03156342\n",
            "  0.03730571], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 1.0183109221870608\n",
            "Validation loss: 1.034614827533966\n",
            "Iter: 45 loss: 1091820.9819931933\n",
            "Iter: 46 loss: 1116748.9117759371\n",
            "Iter: 47 loss: 1091064.3764708543\n",
            "Iter: 48 loss: 1087458.1485663066\n",
            "Iter: 49 loss: 1098883.9825065478\n",
            "Iter: 50 loss: 1086414.7247292022\n",
            "Iter: 51 loss: 1083041.1544564075\n",
            "Iter: 52 loss: 1091796.2266034358\n",
            "Iter: 53 loss: 1081896.8803906152\n",
            "Iter: 54 loss: 1078225.6773795544\n",
            "Iter: 55 loss: 1086433.6957596263\n",
            "Iter: 56 loss: 1076830.1605799338\n",
            "Iter: 57 loss: 1072519.6428512854\n",
            "Iter: 58 loss: 1077865.1862371338\n",
            "Iter: 59 loss: 1070157.4454942169\n",
            "tf.Tensor(\n",
            "[-0.00207436 -0.00207436 -0.00207436 ...  0.0315535   0.03440584\n",
            "  0.04087213], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 1.0036661303532313\n",
            "Validation loss: 1.0167648400653264\n",
            "Iter: 60 loss: 1063962.6247443724\n",
            "Iter: 61 loss: 1090374.8591999754\n",
            "Iter: 62 loss: 1061960.375114599\n",
            "Iter: 63 loss: 1053752.0612868136\n",
            "Iter: 64 loss: 1685789.6708724883\n",
            "Iter: 65 loss: 1053742.225074766\n",
            "Iter: 66 loss: 1041597.9787772384\n",
            "Iter: 67 loss: 1176529.9948636545\n",
            "Iter: 68 loss: 1041061.4976737122\n",
            "Iter: 69 loss: 1025013.9807958645\n",
            "Iter: 70 loss: 1124373.0706441647\n",
            "Iter: 71 loss: 1022763.9655687544\n",
            "Iter: 72 loss: 1101831.5723706118\n",
            "Iter: 73 loss: 1015694.7568113287\n",
            "tf.Tensor(\n",
            "[-0.00184492 -0.00184493 -0.00184493 ...  0.03843449  0.03330145\n",
            "  0.04537526], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9715417963811994\n",
            "Validation loss: 0.9852474780562074\n",
            "Iter: 74 loss: 1003107.877793674\n",
            "Iter: 75 loss: 1002723.5896466923\n",
            "Iter: 76 loss: 994735.9636174253\n",
            "Iter: 77 loss: 1112258.5284869513\n",
            "Iter: 78 loss: 994735.65136139817\n",
            "Iter: 79 loss: 987957.52030857513\n",
            "Iter: 80 loss: 1029733.0808987386\n",
            "Iter: 81 loss: 987194.98348451708\n",
            "Iter: 82 loss: 983840.42089697032\n",
            "Iter: 83 loss: 1013247.3712535166\n",
            "Iter: 84 loss: 983660.18857894954\n",
            "Iter: 85 loss: 981217.93579529272\n",
            "Iter: 86 loss: 989310.69467799121\n",
            "Iter: 87 loss: 980738.91099283483\n",
            "tf.Tensor(\n",
            "[-0.00171316 -0.00171317 -0.00171317 ...  0.03388965  0.03521074\n",
            "  0.04358529], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9521877967589801\n",
            "Validation loss: 0.9631805094782054\n",
            "Iter: 88 loss: 978130.073573298\n",
            "Iter: 89 loss: 995537.15645501856\n",
            "Iter: 90 loss: 977939.85515068623\n",
            "Iter: 91 loss: 975099.99311896041\n",
            "Iter: 92 loss: 1007322.787775555\n",
            "Iter: 93 loss: 975056.9902233741\n",
            "Iter: 94 loss: 972985.4734819429\n",
            "Iter: 95 loss: 976741.48009103525\n",
            "Iter: 96 loss: 972013.10297634313\n",
            "Iter: 97 loss: 969931.31962923845\n",
            "Iter: 98 loss: 978500.17551207426\n",
            "Iter: 99 loss: 969465.09983663843\n",
            "Iter: 100 loss: 967141.92373659741\n",
            "Iter: 101 loss: 975486.27773093735\n",
            "Iter: 102 loss: 966434.26239980024\n",
            "tf.Tensor(\n",
            "[-0.00147298 -0.00147306 -0.00147306 ...  0.03131093  0.03611085\n",
            "  0.04150421], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9452277240430761\n",
            "Validation loss: 0.9560209292687185\n",
            "Iter: 103 loss: 963767.18251872412\n",
            "Iter: 104 loss: 976860.01050991029\n",
            "Iter: 105 loss: 963301.25607730378\n",
            "Iter: 106 loss: 960626.384912552\n",
            "Iter: 107 loss: 972175.81982220488\n",
            "Iter: 108 loss: 959968.5087101002\n",
            "Iter: 109 loss: 956789.35449663829\n",
            "Iter: 110 loss: 997940.3058156959\n",
            "Iter: 111 loss: 956753.73356931587\n",
            "Iter: 112 loss: 954024.91347241192\n",
            "Iter: 113 loss: 971772.98839087156\n",
            "Iter: 114 loss: 953719.14993921644\n",
            "Iter: 115 loss: 951610.95095888991\n",
            "Iter: 116 loss: 961176.45850285678\n",
            "Iter: 117 loss: 951191.45245864661\n",
            "tf.Tensor(\n",
            "[-0.00114528 -0.0011467  -0.00114681 ...  0.03366793  0.03670512\n",
            "  0.03763194], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9354755800682386\n",
            "Validation loss: 0.945975751554458\n",
            "Iter: 118 loss: 949746.78524158942\n",
            "Iter: 119 loss: 982036.43997615227\n",
            "Iter: 120 loss: 949745.06949486281\n",
            "Iter: 121 loss: 947997.11309076089\n",
            "Iter: 122 loss: 960281.85839626135\n",
            "Iter: 123 loss: 947836.66984796117\n",
            "Iter: 124 loss: 945585.96692938614\n",
            "Iter: 125 loss: 962300.4718613897\n",
            "Iter: 126 loss: 945217.80385510519\n",
            "Iter: 127 loss: 941824.93733171839\n",
            "Iter: 128 loss: 975726.42906518606\n",
            "Iter: 129 loss: 941206.42419643\n",
            "Iter: 130 loss: 940170.4553468246\n",
            "Iter: 131 loss: 938274.26236068166\n",
            "tf.Tensor(\n",
            "[-0.00067301 -0.00073126 -0.00073423 ...  0.03639622  0.03871334\n",
            "  0.03259366], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9271084331963382\n",
            "Validation loss: 0.9386997014453392\n",
            "Iter: 132 loss: 934718.23815102666\n",
            "Iter: 133 loss: 934596.625780183\n",
            "Iter: 134 loss: 932193.29811844777\n",
            "Iter: 135 loss: 971349.03240470425\n",
            "Iter: 136 loss: 932189.02935412782\n",
            "Iter: 137 loss: 930767.82193569967\n",
            "Iter: 138 loss: 930764.4318162367\n",
            "Iter: 139 loss: 928855.76250094024\n",
            "Iter: 140 loss: 938987.46897564351\n",
            "Iter: 141 loss: 928517.12882543844\n",
            "Iter: 142 loss: 926452.76147579891\n",
            "Iter: 143 loss: 941142.239471082\n",
            "Iter: 144 loss: 926279.65478290361\n",
            "tf.Tensor(\n",
            "[-0.0003079  -0.00064616 -0.00065536 ...  0.03714052  0.03855866\n",
            "  0.0320329 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.919073319344441\n",
            "Validation loss: 0.9307781555598639\n",
            "Iter: 145 loss: 924797.98267105245\n",
            "Iter: 146 loss: 930072.91984175984\n",
            "Iter: 147 loss: 924441.59094248759\n",
            "Iter: 148 loss: 923463.29248630768\n",
            "Iter: 149 loss: 926525.18256767048\n",
            "Iter: 150 loss: 923162.32715894689\n",
            "Iter: 151 loss: 922548.04064792744\n",
            "Iter: 152 loss: 922090.28211667738\n",
            "Iter: 153 loss: 921888.099597571\n",
            "Iter: 154 loss: 920858.27257655351\n",
            "Iter: 155 loss: 923638.654829565\n",
            "Iter: 156 loss: 920521.89815161587\n",
            "Iter: 157 loss: 919567.24099089764\n",
            "Iter: 158 loss: 921076.99433994351\n",
            "Iter: 159 loss: 919119.35288109933\n",
            "tf.Tensor(\n",
            "[-0.00087279 -0.00048963 -0.00050593 ...  0.0385071   0.04053636\n",
            "  0.02833743], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9134610777465413\n",
            "Validation loss: 0.9240665372228859\n",
            "Iter: 160 loss: 918200.2490128557\n",
            "Iter: 161 loss: 922095.44782791473\n",
            "Iter: 162 loss: 918007.91201782611\n",
            "Iter: 163 loss: 917277.75770025945\n",
            "Iter: 164 loss: 923261.34293615073\n",
            "Iter: 165 loss: 917236.40137256042\n",
            "Iter: 166 loss: 916739.52274169913\n",
            "Iter: 167 loss: 918050.89678954938\n",
            "Iter: 168 loss: 916572.15337410837\n",
            "Iter: 169 loss: 916156.76337974879\n",
            "Iter: 170 loss: 916395.51021674077\n",
            "Iter: 171 loss: 915889.61077484733\n",
            "Iter: 172 loss: 915429.01009775221\n",
            "Iter: 173 loss: 915200.36502380972\n",
            "Iter: 174 loss: 914987.4272160955\n",
            "tf.Tensor(\n",
            "[-0.00164446 -0.00038041 -0.00040446 ...  0.03972709  0.04159128\n",
            "  0.02221111], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.910777936681705\n",
            "Validation loss: 0.9214212540090067\n",
            "Iter: 175 loss: 914265.23443402094\n",
            "Iter: 176 loss: 917006.41088023281\n",
            "Iter: 177 loss: 914091.87228957226\n",
            "Iter: 178 loss: 913553.96071155486\n",
            "Iter: 179 loss: 921894.07156577427\n",
            "Iter: 180 loss: 913553.79386034713\n",
            "Iter: 181 loss: 913132.80138364667\n",
            "Iter: 182 loss: 915988.95606769668\n",
            "Iter: 183 loss: 913091.06335971237\n",
            "Iter: 184 loss: 912654.0572255539\n",
            "Iter: 185 loss: 912303.87490577181\n",
            "Iter: 186 loss: 912174.18259462889\n",
            "Iter: 187 loss: 911541.67367011879\n",
            "Iter: 188 loss: 911976.51284252969\n",
            "Iter: 189 loss: 911146.0048397663\n",
            "tf.Tensor(\n",
            "[-0.00218599 -0.00014439 -0.00018404 ...  0.04246895  0.04415789\n",
            "  0.01070635], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9089093885410907\n",
            "Validation loss: 0.9207400728060323\n",
            "Iter: 190 loss: 910353.87138265884\n",
            "Iter: 191 loss: 913334.30256937072\n",
            "Iter: 192 loss: 910152.82230560319\n",
            "Iter: 193 loss: 909396.6672266575\n",
            "Iter: 194 loss: 911225.67222360813\n",
            "Iter: 195 loss: 909117.71864805708\n",
            "Iter: 196 loss: 908292.13467070507\n",
            "Iter: 197 loss: 909890.73207283567\n",
            "Iter: 198 loss: 907937.29490320687\n",
            "Iter: 199 loss: 907065.88632139657\n",
            "Iter: 200 loss: 913328.84026924218\n",
            "Iter: 201 loss: 906983.66062212375\n",
            "Iter: 202 loss: 906198.07535705075\n",
            "Iter: 203 loss: 911282.24000286055\n",
            "Iter: 204 loss: 906095.01161977206\n",
            "tf.Tensor(\n",
            "[-0.00290472  0.00028386  0.00021339 ...  0.04827046  0.04917418\n",
            " -0.01184975], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9073981904723957\n",
            "Validation loss: 0.9195389102098145\n",
            "Iter: 205 loss: 905281.905836887\n",
            "Iter: 206 loss: 907595.69811813475\n",
            "Iter: 207 loss: 905019.95669575047\n",
            "Iter: 208 loss: 904094.98976149445\n",
            "Iter: 209 loss: 906183.30613514071\n",
            "Iter: 210 loss: 903712.146420465\n",
            "Iter: 211 loss: 902855.731242077\n",
            "Iter: 212 loss: 908668.88615755772\n",
            "Iter: 213 loss: 902765.67783360078\n",
            "Iter: 214 loss: 902053.5253304221\n",
            "Iter: 215 loss: 908100.82086347928\n",
            "Iter: 216 loss: 901990.67323146458\n",
            "Iter: 217 loss: 901175.55101049063\n",
            "Iter: 218 loss: 905667.24883347168\n",
            "Iter: 219 loss: 901057.23208491609\n",
            "tf.Tensor(\n",
            "[-0.0033278   0.00067153  0.0005771  ...  0.05383487  0.05293794\n",
            " -0.03375135], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.9056176571454171\n",
            "Validation loss: 0.9184816277649132\n",
            "Iter: 220 loss: 900033.80761838192\n",
            "Iter: 221 loss: 901186.56770987576\n",
            "Iter: 222 loss: 899369.25899659307\n",
            "Iter: 223 loss: 897514.768924529\n",
            "Iter: 224 loss: 904812.17567241262\n",
            "Iter: 225 loss: 897028.62064123643\n",
            "Iter: 226 loss: 894533.19747209712\n",
            "Iter: 227 loss: 926509.74619824614\n",
            "Iter: 228 loss: 894359.75574236829\n",
            "Iter: 229 loss: 891154.05243833235\n",
            "Iter: 230 loss: 920197.77591933857\n",
            "Iter: 231 loss: 891035.82908898243\n",
            "Iter: 232 loss: 888789.093613582\n",
            "Iter: 233 loss: 921334.80678525288\n",
            "Iter: 234 loss: 888725.68882044719\n",
            "tf.Tensor(\n",
            "[-0.00334306  0.00105168  0.00093355 ...  0.06008933  0.05867495\n",
            " -0.06084938], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8990954029905999\n",
            "Validation loss: 0.9121781744157067\n",
            "Iter: 235 loss: 886544.09858102829\n",
            "Iter: 236 loss: 902931.22595730657\n",
            "Iter: 237 loss: 886434.34593691223\n",
            "Iter: 238 loss: 885284.08301982877\n",
            "Iter: 239 loss: 884805.09537414915\n",
            "Iter: 240 loss: 883404.92629010964\n",
            "Iter: 241 loss: 886748.82838023012\n",
            "Iter: 242 loss: 882890.164393937\n",
            "Iter: 243 loss: 881346.31176435028\n",
            "Iter: 244 loss: 887208.53423396684\n",
            "Iter: 245 loss: 880978.71140776318\n",
            "Iter: 246 loss: 879554.70668187737\n",
            "Iter: 247 loss: 886424.636340416\n",
            "Iter: 248 loss: 879272.53998180851\n",
            "tf.Tensor(\n",
            "[-0.00303257  0.00087635  0.00076338 ...  0.05901897  0.05756989\n",
            " -0.05907061], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8928776856369253\n",
            "Validation loss: 0.9064923981695969\n",
            "Iter: 249 loss: 878062.46697122254\n",
            "Iter: 250 loss: 886646.68508687068\n",
            "Iter: 251 loss: 877950.12300133752\n",
            "Iter: 252 loss: 876834.02822972019\n",
            "Iter: 253 loss: 878075.2506735496\n",
            "Iter: 254 loss: 876237.42584184126\n",
            "Iter: 255 loss: 875091.73209942656\n",
            "Iter: 256 loss: 881266.818021781\n",
            "Iter: 257 loss: 874901.18085633533\n",
            "Iter: 258 loss: 873781.28299498884\n",
            "Iter: 259 loss: 877917.53426508047\n",
            "Iter: 260 loss: 873496.19372037135\n",
            "Iter: 261 loss: 872555.481372547\n",
            "Iter: 262 loss: 874098.59415729425\n",
            "Iter: 263 loss: 872118.03576326871\n",
            "tf.Tensor(\n",
            "[-0.00302722  0.00085078  0.00073988 ...  0.06109632  0.05972952\n",
            " -0.0667759 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8883776263859398\n",
            "Validation loss: 0.9017957262154482\n",
            "Iter: 264 loss: 871096.23540078953\n",
            "Iter: 265 loss: 878499.32096446562\n",
            "Iter: 266 loss: 870994.01245328551\n",
            "Iter: 267 loss: 870126.8136493084\n",
            "Iter: 268 loss: 871163.10942449979\n",
            "Iter: 269 loss: 869654.17362813617\n",
            "Iter: 270 loss: 868488.70449945715\n",
            "Iter: 271 loss: 873293.90783678915\n",
            "Iter: 272 loss: 868214.07262405357\n",
            "Iter: 273 loss: 867104.3593310531\n",
            "Iter: 274 loss: 874122.33909942873\n",
            "Iter: 275 loss: 866962.05578242824\n",
            "Iter: 276 loss: 865958.38429142372\n",
            "Iter: 277 loss: 870166.2258104576\n",
            "Iter: 278 loss: 865739.25695422292\n",
            "tf.Tensor(\n",
            "[-0.00292798  0.00087445  0.00077346 ...  0.06506503  0.06253273\n",
            " -0.07894307], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8848411769688094\n",
            "Validation loss: 0.8984571200031378\n",
            "Iter: 279 loss: 864759.40653893375\n",
            "Iter: 280 loss: 869147.61408913881\n",
            "Iter: 281 loss: 864549.63623592176\n",
            "Iter: 282 loss: 863738.66035762709\n",
            "Iter: 283 loss: 867317.528297287\n",
            "Iter: 284 loss: 863569.22348240274\n",
            "Iter: 285 loss: 862774.11456105\n",
            "Iter: 286 loss: 864724.2952259396\n",
            "Iter: 287 loss: 862480.93711615773\n",
            "Iter: 288 loss: 861623.25531829242\n",
            "Iter: 289 loss: 863773.83604453958\n",
            "Iter: 290 loss: 861313.60171260813\n",
            "Iter: 291 loss: 860414.63143010344\n",
            "Iter: 292 loss: 863079.20465568022\n",
            "Iter: 293 loss: 860128.42564893188\n",
            "tf.Tensor(\n",
            "[-0.00268922  0.00089434  0.00081528 ...  0.06828552  0.06480523\n",
            " -0.08633021], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8819904970166053\n",
            "Validation loss: 0.8968910100830607\n",
            "Iter: 294 loss: 859165.26410584757\n",
            "Iter: 295 loss: 861896.92032272846\n",
            "Iter: 296 loss: 858848.096059871\n",
            "Iter: 297 loss: 857816.69004082121\n",
            "Iter: 298 loss: 860302.94269470091\n",
            "Iter: 299 loss: 857430.2533580804\n",
            "Iter: 300 loss: 856368.89939677878\n",
            "Iter: 301 loss: 860073.13187934086\n",
            "Iter: 302 loss: 856076.83807716728\n",
            "Iter: 303 loss: 854980.770835299\n",
            "Iter: 304 loss: 858525.39011246955\n",
            "Iter: 305 loss: 854660.695074923\n",
            "Iter: 306 loss: 853569.756016772\n",
            "Iter: 307 loss: 858403.00922277942\n",
            "Iter: 308 loss: 853342.00325007737\n",
            "tf.Tensor(\n",
            "[-0.00230247  0.00106482  0.00104887 ...  0.07186052  0.06789612\n",
            " -0.09360697], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8785682901688721\n",
            "Validation loss: 0.8945349036506036\n",
            "Iter: 309 loss: 852324.91768285155\n",
            "Iter: 310 loss: 854424.513866991\n",
            "Iter: 311 loss: 851910.99207569961\n",
            "Iter: 312 loss: 850867.74154206668\n",
            "Iter: 313 loss: 860042.70792321116\n",
            "Iter: 314 loss: 850808.6708401636\n",
            "Iter: 315 loss: 849859.364498302\n",
            "Iter: 316 loss: 851275.4964109459\n",
            "Iter: 317 loss: 849402.63483421784\n",
            "Iter: 318 loss: 848376.56760441477\n",
            "Iter: 319 loss: 853694.69314098021\n",
            "Iter: 320 loss: 848188.00348852843\n",
            "Iter: 321 loss: 847136.75632569788\n",
            "Iter: 322 loss: 850190.06948328391\n",
            "Iter: 323 loss: 846808.5735222887\n",
            "tf.Tensor(\n",
            "[-0.00190612  0.00130507  0.00137725 ...  0.0739283   0.0692176\n",
            " -0.09574169], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8752795683982564\n",
            "Validation loss: 0.8915866105302968\n",
            "Iter: 324 loss: 845733.93505959213\n",
            "Iter: 325 loss: 848840.23440032976\n",
            "Iter: 326 loss: 845364.25385473052\n",
            "Iter: 327 loss: 844283.34156403\n",
            "Iter: 328 loss: 849048.18295748124\n",
            "Iter: 329 loss: 844064.431297554\n",
            "Iter: 330 loss: 842997.60091637564\n",
            "Iter: 331 loss: 847458.07976112515\n",
            "Iter: 332 loss: 842758.674868594\n",
            "Iter: 333 loss: 841790.0758489907\n",
            "Iter: 334 loss: 844155.56471706729\n",
            "Iter: 335 loss: 841435.33689872548\n",
            "Iter: 336 loss: 840503.23766873439\n",
            "Iter: 337 loss: 843728.49583701161\n",
            "Iter: 338 loss: 840255.17909732426\n",
            "tf.Tensor(\n",
            "[-0.00156044  0.00152414  0.00165884 ...  0.07538248  0.07067849\n",
            " -0.09497575], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8719491455148611\n",
            "Validation loss: 0.8883570619446017\n",
            "Iter: 339 loss: 839349.717688441\n",
            "Iter: 340 loss: 844086.675744936\n",
            "Iter: 341 loss: 839192.29069142207\n",
            "Iter: 342 loss: 838370.26247065468\n",
            "Iter: 343 loss: 840895.75501535425\n",
            "Iter: 344 loss: 838124.54597836337\n",
            "Iter: 345 loss: 837245.24639938516\n",
            "Iter: 346 loss: 840751.10508210107\n",
            "Iter: 347 loss: 837032.977173779\n",
            "Iter: 348 loss: 836218.95738857065\n",
            "Iter: 349 loss: 839698.96994079975\n",
            "Iter: 350 loss: 836048.0816806606\n",
            "Iter: 351 loss: 835247.83499513287\n",
            "Iter: 352 loss: 839155.74127110525\n",
            "Iter: 353 loss: 835105.01292547723\n",
            "tf.Tensor(\n",
            "[-0.00127245  0.00155336  0.00177932 ...  0.07714453  0.07119615\n",
            " -0.09444399], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8691637111780794\n",
            "Validation loss: 0.8865931693194632\n",
            "Iter: 354 loss: 834421.162781012\n",
            "Iter: 355 loss: 838569.68794320722\n",
            "Iter: 356 loss: 834324.86186291371\n",
            "Iter: 357 loss: 833642.13005221484\n",
            "Iter: 358 loss: 834178.59771580878\n",
            "Iter: 359 loss: 833224.75281482481\n",
            "Iter: 360 loss: 832338.7552754127\n",
            "Iter: 361 loss: 835453.26086388482\n",
            "Iter: 362 loss: 832090.63316019275\n",
            "Iter: 363 loss: 831175.55850065069\n",
            "Iter: 364 loss: 834903.77022313327\n",
            "Iter: 365 loss: 830969.258895791\n",
            "Iter: 366 loss: 830125.15807896177\n",
            "Iter: 367 loss: 834716.05001841625\n",
            "Iter: 368 loss: 829996.8520896429\n",
            "tf.Tensor(\n",
            "[-0.00100159  0.00145281  0.00182548 ...  0.07895436  0.07264523\n",
            " -0.09383516], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.866292601855853\n",
            "Validation loss: 0.8844684358656038\n",
            "Iter: 369 loss: 829317.947176532\n",
            "Iter: 370 loss: 831711.42655991414\n",
            "Iter: 371 loss: 829140.57432041888\n",
            "Iter: 372 loss: 828518.6125311919\n",
            "Iter: 373 loss: 829618.44877746282\n",
            "Iter: 374 loss: 828244.08653999842\n",
            "Iter: 375 loss: 827577.96584333573\n",
            "Iter: 376 loss: 831081.87869596411\n",
            "Iter: 377 loss: 827472.30621616321\n",
            "Iter: 378 loss: 826895.13475241163\n",
            "Iter: 379 loss: 827858.73244021367\n",
            "Iter: 380 loss: 826629.38040952291\n",
            "Iter: 381 loss: 826028.55195228849\n",
            "Iter: 382 loss: 827867.893971773\n",
            "Iter: 383 loss: 825849.51734683185\n",
            "tf.Tensor(\n",
            "[-0.0008781   0.00132912  0.0018107  ...  0.07986587  0.07285735\n",
            " -0.09355033], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8640085598300614\n",
            "Validation loss: 0.8833979928788462\n",
            "Iter: 384 loss: 825271.69434047909\n",
            "Iter: 385 loss: 827814.5152561001\n",
            "Iter: 386 loss: 825153.46683645668\n",
            "Iter: 387 loss: 824624.20168651908\n",
            "Iter: 388 loss: 826145.94042514183\n",
            "Iter: 389 loss: 824458.10488253436\n",
            "Iter: 390 loss: 823964.36813272641\n",
            "Iter: 391 loss: 827916.29289276781\n",
            "Iter: 392 loss: 823926.48793171521\n",
            "Iter: 393 loss: 823522.51737154182\n",
            "Iter: 394 loss: 823867.9903877246\n",
            "Iter: 395 loss: 823283.94004357711\n",
            "Iter: 396 loss: 822814.6563794571\n",
            "Iter: 397 loss: 824803.2001772701\n",
            "Iter: 398 loss: 822713.386648073\n",
            "tf.Tensor(\n",
            "[-0.00085669  0.00127319  0.00182864 ...  0.08068692  0.07364296\n",
            " -0.09392442], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8622987115379362\n",
            "Validation loss: 0.8824176665170578\n",
            "Iter: 399 loss: 822234.69496596733\n",
            "Iter: 400 loss: 823028.05683097057\n",
            "Iter: 401 loss: 822015.61358343426\n",
            "Iter: 402 loss: 821498.43728239858\n",
            "Iter: 403 loss: 822735.88103141508\n",
            "Iter: 404 loss: 821309.61334587587\n",
            "Iter: 405 loss: 820821.10341339873\n",
            "Iter: 406 loss: 822455.84471306042\n",
            "Iter: 407 loss: 820686.21566566289\n",
            "Iter: 408 loss: 820220.9374000493\n",
            "Iter: 409 loss: 821363.0105049198\n",
            "Iter: 410 loss: 820053.33006019169\n",
            "Iter: 411 loss: 819557.15299916849\n",
            "Iter: 412 loss: 821497.12895833363\n",
            "Iter: 413 loss: 819440.85648059682\n",
            "tf.Tensor(\n",
            "[-0.00091994  0.00119357  0.00181654 ...  0.08183235  0.07427528\n",
            " -0.09457661], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.860534299910204\n",
            "Validation loss: 0.8819531185352238\n",
            "Iter: 414 loss: 818974.27650269412\n",
            "Iter: 415 loss: 820460.15707168414\n",
            "Iter: 416 loss: 818839.01507249521\n",
            "Iter: 417 loss: 818432.2067165972\n",
            "Iter: 418 loss: 820056.82712432172\n",
            "Iter: 419 loss: 818339.98569387477\n",
            "Iter: 420 loss: 817950.65948731534\n",
            "Iter: 421 loss: 819338.65998034773\n",
            "Iter: 422 loss: 817849.83054852\n",
            "Iter: 423 loss: 817486.02193480276\n",
            "Iter: 424 loss: 818220.84403691837\n",
            "Iter: 425 loss: 817337.44084172568\n",
            "Iter: 426 loss: 816980.62364416057\n",
            "Iter: 427 loss: 820192.50427604327\n",
            "Iter: 428 loss: 816960.6525341291\n",
            "tf.Tensor(\n",
            "[-0.00098673  0.00111505  0.00177776 ...  0.08299551  0.07486662\n",
            " -0.09529346], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8591863808408405\n",
            "Validation loss: 0.8808748479448699\n",
            "Iter: 429 loss: 816643.20077089255\n",
            "Iter: 430 loss: 816884.25928398175\n",
            "Iter: 431 loss: 816448.52641881513\n",
            "Iter: 432 loss: 816108.50165217638\n",
            "Iter: 433 loss: 816989.78041144577\n",
            "Iter: 434 loss: 815991.12184755469\n",
            "Iter: 435 loss: 815642.00300291961\n",
            "Iter: 436 loss: 816826.95672769193\n",
            "Iter: 437 loss: 815547.08950570261\n",
            "Iter: 438 loss: 815201.25000828691\n",
            "Iter: 439 loss: 815864.23812788131\n",
            "Iter: 440 loss: 815055.7219260761\n",
            "Iter: 441 loss: 814709.05762489571\n",
            "Iter: 442 loss: 815668.35974933009\n",
            "Iter: 443 loss: 814595.6318370332\n",
            "tf.Tensor(\n",
            "[-0.00100268  0.00105556  0.00172822 ...  0.0843577   0.07567891\n",
            " -0.09659755], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8578502510768493\n",
            "Validation loss: 0.8801876758943851\n",
            "Iter: 444 loss: 814250.25866307621\n",
            "Iter: 445 loss: 815378.0660134427\n",
            "Iter: 446 loss: 814152.68311957153\n",
            "Iter: 447 loss: 813815.66174133332\n",
            "Iter: 448 loss: 814858.8273442561\n",
            "Iter: 449 loss: 813716.43059981125\n",
            "Iter: 450 loss: 813386.11821229162\n",
            "Iter: 451 loss: 814181.97707914282\n",
            "Iter: 452 loss: 813266.09261259\n",
            "Iter: 453 loss: 812934.33889860066\n",
            "Iter: 454 loss: 814526.00900319754\n",
            "Iter: 455 loss: 812874.80072911223\n",
            "Iter: 456 loss: 812586.39615858125\n",
            "Iter: 457 loss: 813494.97643252241\n",
            "Iter: 458 loss: 812502.5125693623\n",
            "tf.Tensor(\n",
            "[-0.00082779  0.00101512  0.00168128 ...  0.08550739  0.0761872\n",
            " -0.09814205], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8566865473102732\n",
            "Validation loss: 0.8797522343756226\n",
            "Iter: 459 loss: 812225.725273879\n",
            "Iter: 460 loss: 813212.04870573792\n",
            "Iter: 461 loss: 812155.36150861089\n",
            "Iter: 462 loss: 811878.59871541\n",
            "Iter: 463 loss: 813538.00785057712\n",
            "Iter: 464 loss: 811840.125191337\n",
            "Iter: 465 loss: 811584.79001571925\n",
            "Iter: 466 loss: 811660.81232289108\n",
            "Iter: 467 loss: 811401.245946436\n",
            "Iter: 468 loss: 811084.28518429911\n",
            "Iter: 469 loss: 812079.71410757\n",
            "Iter: 470 loss: 810991.57444076589\n",
            "Iter: 471 loss: 810678.95512481779\n",
            "Iter: 472 loss: 811876.94484264671\n",
            "Iter: 473 loss: 810603.99254545616\n",
            "tf.Tensor(\n",
            "[-0.0005317   0.00093562  0.00157744 ...  0.08666054  0.07715856\n",
            " -0.09974513], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.855644246648402\n",
            "Validation loss: 0.8791999579479552\n",
            "Iter: 474 loss: 810302.23523371865\n",
            "Iter: 475 loss: 811107.4832610084\n",
            "Iter: 476 loss: 810201.12791241216\n",
            "Iter: 477 loss: 809920.74364494986\n",
            "Iter: 478 loss: 810656.75302340114\n",
            "Iter: 479 loss: 809825.58828753221\n",
            "Iter: 480 loss: 809528.62959003053\n",
            "Iter: 481 loss: 810163.27811121754\n",
            "Iter: 482 loss: 809411.78544494847\n",
            "Iter: 483 loss: 809094.63534398039\n",
            "Iter: 484 loss: 809968.51668719994\n",
            "Iter: 485 loss: 808990.96336447191\n",
            "Iter: 486 loss: 808684.456913837\n",
            "Iter: 487 loss: 809298.34191564552\n",
            "Iter: 488 loss: 808558.35831431067\n",
            "tf.Tensor(\n",
            "[-0.00019333  0.00080549  0.00140089 ...  0.088125    0.0777691\n",
            " -0.10150853], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8544504535566527\n",
            "Validation loss: 0.8786379092052283\n",
            "Iter: 489 loss: 808227.78876270191\n",
            "Iter: 490 loss: 809309.92226517783\n",
            "Iter: 491 loss: 808134.98198393313\n",
            "Iter: 492 loss: 807822.526987849\n",
            "Iter: 493 loss: 809437.27513889037\n",
            "Iter: 494 loss: 807771.69460357388\n",
            "Iter: 495 loss: 807511.91501144506\n",
            "Iter: 496 loss: 809063.30983060622\n",
            "Iter: 497 loss: 807478.84249634144\n",
            "Iter: 498 loss: 807235.04088571214\n",
            "Iter: 499 loss: 808366.92321709031\n",
            "Iter: 500 loss: 807186.869358321\n",
            "Iter: 501 loss: 806978.03813375509\n",
            "Iter: 502 loss: 806800.12775426137\n",
            "Iter: 503 loss: 806742.31618776557\n",
            "tf.Tensor(\n",
            "[ 0.00016146  0.00065513  0.00122884 ...  0.08953935  0.07884991\n",
            " -0.10306222], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8533523739416746\n",
            "Validation loss: 0.8778825722697191\n",
            "Iter: 504 loss: 806423.21961375943\n",
            "Iter: 505 loss: 808434.47368943621\n",
            "Iter: 506 loss: 806386.50560117769\n",
            "Iter: 507 loss: 806090.73467142938\n",
            "Iter: 508 loss: 806881.769095346\n",
            "Iter: 509 loss: 805991.45253173949\n",
            "Iter: 510 loss: 805701.21156439465\n",
            "Iter: 511 loss: 806144.86444565153\n",
            "Iter: 512 loss: 805563.56535949581\n",
            "Iter: 513 loss: 805256.6816687613\n",
            "Iter: 514 loss: 806311.35949318775\n",
            "Iter: 515 loss: 805175.04442086676\n",
            "Iter: 516 loss: 804862.34976385662\n",
            "Iter: 517 loss: 805848.35015958\n",
            "Iter: 518 loss: 804771.90624770429\n",
            "tf.Tensor(\n",
            "[ 0.00073408  0.00039939  0.0009964  ...  0.09134648  0.07954419\n",
            " -0.10513126], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8521342486965406\n",
            "Validation loss: 0.8774333258443825\n",
            "Iter: 519 loss: 804462.07599586062\n",
            "Iter: 520 loss: 805083.887892953\n",
            "Iter: 521 loss: 804335.01070510363\n",
            "Iter: 522 loss: 804012.69492992188\n",
            "Iter: 523 loss: 804741.18972744432\n",
            "Iter: 524 loss: 803890.65045290336\n",
            "Iter: 525 loss: 803558.70090270869\n",
            "Iter: 526 loss: 804580.75704734051\n",
            "Iter: 527 loss: 803460.07239402423\n",
            "Iter: 528 loss: 803110.44019286241\n",
            "Iter: 529 loss: 803703.36876864953\n",
            "Iter: 530 loss: 802952.12030826567\n",
            "Iter: 531 loss: 802592.84106632438\n",
            "Iter: 532 loss: 804295.96337649983\n",
            "Iter: 533 loss: 802526.12217465881\n",
            "tf.Tensor(\n",
            "[ 1.32545258e-03  4.50578005e-05  6.94997579e-04 ...  9.32284745e-02\n",
            "  8.09193995e-02 -1.07258675e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8508360629703292\n",
            "Validation loss: 0.8772061973284291\n",
            "Iter: 534 loss: 802257.59928591386\n",
            "Iter: 535 loss: 806711.98645325075\n",
            "Iter: 536 loss: 802257.58277955023\n",
            "Iter: 537 loss: 802044.30847001926\n",
            "Iter: 538 loss: 801814.30393746868\n",
            "Iter: 539 loss: 801777.7527351391\n",
            "Iter: 540 loss: 801451.96844597091\n",
            "Iter: 541 loss: 801868.08414889069\n",
            "Iter: 542 loss: 801283.31432295823\n",
            "Iter: 543 loss: 800897.117477543\n",
            "Iter: 544 loss: 802422.98629376711\n",
            "Iter: 545 loss: 800808.50736609846\n",
            "Iter: 546 loss: 800429.18927696149\n",
            "Iter: 547 loss: 801644.418723846\n",
            "Iter: 548 loss: 800320.43361495947\n",
            "tf.Tensor(\n",
            "[ 0.00181885 -0.00032517  0.0003798  ...  0.0950193   0.08171668\n",
            " -0.10910465], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8496138201332764\n",
            "Validation loss: 0.8766539646871042\n",
            "Iter: 549 loss: 799959.04027499154\n",
            "Iter: 550 loss: 800343.84822086943\n",
            "Iter: 551 loss: 799759.42521861917\n",
            "Iter: 552 loss: 799323.726582555\n",
            "Iter: 553 loss: 800622.32702140231\n",
            "Iter: 554 loss: 799190.1617931372\n",
            "Iter: 555 loss: 798744.96194081486\n",
            "Iter: 556 loss: 800231.83866354707\n",
            "Iter: 557 loss: 798622.68569639465\n",
            "Iter: 558 loss: 798177.29486607085\n",
            "Iter: 559 loss: 799077.40387629252\n",
            "Iter: 560 loss: 797995.83448222454\n",
            "Iter: 561 loss: 797506.63050916954\n",
            "Iter: 562 loss: 798869.87625444832\n",
            "Iter: 563 loss: 797348.83952022088\n",
            "tf.Tensor(\n",
            "[ 2.35343548e-03 -8.67843257e-04 -6.54459322e-05 ...  9.72718247e-02\n",
            "  8.33680399e-02 -1.11318826e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8481409495577741\n",
            "Validation loss: 0.8758353425549735\n",
            "Iter: 564 loss: 796844.34071961872\n",
            "Iter: 565 loss: 797982.93285463622\n",
            "Iter: 566 loss: 796652.80420550238\n",
            "Iter: 567 loss: 796133.92959442327\n",
            "Iter: 568 loss: 797936.29167239822\n",
            "Iter: 569 loss: 795997.06682886742\n",
            "Iter: 570 loss: 795560.27308977477\n",
            "Iter: 571 loss: 801717.90716248343\n",
            "Iter: 572 loss: 795558.41659600823\n",
            "Iter: 573 loss: 795177.81526097807\n",
            "Iter: 574 loss: 795242.27194445627\n",
            "Iter: 575 loss: 794891.64525646577\n",
            "Iter: 576 loss: 794414.1543493655\n",
            "Iter: 577 loss: 794693.44631830126\n",
            "Iter: 578 loss: 794101.48235898826\n",
            "tf.Tensor(\n",
            "[ 0.00269503 -0.00142403 -0.00052612 ...  0.09974841  0.08452922\n",
            " -0.11371219], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.846749710094246\n",
            "Validation loss: 0.8742918317319177\n",
            "Iter: 579 loss: 793466.51861215162\n",
            "Iter: 580 loss: 794926.7190779259\n",
            "Iter: 581 loss: 793229.08296519413\n",
            "Iter: 582 loss: 792561.7005481649\n",
            "Iter: 583 loss: 794118.9806859747\n",
            "Iter: 584 loss: 792316.57112532272\n",
            "Iter: 585 loss: 791594.61237665929\n",
            "Iter: 586 loss: 793630.9751460132\n",
            "Iter: 587 loss: 791362.45151974889\n",
            "Iter: 588 loss: 790570.2444988616\n",
            "Iter: 589 loss: 792881.32984433626\n",
            "Iter: 590 loss: 790323.68154856924\n",
            "Iter: 591 loss: 789546.11873491923\n",
            "Iter: 592 loss: 792237.06293984328\n",
            "Iter: 593 loss: 789343.68479878188\n",
            "tf.Tensor(\n",
            "[ 0.00267369 -0.00199618 -0.00101832 ...  0.10286217  0.08644392\n",
            " -0.11635265], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8449839183494362\n",
            "Validation loss: 0.8737640145019275\n",
            "Iter: 594 loss: 788573.01329699613\n",
            "Iter: 595 loss: 789740.53935676627\n",
            "Iter: 596 loss: 788204.5812193586\n",
            "Iter: 597 loss: 787295.89199055173\n",
            "Iter: 598 loss: 789783.9560726831\n",
            "Iter: 599 loss: 787001.47823024681\n",
            "Iter: 600 loss: 786064.54901389952\n",
            "Iter: 601 loss: 788579.55001437338\n",
            "Iter: 602 loss: 785753.58165813435\n",
            "Iter: 603 loss: 784774.96916932787\n",
            "Iter: 604 loss: 786975.51026901568\n",
            "Iter: 605 loss: 784403.11195645947\n",
            "Iter: 606 loss: 783732.63151825976\n",
            "Iter: 607 loss: 783723.9816420459\n",
            "tf.Tensor(\n",
            "[ 0.00257871 -0.00258418 -0.00154342 ...  0.10651271  0.08832654\n",
            " -0.11935419], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8434902544430599\n",
            "Validation loss: 0.8739655680532239\n",
            "Iter: 608 loss: 783076.10513128678\n",
            "Iter: 609 loss: 782814.78449446871\n",
            "Iter: 610 loss: 782469.85835132468\n",
            "Iter: 611 loss: 781577.15916524862\n",
            "Iter: 612 loss: 782870.71135352179\n",
            "Iter: 613 loss: 781136.76336258336\n",
            "Iter: 614 loss: 780022.49433677853\n",
            "Iter: 615 loss: 784850.76496756671\n",
            "Iter: 616 loss: 779793.35690892825\n",
            "Iter: 617 loss: 778755.17943168047\n",
            "Iter: 618 loss: 781098.87022774713\n",
            "Iter: 619 loss: 778364.34014398127\n",
            "Iter: 620 loss: 777257.338661762\n",
            "Iter: 621 loss: 780199.28649632516\n",
            "Iter: 622 loss: 776885.49094800616\n",
            "tf.Tensor(\n",
            "[ 0.00261965 -0.00311341 -0.00206189 ...  0.10997571  0.09043176\n",
            " -0.12284575], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8420013413040103\n",
            "Validation loss: 0.8746308106254772\n",
            "Iter: 623 loss: 775649.95735219319\n",
            "Iter: 624 loss: 779807.68932113494\n",
            "Iter: 625 loss: 775312.18462210183\n",
            "Iter: 626 loss: 774142.93580436532\n",
            "Iter: 627 loss: 777299.99562297878\n",
            "Iter: 628 loss: 773758.23706902319\n",
            "Iter: 629 loss: 772622.29400201747\n",
            "Iter: 630 loss: 775250.82661670225\n",
            "Iter: 631 loss: 772199.55490212282\n",
            "Iter: 632 loss: 771029.0205684033\n",
            "Iter: 633 loss: 774974.7163899563\n",
            "Iter: 634 loss: 770714.53465283755\n",
            "Iter: 635 loss: 769639.1061531601\n",
            "Iter: 636 loss: 772873.69365283207\n",
            "Iter: 637 loss: 769314.82230125542\n",
            "tf.Tensor(\n",
            "[ 0.0028995  -0.00342648 -0.00247452 ...  0.11256901  0.09215073\n",
            " -0.12640247], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8403792790647422\n",
            "Validation loss: 0.8731299804506272\n",
            "Iter: 638 loss: 768323.61893055413\n",
            "Iter: 639 loss: 772012.161060556\n",
            "Iter: 640 loss: 768084.45677437482\n",
            "Iter: 641 loss: 767187.82684047148\n",
            "Iter: 642 loss: 773922.58888091333\n",
            "Iter: 643 loss: 767118.68849665369\n",
            "Iter: 644 loss: 766378.87946503214\n",
            "Iter: 645 loss: 768950.85664344893\n",
            "Iter: 646 loss: 766184.00831178227\n",
            "Iter: 647 loss: 765529.23603136931\n",
            "Iter: 648 loss: 765624.52850458224\n",
            "Iter: 649 loss: 765032.3951542112\n",
            "Iter: 650 loss: 764149.98136769317\n",
            "Iter: 651 loss: 766523.2087763712\n",
            "Iter: 652 loss: 763857.9467602761\n",
            "tf.Tensor(\n",
            "[ 0.00307459 -0.00358611 -0.00279554 ...  0.11455664  0.09332407\n",
            " -0.12956479], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8390503293087465\n",
            "Validation loss: 0.8716242340560224\n",
            "Iter: 653 loss: 763080.72560121538\n",
            "Iter: 654 loss: 766411.35476458387\n",
            "Iter: 655 loss: 762920.62172385841\n",
            "Iter: 656 loss: 762199.50633981137\n",
            "Iter: 657 loss: 764635.92652934149\n",
            "Iter: 658 loss: 762005.15426532715\n",
            "Iter: 659 loss: 761300.93663521588\n",
            "Iter: 660 loss: 762690.82141857909\n",
            "Iter: 661 loss: 761011.89223062072\n",
            "Iter: 662 loss: 760310.05967612739\n",
            "Iter: 663 loss: 762055.93276652973\n",
            "Iter: 664 loss: 760064.13843798148\n",
            "Iter: 665 loss: 759354.70348022226\n",
            "Iter: 666 loss: 761328.37223507441\n",
            "Iter: 667 loss: 759126.56582399725\n",
            "tf.Tensor(\n",
            "[ 0.00280829 -0.00355414 -0.00300638 ...  0.11568612  0.0941035\n",
            " -0.13181699], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.837528959675266\n",
            "Validation loss: 0.8701095840657292\n",
            "Iter: 668 loss: 758438.69162847276\n",
            "Iter: 669 loss: 760163.88602958166\n",
            "Iter: 670 loss: 758199.74110328872\n",
            "Iter: 671 loss: 757521.06053966773\n",
            "Iter: 672 loss: 759067.87519919151\n",
            "Iter: 673 loss: 757267.35722406232\n",
            "Iter: 674 loss: 756598.88978745753\n",
            "Iter: 675 loss: 759877.29766252579\n",
            "Iter: 676 loss: 756485.59334584151\n",
            "Iter: 677 loss: 755935.43926894641\n",
            "Iter: 678 loss: 759009.28639106173\n",
            "Iter: 679 loss: 755854.99460671085\n",
            "Iter: 680 loss: 755356.196511114\n",
            "Iter: 681 loss: 757225.49233263941\n",
            "Iter: 682 loss: 755236.95133103861\n",
            "tf.Tensor(\n",
            "[ 0.00222785 -0.00352463 -0.00320714 ...  0.11668369  0.09455039\n",
            " -0.1337786 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8362534912532341\n",
            "Validation loss: 0.8683238603365062\n",
            "Iter: 683 loss: 754785.60246057482\n",
            "Iter: 684 loss: 754730.77926431166\n",
            "Iter: 685 loss: 754407.05480851582\n",
            "Iter: 686 loss: 753788.74276086234\n",
            "Iter: 687 loss: 755095.82638234308\n",
            "Iter: 688 loss: 753545.94861157041\n",
            "Iter: 689 loss: 752934.56818038388\n",
            "Iter: 690 loss: 755280.399301191\n",
            "Iter: 691 loss: 752790.97315064224\n",
            "Iter: 692 loss: 752237.65274661989\n",
            "Iter: 693 loss: 753900.22776850546\n",
            "Iter: 694 loss: 752070.90928107512\n",
            "Iter: 695 loss: 751500.02645857842\n",
            "Iter: 696 loss: 753453.836726118\n",
            "Iter: 697 loss: 751347.98908977758\n",
            "tf.Tensor(\n",
            "[ 0.00148678 -0.00353852 -0.00343784 ...  0.11771934  0.0956363\n",
            " -0.13616594], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8348012398625325\n",
            "Validation loss: 0.8678361820273734\n",
            "Iter: 698 loss: 750840.82138866838\n",
            "Iter: 699 loss: 752002.68314206856\n",
            "Iter: 700 loss: 750651.931484032\n",
            "Iter: 701 loss: 750137.67725971749\n",
            "Iter: 702 loss: 751246.59611997241\n",
            "Iter: 703 loss: 749937.22834288934\n",
            "Iter: 704 loss: 749417.64537256723\n",
            "Iter: 705 loss: 750824.75356545579\n",
            "Iter: 706 loss: 749246.80639651371\n",
            "Iter: 707 loss: 748739.71084776928\n",
            "Iter: 708 loss: 750243.04197130457\n",
            "Iter: 709 loss: 748584.7895846162\n",
            "Iter: 710 loss: 748084.5818647733\n",
            "Iter: 711 loss: 749968.64190058957\n",
            "Iter: 712 loss: 747965.16698483052\n",
            "tf.Tensor(\n",
            "[ 0.00086368 -0.00359243 -0.00359762 ...  0.11857128  0.09611691\n",
            " -0.13804072], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8330285760467537\n",
            "Validation loss: 0.8662327690182352\n",
            "Iter: 713 loss: 747565.46445652691\n",
            "Iter: 714 loss: 750453.16311452375\n",
            "Iter: 715 loss: 747522.6941218354\n",
            "Iter: 716 loss: 747117.23224811\n",
            "Iter: 717 loss: 749825.35310886439\n",
            "Iter: 718 loss: 747075.84349444823\n",
            "Iter: 719 loss: 746699.89335837145\n",
            "Iter: 720 loss: 747005.891260523\n",
            "Iter: 721 loss: 746467.14774271881\n",
            "Iter: 722 loss: 745969.2276647446\n",
            "Iter: 723 loss: 748202.96928598348\n",
            "Iter: 724 loss: 745873.13588717661\n",
            "Iter: 725 loss: 745451.257474254\n",
            "Iter: 726 loss: 747102.91772917018\n",
            "Iter: 727 loss: 745353.8995872332\n",
            "tf.Tensor(\n",
            "[ 0.00046078 -0.00363724 -0.00369381 ...  0.11950793  0.09702456\n",
            " -0.1394333 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8314148760589353\n",
            "Validation loss: 0.8649466835228723\n",
            "Iter: 728 loss: 744962.0900399175\n",
            "Iter: 729 loss: 745589.4012603024\n",
            "Iter: 730 loss: 744779.62792156346\n",
            "Iter: 731 loss: 744363.08685932448\n",
            "Iter: 732 loss: 746095.61753071751\n",
            "Iter: 733 loss: 744273.51168400713\n",
            "Iter: 734 loss: 743912.58760641469\n",
            "Iter: 735 loss: 745338.97546799434\n",
            "Iter: 736 loss: 743830.36673553556\n",
            "Iter: 737 loss: 743505.96677199192\n",
            "Iter: 738 loss: 744106.98104148638\n",
            "Iter: 739 loss: 743363.43240962212\n",
            "Iter: 740 loss: 743015.14014739357\n",
            "Iter: 741 loss: 744092.7808823993\n",
            "Iter: 742 loss: 742912.79461150954\n",
            "tf.Tensor(\n",
            "[ 0.00018071 -0.0036399  -0.0037205  ...  0.1205321   0.09737098\n",
            " -0.14018549], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8296855688187034\n",
            "Validation loss: 0.8636160106458173\n",
            "Iter: 743 loss: 742564.96896770247\n",
            "Iter: 744 loss: 743629.37311021355\n",
            "Iter: 745 loss: 742460.044617992\n",
            "Iter: 746 loss: 742134.48919819912\n",
            "Iter: 747 loss: 743226.85416867549\n",
            "Iter: 748 loss: 742046.65182197036\n",
            "Iter: 749 loss: 741782.97476082714\n",
            "Iter: 750 loss: 743698.54808822274\n",
            "Iter: 751 loss: 741757.34547604644\n",
            "Iter: 752 loss: 741503.25074801652\n",
            "Iter: 753 loss: 742767.87059036572\n",
            "Iter: 754 loss: 741460.07970210246\n",
            "Iter: 755 loss: 741229.396385092\n",
            "Iter: 756 loss: 741250.16890248423\n",
            "Iter: 757 loss: 741048.38320863713\n",
            "tf.Tensor(\n",
            "[-1.39409124e-04 -3.57751474e-03 -3.72279167e-03 ...  1.21522057e-01\n",
            "  9.83681389e-02 -1.40784514e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8282635852351332\n",
            "Validation loss: 0.8630492693388859\n",
            "Iter: 758 loss: 740718.36898935307\n",
            "Iter: 759 loss: 742431.65161220334\n",
            "Iter: 760 loss: 740665.98421609763\n",
            "Iter: 761 loss: 740387.61111643713\n",
            "Iter: 762 loss: 741211.11176717491\n",
            "Iter: 763 loss: 740302.606759753\n",
            "Iter: 764 loss: 740028.68477781769\n",
            "Iter: 765 loss: 740815.0690758432\n",
            "Iter: 766 loss: 739942.06895080488\n",
            "Iter: 767 loss: 739672.28508412081\n",
            "Iter: 768 loss: 740406.16109546239\n",
            "Iter: 769 loss: 739583.23698136176\n",
            "Iter: 770 loss: 739315.75905918586\n",
            "Iter: 771 loss: 740451.04535613477\n",
            "Iter: 772 loss: 739259.7497048981\n",
            "tf.Tensor(\n",
            "[-0.00034363 -0.00344112 -0.00367116 ...  0.12213773  0.0986863\n",
            " -0.14092609], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8269976598260358\n",
            "Validation loss: 0.8623509784772087\n",
            "Iter: 773 loss: 739028.85181523359\n",
            "Iter: 774 loss: 739404.85577795783\n",
            "Iter: 775 loss: 738922.40464561444\n",
            "Iter: 776 loss: 738673.12651016738\n",
            "Iter: 777 loss: 739418.64929568488\n",
            "Iter: 778 loss: 738597.7089014902\n",
            "Iter: 779 loss: 738360.30417990033\n",
            "Iter: 780 loss: 738963.48283111141\n",
            "Iter: 781 loss: 738278.026884088\n",
            "Iter: 782 loss: 738038.24644920276\n",
            "Iter: 783 loss: 738576.64748107735\n",
            "Iter: 784 loss: 737947.39290303166\n",
            "Iter: 785 loss: 737724.69220420753\n",
            "Iter: 786 loss: 738808.78406924184\n",
            "Iter: 787 loss: 737684.31879108038\n",
            "tf.Tensor(\n",
            "[-0.00070224 -0.00329845 -0.00364733 ...  0.12306467  0.09973522\n",
            " -0.14145742], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8257269814922573\n",
            "Validation loss: 0.8620061269583542\n",
            "Iter: 788 loss: 737503.19595691562\n",
            "Iter: 789 loss: 739248.179726151\n",
            "Iter: 790 loss: 737496.56020024652\n",
            "Iter: 791 loss: 737342.54611771274\n",
            "Iter: 792 loss: 737460.63345543586\n",
            "Iter: 793 loss: 737247.14093483088\n",
            "Iter: 794 loss: 737043.94349884929\n",
            "Iter: 795 loss: 737303.04427291465\n",
            "Iter: 796 loss: 736939.66319941648\n",
            "Iter: 797 loss: 736723.9817112434\n",
            "Iter: 798 loss: 737637.9112699969\n",
            "Iter: 799 loss: 736678.81526953785\n",
            "Iter: 800 loss: 736479.22051857447\n",
            "Iter: 801 loss: 736813.14227956056\n",
            "Iter: 802 loss: 736388.8396134791\n",
            "tf.Tensor(\n",
            "[-0.00097914 -0.00322065 -0.00363849 ...  0.124054    0.10026327\n",
            " -0.14199372], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8246106536819929\n",
            "Validation loss: 0.86149272387748\n",
            "Iter: 803 loss: 736180.61006610387\n",
            "Iter: 804 loss: 736910.22674949793\n",
            "Iter: 805 loss: 736126.454577838\n",
            "Iter: 806 loss: 735932.91847604129\n",
            "Iter: 807 loss: 736522.87804775871\n",
            "Iter: 808 loss: 735875.42628510646\n",
            "Iter: 809 loss: 735676.75310814881\n",
            "Iter: 810 loss: 736248.65269479738\n",
            "Iter: 811 loss: 735614.478259728\n",
            "Iter: 812 loss: 735425.67369594844\n",
            "Iter: 813 loss: 736030.69328989647\n",
            "Iter: 814 loss: 735372.08680112974\n",
            "Iter: 815 loss: 735187.844908152\n",
            "Iter: 816 loss: 735582.050537449\n",
            "Iter: 817 loss: 735115.80659443361\n",
            "tf.Tensor(\n",
            "[-0.00126767 -0.00318089 -0.00363918 ...  0.12520548  0.10128178\n",
            " -0.14251124], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8234966557190782\n",
            "Validation loss: 0.8607439310568699\n",
            "Iter: 818 loss: 734921.74797159946\n",
            "Iter: 819 loss: 735341.2327783223\n",
            "Iter: 820 loss: 734846.51612488215\n",
            "Iter: 821 loss: 734661.59287457052\n",
            "Iter: 822 loss: 735481.62088949187\n",
            "Iter: 823 loss: 734624.03534121881\n",
            "Iter: 824 loss: 734472.896404151\n",
            "Iter: 825 loss: 736108.38161838625\n",
            "Iter: 826 loss: 734469.5665882061\n",
            "Iter: 827 loss: 734347.22942116985\n",
            "Iter: 828 loss: 734302.11057665455\n",
            "Iter: 829 loss: 734233.87610532553\n",
            "Iter: 830 loss: 734057.6237389209\n",
            "Iter: 831 loss: 734413.18938021548\n",
            "Iter: 832 loss: 733986.00182072574\n",
            "tf.Tensor(\n",
            "[-0.00166258 -0.00312164 -0.00364946 ...  0.12638189  0.10203952\n",
            " -0.14313788], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8223919531083653\n",
            "Validation loss: 0.860198116254261\n",
            "Iter: 833 loss: 733805.835799666\n",
            "Iter: 834 loss: 734416.12946232036\n",
            "Iter: 835 loss: 733757.44417251518\n",
            "Iter: 836 loss: 733580.88471437921\n",
            "Iter: 837 loss: 733959.91547279549\n",
            "Iter: 838 loss: 733511.73049253586\n",
            "Iter: 839 loss: 733330.34665599407\n",
            "Iter: 840 loss: 733905.99622414983\n",
            "Iter: 841 loss: 733278.35237899667\n",
            "Iter: 842 loss: 733107.20147717756\n",
            "Iter: 843 loss: 733689.69174228015\n",
            "Iter: 844 loss: 733061.28067073168\n",
            "Iter: 845 loss: 732894.74141624686\n",
            "Iter: 846 loss: 733217.38347897178\n",
            "Iter: 847 loss: 732825.35775738407\n",
            "tf.Tensor(\n",
            "[-0.00213379 -0.00304401 -0.00366834 ...  0.12760106  0.1032286\n",
            " -0.1441576 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8211812703054209\n",
            "Validation loss: 0.8596337331166624\n",
            "Iter: 848 loss: 732656.23214195971\n",
            "Iter: 849 loss: 733302.643558881\n",
            "Iter: 850 loss: 732616.2396272599\n",
            "Iter: 851 loss: 732457.39609293523\n",
            "Iter: 852 loss: 732886.22317182343\n",
            "Iter: 853 loss: 732405.06127756229\n",
            "Iter: 854 loss: 732248.1121472083\n",
            "Iter: 855 loss: 732571.23256516526\n",
            "Iter: 856 loss: 732185.30826891633\n",
            "Iter: 857 loss: 732043.31753572519\n",
            "Iter: 858 loss: 733237.56063371687\n",
            "Iter: 859 loss: 732034.66894084541\n",
            "Iter: 860 loss: 731910.05614288244\n",
            "Iter: 861 loss: 732346.61099470523\n",
            "Iter: 862 loss: 731877.73359898268\n",
            "tf.Tensor(\n",
            "[-0.00255252 -0.00298721 -0.00369524 ...  0.12867039  0.10408956\n",
            " -0.14522872], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8201639144293443\n",
            "Validation loss: 0.8592804501227564\n",
            "Iter: 863 loss: 731761.05108387419\n",
            "Iter: 864 loss: 731824.15178474167\n",
            "Iter: 865 loss: 731684.14969423576\n",
            "Iter: 866 loss: 731536.41178071464\n",
            "Iter: 867 loss: 731746.43365822325\n",
            "Iter: 868 loss: 731463.928298981\n",
            "Iter: 869 loss: 731308.89898178517\n",
            "Iter: 870 loss: 731784.65338818135\n",
            "Iter: 871 loss: 731263.09521857381\n",
            "Iter: 872 loss: 731110.77780308679\n",
            "Iter: 873 loss: 731357.16147993191\n",
            "Iter: 874 loss: 731040.66842272528\n",
            "Iter: 875 loss: 730883.31870226306\n",
            "Iter: 876 loss: 731563.33520849864\n",
            "Iter: 877 loss: 730851.11487494048\n",
            "tf.Tensor(\n",
            "[-0.00315206 -0.00294499 -0.00376303 ...  0.13024294  0.10534133\n",
            " -0.14652716], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8189639671638846\n",
            "Validation loss: 0.8587375268822225\n",
            "Iter: 878 loss: 730707.95940628531\n",
            "Iter: 879 loss: 731231.04869539628\n",
            "Iter: 880 loss: 730672.23990426806\n",
            "Iter: 881 loss: 730540.99859578616\n",
            "Iter: 882 loss: 730778.6374400839\n",
            "Iter: 883 loss: 730484.15724095912\n",
            "Iter: 884 loss: 730342.70450955152\n",
            "Iter: 885 loss: 730822.47033855761\n",
            "Iter: 886 loss: 730304.74502968031\n",
            "Iter: 887 loss: 730167.47650309058\n",
            "Iter: 888 loss: 730509.007225189\n",
            "Iter: 889 loss: 730119.18990018265\n",
            "Iter: 890 loss: 729985.76798903523\n",
            "Iter: 891 loss: 730502.97961469367\n",
            "Iter: 892 loss: 729954.74877765751\n",
            "tf.Tensor(\n",
            "[-0.00368819 -0.00295286 -0.00386334 ...  0.13177113  0.10649452\n",
            " -0.14760705], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8179000501416456\n",
            "Validation loss: 0.8583854313297206\n",
            "Iter: 893 loss: 729838.02458203735\n",
            "Iter: 894 loss: 730736.638256543\n",
            "Iter: 895 loss: 729828.94833331928\n",
            "Iter: 896 loss: 729728.25152296922\n",
            "Iter: 897 loss: 729915.00042673177\n",
            "Iter: 898 loss: 729685.26314355119\n",
            "Iter: 899 loss: 729582.70942838117\n",
            "Iter: 900 loss: 729593.20656525088\n",
            "Iter: 901 loss: 729503.63693726354\n",
            "Iter: 902 loss: 729369.69173389126\n",
            "Iter: 903 loss: 729737.90133165079\n",
            "Iter: 904 loss: 729326.02910899534\n",
            "Iter: 905 loss: 729193.53225855611\n",
            "Iter: 906 loss: 729650.38499701908\n",
            "Iter: 907 loss: 729158.53244313248\n",
            "tf.Tensor(\n",
            "[-0.00413463 -0.00300555 -0.00397951 ...  0.1331311   0.10753572\n",
            " -0.1485459 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8169437816575179\n",
            "Validation loss: 0.8578133648939884\n",
            "Iter: 908 loss: 729035.59692626423\n",
            "Iter: 909 loss: 729270.309719952\n",
            "Iter: 910 loss: 728983.89108854847\n",
            "Iter: 911 loss: 728852.68315422477\n",
            "Iter: 912 loss: 729325.695339315\n",
            "Iter: 913 loss: 728819.57263481687\n",
            "Iter: 914 loss: 728696.11908438557\n",
            "Iter: 915 loss: 728907.39981624961\n",
            "Iter: 916 loss: 728640.93637486373\n",
            "Iter: 917 loss: 728507.37022543221\n",
            "Iter: 918 loss: 728838.80989856331\n",
            "Iter: 919 loss: 728460.30694914167\n",
            "Iter: 920 loss: 728322.08044015744\n",
            "Iter: 921 loss: 728855.00701555307\n",
            "Iter: 922 loss: 728289.68765647523\n",
            "tf.Tensor(\n",
            "[-0.00458675 -0.00313423 -0.00413027 ...  0.13470135  0.10903665\n",
            " -0.14983333], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8157949256854532\n",
            "Validation loss: 0.8572814661747675\n",
            "Iter: 923 loss: 728163.98014841089\n",
            "Iter: 924 loss: 728473.12041951832\n",
            "Iter: 925 loss: 728119.43863100559\n",
            "Iter: 926 loss: 727995.65107825329\n",
            "Iter: 927 loss: 728711.66392325622\n",
            "Iter: 928 loss: 727979.16657105018\n",
            "Iter: 929 loss: 727870.96103501192\n",
            "Iter: 930 loss: 728528.74767012533\n",
            "Iter: 931 loss: 727857.52809606364\n",
            "Iter: 932 loss: 727766.814847599\n",
            "Iter: 933 loss: 727758.03691926075\n",
            "Iter: 934 loss: 727691.5559363669\n",
            "Iter: 935 loss: 727574.3969919231\n",
            "Iter: 936 loss: 727748.23011838319\n",
            "Iter: 937 loss: 727518.10622404481\n",
            "tf.Tensor(\n",
            "[-0.00492034 -0.00331886 -0.00426647 ...  0.13616138  0.11023614\n",
            " -0.15098751], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8147277086462688\n",
            "Validation loss: 0.856862994868734\n",
            "Iter: 938 loss: 727382.93951106\n",
            "Iter: 939 loss: 727724.15017578669\n",
            "Iter: 940 loss: 727335.80051387439\n",
            "Iter: 941 loss: 727195.48278635228\n",
            "Iter: 942 loss: 727587.10596033512\n",
            "Iter: 943 loss: 727150.51115109248\n",
            "Iter: 944 loss: 727016.27160736453\n",
            "Iter: 945 loss: 727483.02596772288\n",
            "Iter: 946 loss: 726980.90241825557\n",
            "Iter: 947 loss: 726847.42447038344\n",
            "Iter: 948 loss: 727085.50467834773\n",
            "Iter: 949 loss: 726789.13887237\n",
            "Iter: 950 loss: 726649.59877961571\n",
            "Iter: 951 loss: 726951.41686210351\n",
            "Iter: 952 loss: 726595.40530477988\n",
            "tf.Tensor(\n",
            "[-0.00533217 -0.00360795 -0.00442349 ...  0.13820238  0.11208428\n",
            " -0.15213061], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.813350475611312\n",
            "Validation loss: 0.8560116412840652\n",
            "Iter: 953 loss: 726449.81138670316\n",
            "Iter: 954 loss: 726943.81552485365\n",
            "Iter: 955 loss: 726410.71764043381\n",
            "Iter: 956 loss: 726275.19339030981\n",
            "Iter: 957 loss: 726660.51483376243\n",
            "Iter: 958 loss: 726232.34630237625\n",
            "Iter: 959 loss: 726097.23787318356\n",
            "Iter: 960 loss: 726494.43018918775\n",
            "Iter: 961 loss: 726055.80134058406\n",
            "Iter: 962 loss: 725940.84688418033\n",
            "Iter: 963 loss: 726997.54639521136\n",
            "Iter: 964 loss: 725935.8909179105\n",
            "Iter: 965 loss: 725828.39882779925\n",
            "Iter: 966 loss: 726008.40280641511\n",
            "Iter: 967 loss: 725779.76760937518\n",
            "tf.Tensor(\n",
            "[-0.00569974 -0.00389909 -0.00454093 ...  0.14016108  0.11350679\n",
            " -0.15299017], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8120953284437452\n",
            "Validation loss: 0.8559630275558382\n",
            "Iter: 968 loss: 725671.9101573762\n",
            "Iter: 969 loss: 725656.30809021392\n",
            "Iter: 970 loss: 725580.8067847878\n",
            "Iter: 971 loss: 725443.18247167859\n",
            "Iter: 972 loss: 725929.35216651368\n",
            "Iter: 973 loss: 725407.74959862849\n",
            "Iter: 974 loss: 725271.2708805704\n",
            "Iter: 975 loss: 725585.94859184441\n",
            "Iter: 976 loss: 725220.50017441472\n",
            "Iter: 977 loss: 725080.11368947849\n",
            "Iter: 978 loss: 725340.71850286587\n",
            "Iter: 979 loss: 725020.21762310283\n",
            "Iter: 980 loss: 724871.7284484281\n",
            "Iter: 981 loss: 725517.8264045323\n",
            "Iter: 982 loss: 724841.31361606345\n",
            "tf.Tensor(\n",
            "[-0.00609317 -0.00425003 -0.00464797 ...  0.14225957  0.11545156\n",
            " -0.15405985], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8106983336265114\n",
            "Validation loss: 0.8558073983197158\n",
            "Iter: 983 loss: 724699.91677209409\n",
            "Iter: 984 loss: 725045.11908509815\n",
            "Iter: 985 loss: 724649.55837420234\n",
            "Iter: 986 loss: 724507.12005567364\n",
            "Iter: 987 loss: 724688.9129049686\n",
            "Iter: 988 loss: 724433.94537397043\n",
            "Iter: 989 loss: 724267.59013735224\n",
            "Iter: 990 loss: 724673.02002816729\n",
            "Iter: 991 loss: 724208.200494554\n",
            "Iter: 992 loss: 724039.70327381138\n",
            "Iter: 993 loss: 724655.48079083825\n",
            "Iter: 994 loss: 723997.75815705571\n",
            "Iter: 995 loss: 723847.60201800754\n",
            "Iter: 996 loss: 724559.670408598\n",
            "Iter: 997 loss: 723820.44594198815\n",
            "tf.Tensor(\n",
            "[-0.0064289  -0.0046399  -0.00474956 ...  0.14436694  0.11722149\n",
            " -0.15520166], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8092016024963454\n",
            "Validation loss: 0.8552503641566791\n",
            "Iter: 998 loss: 723700.74881813338\n",
            "Iter: 999 loss: 724838.77672533446\n",
            "Iter: 1000 loss: 723696.15094429231\n",
            "Iter: 1001 loss: 723593.64635793446\n",
            "Iter: 1002 loss: 723532.36462747422\n",
            "Iter: 1003 loss: 723489.85852862243\n",
            "Iter: 1004 loss: 723346.50989005622\n",
            "Iter: 1005 loss: 723570.90959605738\n",
            "Iter: 1006 loss: 723279.55619498156\n",
            "Iter: 1007 loss: 723121.72568443837\n",
            "Iter: 1008 loss: 723578.45171272452\n",
            "Iter: 1009 loss: 723072.69004166545\n",
            "Iter: 1010 loss: 722917.83927676361\n",
            "Iter: 1011 loss: 723306.70751944929\n",
            "Iter: 1012 loss: 722863.75006949261\n",
            "tf.Tensor(\n",
            "[-0.00662625 -0.00495721 -0.00481862 ...  0.14618257  0.11905492\n",
            " -0.15609297], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8079143703789761\n",
            "Validation loss: 0.8547934370523496\n",
            "Iter: 1013 loss: 722707.3302491951\n",
            "Iter: 1014 loss: 723228.856309898\n",
            "Iter: 1015 loss: 722664.73935341521\n",
            "Iter: 1016 loss: 722516.71055049554\n",
            "Iter: 1017 loss: 722977.77199850127\n",
            "Iter: 1018 loss: 722473.38149590744\n",
            "Iter: 1019 loss: 722329.695356077\n",
            "Iter: 1020 loss: 722713.3206868259\n",
            "Iter: 1021 loss: 722282.026971716\n",
            "Iter: 1022 loss: 722133.85665052989\n",
            "Iter: 1023 loss: 722331.74945727526\n",
            "Iter: 1024 loss: 722059.33459067449\n",
            "Iter: 1025 loss: 721897.62459885667\n",
            "Iter: 1026 loss: 722368.04385606945\n",
            "Iter: 1027 loss: 721847.59395415324\n",
            "tf.Tensor(\n",
            "[-0.00680308 -0.00525026 -0.00486706 ...  0.14818602  0.12069403\n",
            " -0.15693118], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8066900277728035\n",
            "Validation loss: 0.8544951339422397\n",
            "Iter: 1028 loss: 721684.10849922313\n",
            "Iter: 1029 loss: 722150.49577057769\n",
            "Iter: 1030 loss: 721632.72924877878\n",
            "Iter: 1031 loss: 721498.1714723988\n",
            "Iter: 1032 loss: 722657.66759600479\n",
            "Iter: 1033 loss: 721490.74923517916\n",
            "Iter: 1034 loss: 721363.92684366717\n",
            "Iter: 1035 loss: 721761.74098563287\n",
            "Iter: 1036 loss: 721327.28344987531\n",
            "Iter: 1037 loss: 721214.894178353\n",
            "Iter: 1038 loss: 721164.24847177987\n",
            "Iter: 1039 loss: 721107.73520916\n",
            "Iter: 1040 loss: 720942.58820640144\n",
            "Iter: 1041 loss: 721300.02223572461\n",
            "Iter: 1042 loss: 720878.76259859256\n",
            "tf.Tensor(\n",
            "[-0.00693547 -0.00550564 -0.0048948  ...  0.15018614  0.12239165\n",
            " -0.15790756], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8056000344679468\n",
            "Validation loss: 0.8537939964493158\n",
            "Iter: 1043 loss: 720712.38104694569\n",
            "Iter: 1044 loss: 721246.72233170038\n",
            "Iter: 1045 loss: 720665.46042357\n",
            "Iter: 1046 loss: 720499.24468243821\n",
            "Iter: 1047 loss: 720987.09178717854\n",
            "Iter: 1048 loss: 720448.31025842787\n",
            "Iter: 1049 loss: 720288.47798802028\n",
            "Iter: 1050 loss: 720698.68572887313\n",
            "Iter: 1051 loss: 720233.8056762194\n",
            "Iter: 1052 loss: 720076.67029062158\n",
            "Iter: 1053 loss: 720728.76042860933\n",
            "Iter: 1054 loss: 720042.74609613384\n",
            "Iter: 1055 loss: 719895.4296175472\n",
            "Iter: 1056 loss: 720162.55007419852\n",
            "Iter: 1057 loss: 719831.92401136132\n",
            "tf.Tensor(\n",
            "[-0.00701071 -0.00573541 -0.00491084 ...  0.15231548  0.12425728\n",
            " -0.15917447], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8044524966293494\n",
            "Validation loss: 0.8534060786022046\n",
            "Iter: 1058 loss: 719677.96646925714\n",
            "Iter: 1059 loss: 719994.16139402543\n",
            "Iter: 1060 loss: 719616.35522708273\n",
            "Iter: 1061 loss: 719454.70854271518\n",
            "Iter: 1062 loss: 719764.63441780244\n",
            "Iter: 1063 loss: 719387.28493522\n",
            "Iter: 1064 loss: 719220.89395453723\n",
            "Iter: 1065 loss: 719942.31405303639\n",
            "Iter: 1066 loss: 719187.327253656\n",
            "Iter: 1067 loss: 719060.31395430851\n",
            "Iter: 1068 loss: 720824.03084271064\n",
            "Iter: 1069 loss: 719059.80961289245\n",
            "Iter: 1070 loss: 718960.6715690915\n",
            "Iter: 1071 loss: 718933.56791003188\n",
            "Iter: 1072 loss: 718872.65278996655\n",
            "tf.Tensor(\n",
            "[-0.00701948 -0.00590821 -0.00491817 ...  0.15403763  0.12577668\n",
            " -0.16013313], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.803480029691889\n",
            "Validation loss: 0.852758280994753\n",
            "Iter: 1073 loss: 718737.58522718959\n",
            "Iter: 1074 loss: 718860.97032591014\n",
            "Iter: 1075 loss: 718659.54972925875\n",
            "Iter: 1076 loss: 718498.33912156429\n",
            "Iter: 1077 loss: 718829.79087266861\n",
            "Iter: 1078 loss: 718434.03692560282\n",
            "Iter: 1079 loss: 718269.69449938519\n",
            "Iter: 1080 loss: 719021.93369096261\n",
            "Iter: 1081 loss: 718238.72309345065\n",
            "Iter: 1082 loss: 718096.3220248135\n",
            "Iter: 1083 loss: 718413.59976642393\n",
            "Iter: 1084 loss: 718042.40815433394\n",
            "Iter: 1085 loss: 717896.11225348187\n",
            "Iter: 1086 loss: 718434.33387599268\n",
            "Iter: 1087 loss: 717860.27006839064\n",
            "tf.Tensor(\n",
            "[-0.00702494 -0.00614688 -0.0049296  ...  0.15629519  0.12803199\n",
            " -0.16135682], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8023718313526906\n",
            "Validation loss: 0.8520350012480643\n",
            "Iter: 1088 loss: 717722.20570431871\n",
            "Iter: 1089 loss: 718177.06125397445\n",
            "Iter: 1090 loss: 717684.032718896\n",
            "Iter: 1091 loss: 717553.50081378431\n",
            "Iter: 1092 loss: 717753.45929387514\n",
            "Iter: 1093 loss: 717492.06375784753\n",
            "Iter: 1094 loss: 717351.84902671\n",
            "Iter: 1095 loss: 717712.0347729713\n",
            "Iter: 1096 loss: 717303.955658987\n",
            "Iter: 1097 loss: 717168.99558336055\n",
            "Iter: 1098 loss: 717494.45677337\n",
            "Iter: 1099 loss: 717120.65789057815\n",
            "Iter: 1100 loss: 716993.37803360843\n",
            "Iter: 1101 loss: 717838.53847085719\n",
            "Iter: 1102 loss: 716980.49832868762\n",
            "tf.Tensor(\n",
            "[-0.00705923 -0.00629149 -0.00493185 ...  0.15815206  0.12951818\n",
            " -0.16238641], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.801517889417603\n",
            "Validation loss: 0.8512328244166046\n",
            "Iter: 1103 loss: 716860.22718490392\n",
            "Iter: 1104 loss: 717548.80571333657\n",
            "Iter: 1105 loss: 716843.67025411024\n",
            "Iter: 1106 loss: 716751.72567410208\n",
            "Iter: 1107 loss: 716660.92315168364\n",
            "Iter: 1108 loss: 716641.68652731529\n",
            "Iter: 1109 loss: 716495.18404852273\n",
            "Iter: 1110 loss: 716855.585705209\n",
            "Iter: 1111 loss: 716443.53647085\n",
            "Iter: 1112 loss: 716288.80165841593\n",
            "Iter: 1113 loss: 716620.88509360584\n",
            "Iter: 1114 loss: 716228.89306267677\n",
            "Iter: 1115 loss: 716070.39437047055\n",
            "Iter: 1116 loss: 716534.00951439631\n",
            "Iter: 1117 loss: 716021.83559311589\n",
            "tf.Tensor(\n",
            "[-0.00714465 -0.00637794 -0.00491761 ...  0.16048466  0.13175463\n",
            " -0.16368793], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.8005833858018914\n",
            "Validation loss: 0.8504047856330813\n",
            "Iter: 1118 loss: 715870.68066473131\n",
            "Iter: 1119 loss: 716437.22032275551\n",
            "Iter: 1120 loss: 715834.4502914988\n",
            "Iter: 1121 loss: 715693.0416317007\n",
            "Iter: 1122 loss: 716121.91522725753\n",
            "Iter: 1123 loss: 715651.14581627154\n",
            "Iter: 1124 loss: 715510.84640245116\n",
            "Iter: 1125 loss: 715963.86679636745\n",
            "Iter: 1126 loss: 715471.28553844371\n",
            "Iter: 1127 loss: 715336.79015507479\n",
            "Iter: 1128 loss: 715591.91397295776\n",
            "Iter: 1129 loss: 715280.45707148744\n",
            "Iter: 1130 loss: 715141.70436549559\n",
            "Iter: 1131 loss: 715331.83809055376\n",
            "Iter: 1132 loss: 715072.91988698859\n",
            "tf.Tensor(\n",
            "[-0.00724601 -0.00635549 -0.00487881 ...  0.16278805  0.13355196\n",
            " -0.16478195], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7996395947291328\n",
            "Validation loss: 0.849701305839025\n",
            "Iter: 1133 loss: 714931.74321659212\n",
            "Iter: 1134 loss: 715535.289991955\n",
            "Iter: 1135 loss: 714902.61636606883\n",
            "Iter: 1136 loss: 714801.91833007312\n",
            "Iter: 1137 loss: 716248.45001332567\n",
            "Iter: 1138 loss: 714801.74763460085\n",
            "Iter: 1139 loss: 714708.07519866491\n",
            "Iter: 1140 loss: 714747.85973402369\n",
            "Iter: 1141 loss: 714643.69949728937\n",
            "Iter: 1142 loss: 714531.63091174676\n",
            "Iter: 1143 loss: 714529.23234968248\n",
            "Iter: 1144 loss: 714441.38087146392\n",
            "Iter: 1145 loss: 714295.51973826264\n",
            "Iter: 1146 loss: 714749.20887240954\n",
            "Iter: 1147 loss: 714253.19572442735\n",
            "tf.Tensor(\n",
            "[-0.00728574 -0.00625694 -0.00481917 ...  0.16464161  0.13547624\n",
            " -0.16545513], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7988375217040141\n",
            "Validation loss: 0.84910637610075\n",
            "Iter: 1148 loss: 714108.6383900363\n",
            "Iter: 1149 loss: 714436.02820563118\n",
            "Iter: 1150 loss: 714054.59625572164\n",
            "Iter: 1151 loss: 713906.73549444031\n",
            "Iter: 1152 loss: 714324.62127608841\n",
            "Iter: 1153 loss: 713860.06416823331\n",
            "Iter: 1154 loss: 713716.5654378183\n",
            "Iter: 1155 loss: 714147.84014580725\n",
            "Iter: 1156 loss: 713673.62602202431\n",
            "Iter: 1157 loss: 713530.74477863824\n",
            "Iter: 1158 loss: 714038.020947606\n",
            "Iter: 1159 loss: 713494.40092371334\n",
            "Iter: 1160 loss: 713362.07845901151\n",
            "Iter: 1161 loss: 713937.76196892664\n",
            "Iter: 1162 loss: 713335.12670707109\n",
            "tf.Tensor(\n",
            "[-0.00722661 -0.0060988  -0.00470829 ...  0.16691662  0.13745477\n",
            " -0.16638939], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.797854859386497\n",
            "Validation loss: 0.8485995810427773\n",
            "Iter: 1163 loss: 713219.0035379359\n",
            "Iter: 1164 loss: 713408.76754946739\n",
            "Iter: 1165 loss: 713166.0328031946\n",
            "Iter: 1166 loss: 713042.92600070883\n",
            "Iter: 1167 loss: 713255.47709993331\n",
            "Iter: 1168 loss: 712988.33183068142\n",
            "Iter: 1169 loss: 712857.05699393945\n",
            "Iter: 1170 loss: 713213.30271546415\n",
            "Iter: 1171 loss: 712814.1069395676\n",
            "Iter: 1172 loss: 712725.38318776828\n",
            "Iter: 1173 loss: 712723.77361984993\n",
            "Iter: 1174 loss: 712644.2133828958\n",
            "Iter: 1175 loss: 712578.84726456529\n",
            "Iter: 1176 loss: 712555.71977725555\n",
            "tf.Tensor(\n",
            "[-0.00710272 -0.0059424  -0.00456854 ...  0.16895257  0.13949515\n",
            " -0.16724285], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7969942319132564\n",
            "Validation loss: 0.8484392927840416\n",
            "Iter: 1177 loss: 712437.05045076949\n",
            "Iter: 1178 loss: 712430.87157098844\n",
            "Iter: 1179 loss: 712340.51412850572\n",
            "Iter: 1180 loss: 712185.33986994787\n",
            "Iter: 1181 loss: 712617.86418445\n",
            "Iter: 1182 loss: 712135.70629472251\n",
            "Iter: 1183 loss: 711985.34898328246\n",
            "Iter: 1184 loss: 712457.15615087538\n",
            "Iter: 1185 loss: 711942.03877426\n",
            "Iter: 1186 loss: 711794.41010853928\n",
            "Iter: 1187 loss: 712315.5676122423\n",
            "Iter: 1188 loss: 711756.56733306509\n",
            "Iter: 1189 loss: 711625.66576321109\n",
            "Iter: 1190 loss: 711876.98959164368\n",
            "Iter: 1191 loss: 711571.06854982092\n",
            "tf.Tensor(\n",
            "[-0.00693321 -0.00574173 -0.00433986 ...  0.17182771  0.14205676\n",
            " -0.16809725], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7958315644187716\n",
            "Validation loss: 0.8479471707494469\n",
            "Iter: 1192 loss: 711428.41578273452\n",
            "Iter: 1193 loss: 711832.43054577429\n",
            "Iter: 1194 loss: 711383.37912604271\n",
            "Iter: 1195 loss: 711250.44356166339\n",
            "Iter: 1196 loss: 711641.98608812666\n",
            "Iter: 1197 loss: 711209.86164121132\n",
            "Iter: 1198 loss: 711087.0125744181\n",
            "Iter: 1199 loss: 711712.31367793446\n",
            "Iter: 1200 loss: 711067.0624007202\n",
            "Iter: 1201 loss: 710955.00429375877\n",
            "Iter: 1202 loss: 711368.57616479241\n",
            "Iter: 1203 loss: 710927.343565941\n",
            "Iter: 1204 loss: 710823.92673668882\n",
            "Iter: 1205 loss: 710946.02346627624\n",
            "Iter: 1206 loss: 710769.25662732229\n",
            "tf.Tensor(\n",
            "[-0.00682574 -0.00554154 -0.00410378 ...  0.17429421  0.14426291\n",
            " -0.16868735], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7948710578338981\n",
            "Validation loss: 0.8476464466331327\n",
            "Iter: 1207 loss: 710682.07463388122\n",
            "Iter: 1208 loss: 711998.76379312587\n",
            "Iter: 1209 loss: 710682.03557593632\n",
            "Iter: 1210 loss: 710598.52227697207\n",
            "Iter: 1211 loss: 710556.176491761\n",
            "Iter: 1212 loss: 710517.1393376824\n",
            "Iter: 1213 loss: 710415.11728904\n",
            "Iter: 1214 loss: 710401.155755659\n",
            "Iter: 1215 loss: 710329.25402126322\n",
            "Iter: 1216 loss: 710195.77143660758\n",
            "Iter: 1217 loss: 710783.95398320386\n",
            "Iter: 1218 loss: 710169.22465961892\n",
            "Iter: 1219 loss: 710045.358439534\n",
            "Iter: 1220 loss: 710326.11579623574\n",
            "Iter: 1221 loss: 709998.8780146729\n",
            "tf.Tensor(\n",
            "[-0.00672292 -0.00533108 -0.00383427 ...  0.17665063  0.14652108\n",
            " -0.16936509], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7939415858675213\n",
            "Validation loss: 0.8470033797176763\n",
            "Iter: 1222 loss: 709874.4745325197\n",
            "Iter: 1223 loss: 710093.23951948958\n",
            "Iter: 1224 loss: 709819.849473227\n",
            "Iter: 1225 loss: 709693.09319906041\n",
            "Iter: 1226 loss: 710121.25054023881\n",
            "Iter: 1227 loss: 709658.98422497243\n",
            "Iter: 1228 loss: 709531.31450310408\n",
            "Iter: 1229 loss: 709847.96597938519\n",
            "Iter: 1230 loss: 709486.45525084762\n",
            "Iter: 1231 loss: 709357.324154792\n",
            "Iter: 1232 loss: 709726.25921432488\n",
            "Iter: 1233 loss: 709316.7206204317\n",
            "Iter: 1234 loss: 709194.37730184349\n",
            "Iter: 1235 loss: 709693.369367295\n",
            "Iter: 1236 loss: 709167.56874900742\n",
            "tf.Tensor(\n",
            "[-0.00653259 -0.0051021  -0.00349412 ...  0.17927721  0.14883461\n",
            " -0.1703002 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7929408614540859\n",
            "Validation loss: 0.8466389055357475\n",
            "Iter: 1237 loss: 709060.28575384663\n",
            "Iter: 1238 loss: 709655.12541708676\n",
            "Iter: 1239 loss: 709044.803151097\n",
            "Iter: 1240 loss: 708947.281748674\n",
            "Iter: 1241 loss: 709162.862025079\n",
            "Iter: 1242 loss: 708910.04476211837\n",
            "Iter: 1243 loss: 708829.00476976542\n",
            "Iter: 1244 loss: 709721.31573483837\n",
            "Iter: 1245 loss: 708827.33659658639\n",
            "Iter: 1246 loss: 708754.68152973044\n",
            "Iter: 1247 loss: 708689.455129487\n",
            "Iter: 1248 loss: 708671.12461444852\n",
            "Iter: 1249 loss: 708567.30351145077\n",
            "Iter: 1250 loss: 708651.84601588745\n",
            "Iter: 1251 loss: 708505.13422418386\n",
            "tf.Tensor(\n",
            "[-0.00633233 -0.00491992 -0.00319781 ...  0.18147507  0.15110195\n",
            " -0.1711683 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7921493466857767\n",
            "Validation loss: 0.8461321016956233\n",
            "Iter: 1252 loss: 708385.4377891128\n",
            "Iter: 1253 loss: 708754.7999719592\n",
            "Iter: 1254 loss: 708350.25409720629\n",
            "Iter: 1255 loss: 708235.53856409562\n",
            "Iter: 1256 loss: 708460.2432143531\n",
            "Iter: 1257 loss: 708188.10170038592\n",
            "Iter: 1258 loss: 708066.4314326609\n",
            "Iter: 1259 loss: 708474.77712348325\n",
            "Iter: 1260 loss: 708033.411683255\n",
            "Iter: 1261 loss: 707913.583657248\n",
            "Iter: 1262 loss: 708191.70656095562\n",
            "Iter: 1263 loss: 707869.26546814991\n",
            "Iter: 1264 loss: 707750.30193171336\n",
            "Iter: 1265 loss: 707982.7335854813\n",
            "Iter: 1266 loss: 707701.07035582524\n",
            "tf.Tensor(\n",
            "[-0.00605277 -0.00473989 -0.00281034 ...  0.18443496  0.15349462\n",
            " -0.17225932], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7911249494406295\n",
            "Validation loss: 0.8459584530088667\n",
            "Iter: 1267 loss: 707576.97887315054\n",
            "Iter: 1268 loss: 708037.09504558065\n",
            "Iter: 1269 loss: 707546.555198928\n",
            "Iter: 1270 loss: 707429.39584693511\n",
            "Iter: 1271 loss: 707796.57598312583\n",
            "Iter: 1272 loss: 707395.44345976575\n",
            "Iter: 1273 loss: 707286.2771128962\n",
            "Iter: 1274 loss: 707847.39377264539\n",
            "Iter: 1275 loss: 707268.53524269443\n",
            "Iter: 1276 loss: 707173.70655882149\n",
            "Iter: 1277 loss: 707743.67781611136\n",
            "Iter: 1278 loss: 707161.85740468919\n",
            "Iter: 1279 loss: 707089.63875502546\n",
            "Iter: 1280 loss: 707451.71439844859\n",
            "Iter: 1281 loss: 707077.55830485572\n",
            "tf.Tensor(\n",
            "[-0.00581944 -0.00468024 -0.00249555 ...  0.18690364  0.15589632\n",
            " -0.17322766], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7902969406740485\n",
            "Validation loss: 0.84559422228852\n",
            "Iter: 1282 loss: 707006.647800676\n",
            "Iter: 1283 loss: 706993.06306676276\n",
            "Iter: 1284 loss: 706945.63518735336\n",
            "Iter: 1285 loss: 706856.18223702942\n",
            "Iter: 1286 loss: 706876.76179891266\n",
            "Iter: 1287 loss: 706790.43383993837\n",
            "Iter: 1288 loss: 706678.60581125924\n",
            "Iter: 1289 loss: 706986.91615293373\n",
            "Iter: 1290 loss: 706642.29487094423\n",
            "Iter: 1291 loss: 706528.76278597431\n",
            "Iter: 1292 loss: 706851.26027533785\n",
            "Iter: 1293 loss: 706492.77052160713\n",
            "Iter: 1294 loss: 706380.6175573091\n",
            "Iter: 1295 loss: 706643.98361370491\n",
            "Iter: 1296 loss: 706339.37846736121\n",
            "tf.Tensor(\n",
            "[-0.00546182 -0.00471123 -0.00209466 ...  0.19006061  0.15851794\n",
            " -0.17456362], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7892825088730431\n",
            "Validation loss: 0.845103039559442\n",
            "Iter: 1297 loss: 706225.71111599007\n",
            "Iter: 1298 loss: 706624.33358502656\n",
            "Iter: 1299 loss: 706196.06318553747\n",
            "Iter: 1300 loss: 706087.91081427166\n",
            "Iter: 1301 loss: 706354.69954413385\n",
            "Iter: 1302 loss: 706049.5095546504\n",
            "Iter: 1303 loss: 705937.23921245057\n",
            "Iter: 1304 loss: 706183.26055211469\n",
            "Iter: 1305 loss: 705893.94186622428\n",
            "Iter: 1306 loss: 705781.631976721\n",
            "Iter: 1307 loss: 706111.42455287348\n",
            "Iter: 1308 loss: 705747.00034760055\n",
            "Iter: 1309 loss: 705647.49093385017\n",
            "Iter: 1310 loss: 706463.76869924681\n",
            "Iter: 1311 loss: 705641.188376537\n",
            "tf.Tensor(\n",
            "[-0.0050721  -0.00479789 -0.00170932 ...  0.19311513  0.16134943\n",
            " -0.17582514], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7882956964494844\n",
            "Validation loss: 0.8448008871887402\n",
            "Iter: 1312 loss: 705556.414057307\n",
            "Iter: 1313 loss: 706007.44730840088\n",
            "Iter: 1314 loss: 705543.32038365037\n",
            "Iter: 1315 loss: 705472.37764846778\n",
            "Iter: 1316 loss: 705699.46978201717\n",
            "Iter: 1317 loss: 705452.17599739926\n",
            "Iter: 1318 loss: 705381.12516052625\n",
            "Iter: 1319 loss: 705370.81936569232\n",
            "Iter: 1320 loss: 705321.04944262025\n",
            "Iter: 1321 loss: 705227.087123551\n",
            "Iter: 1322 loss: 705321.10659591539\n",
            "Iter: 1323 loss: 705174.11095874861\n",
            "Iter: 1324 loss: 705064.34316137491\n",
            "Iter: 1325 loss: 705325.6767507568\n",
            "Iter: 1326 loss: 705024.45815671887\n",
            "tf.Tensor(\n",
            "[-0.0046943  -0.00487223 -0.00136456 ...  0.19593511  0.16395813\n",
            " -0.17687226], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7873824573337624\n",
            "Validation loss: 0.8442891891921462\n",
            "Iter: 1327 loss: 704914.3066032317\n",
            "Iter: 1328 loss: 705209.855094743\n",
            "Iter: 1329 loss: 704877.66884759045\n",
            "Iter: 1330 loss: 704770.4138369977\n",
            "Iter: 1331 loss: 705009.597499009\n",
            "Iter: 1332 loss: 704729.520571245\n",
            "Iter: 1333 loss: 704619.58215901419\n",
            "Iter: 1334 loss: 705162.45612481574\n",
            "Iter: 1335 loss: 704600.71562392043\n",
            "Iter: 1336 loss: 704504.94125378458\n",
            "Iter: 1337 loss: 704663.82950091362\n",
            "Iter: 1338 loss: 704461.3142070364\n",
            "Iter: 1339 loss: 704355.86248775886\n",
            "Iter: 1340 loss: 704590.21933522\n",
            "Iter: 1341 loss: 704315.55950551142\n",
            "tf.Tensor(\n",
            "[-0.00419013 -0.00491293 -0.00095646 ...  0.19943626  0.16691161\n",
            " -0.17824269], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7862938517665234\n",
            "Validation loss: 0.8439423506084628\n",
            "Iter: 1342 loss: 704207.45696564415\n",
            "Iter: 1343 loss: 704667.49480395764\n",
            "Iter: 1344 loss: 704184.78013912868\n",
            "Iter: 1345 loss: 704096.69218134577\n",
            "Iter: 1346 loss: 704788.63447027048\n",
            "Iter: 1347 loss: 704090.48690217617\n",
            "Iter: 1348 loss: 704012.3714767982\n",
            "Iter: 1349 loss: 704368.318210846\n",
            "Iter: 1350 loss: 703997.28965993423\n",
            "Iter: 1351 loss: 703930.65517299611\n",
            "Iter: 1352 loss: 704018.65694450412\n",
            "Iter: 1353 loss: 703896.853054797\n",
            "Iter: 1354 loss: 703817.32657097513\n",
            "Iter: 1355 loss: 703913.79251100088\n",
            "Iter: 1356 loss: 703775.57010504906\n",
            "tf.Tensor(\n",
            "[-0.00378286 -0.00491793 -0.00063651 ...  0.20230031  0.16955092\n",
            " -0.1793854 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7855001516783195\n",
            "Validation loss: 0.8437995369361454\n",
            "Iter: 1357 loss: 703691.06558777415\n",
            "Iter: 1358 loss: 703715.27534047351\n",
            "Iter: 1359 loss: 703630.1228347955\n",
            "Iter: 1360 loss: 703521.73281720723\n",
            "Iter: 1361 loss: 703910.063600616\n",
            "Iter: 1362 loss: 703494.12220937537\n",
            "Iter: 1363 loss: 703392.30840966129\n",
            "Iter: 1364 loss: 703577.5663199916\n",
            "Iter: 1365 loss: 703348.2678547469\n",
            "Iter: 1366 loss: 703238.92581291578\n",
            "Iter: 1367 loss: 703556.16053838632\n",
            "Iter: 1368 loss: 703204.78433180472\n",
            "Iter: 1369 loss: 703093.20906998252\n",
            "Iter: 1370 loss: 703358.64231810684\n",
            "Iter: 1371 loss: 703052.572302483\n",
            "tf.Tensor(\n",
            "[-3.30342152e-03 -4.94025772e-03 -1.92928498e-04 ...  2.06338395e-01\n",
            "  1.72757681e-01 -1.80741694e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7844514722951084\n",
            "Validation loss: 0.8433873731775835\n",
            "Iter: 1372 loss: 702943.90903243551\n",
            "Iter: 1373 loss: 703413.786165402\n",
            "Iter: 1374 loss: 702921.52822970471\n",
            "Iter: 1375 loss: 702816.48866710952\n",
            "Iter: 1376 loss: 703064.65072882292\n",
            "Iter: 1377 loss: 702777.964728394\n",
            "Iter: 1378 loss: 702677.59846979473\n",
            "Iter: 1379 loss: 702937.21099115245\n",
            "Iter: 1380 loss: 702643.2494548877\n",
            "Iter: 1381 loss: 702563.61104764545\n",
            "Iter: 1382 loss: 702563.56480185851\n",
            "Iter: 1383 loss: 702496.067835822\n",
            "Iter: 1384 loss: 702550.603596738\n",
            "Iter: 1385 loss: 702455.44110832922\n",
            "tf.Tensor(\n",
            "[-3.02509043e-03 -4.98861607e-03  1.82057079e-04 ...  2.09796661e-01\n",
            "  1.75894813e-01 -1.81910965e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7835627781557579\n",
            "Validation loss: 0.8431323129297579\n",
            "Iter: 1386 loss: 702378.0110432267\n",
            "Iter: 1387 loss: 702558.5079923626\n",
            "Iter: 1388 loss: 702349.372123901\n",
            "Iter: 1389 loss: 702268.42848566279\n",
            "Iter: 1390 loss: 702370.216847384\n",
            "Iter: 1391 loss: 702226.59617204743\n",
            "Iter: 1392 loss: 702138.366546279\n",
            "Iter: 1393 loss: 702191.25797837041\n",
            "Iter: 1394 loss: 702081.37076910434\n",
            "Iter: 1395 loss: 701975.37535922322\n",
            "Iter: 1396 loss: 702301.941754172\n",
            "Iter: 1397 loss: 701944.13840863248\n",
            "Iter: 1398 loss: 701840.12567416718\n",
            "Iter: 1399 loss: 702105.02689461655\n",
            "Iter: 1400 loss: 701804.16863886686\n",
            "tf.Tensor(\n",
            "[-0.00283167 -0.00506677  0.00056453 ...  0.21348782  0.17909643\n",
            " -0.18325265], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.782620217700105\n",
            "Validation loss: 0.8429211690183457\n",
            "Iter: 1401 loss: 701701.69695456361\n",
            "Iter: 1402 loss: 701982.08547272871\n",
            "Iter: 1403 loss: 701668.16551253072\n",
            "Iter: 1404 loss: 701561.71837671567\n",
            "Iter: 1405 loss: 701895.67721792427\n",
            "Iter: 1406 loss: 701530.82596844563\n",
            "Iter: 1407 loss: 701425.64141315792\n",
            "Iter: 1408 loss: 701663.63133649318\n",
            "Iter: 1409 loss: 701385.9347638461\n",
            "Iter: 1410 loss: 701280.523584887\n",
            "Iter: 1411 loss: 701597.08037784474\n",
            "Iter: 1412 loss: 701248.68986474164\n",
            "Iter: 1413 loss: 701143.52496607392\n",
            "Iter: 1414 loss: 701671.54631853919\n",
            "Iter: 1415 loss: 701125.8683317824\n",
            "tf.Tensor(\n",
            "[-0.00261822 -0.00514998  0.00095697 ...  0.2176109   0.18271035\n",
            " -0.18462223], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7816334992982743\n",
            "Validation loss: 0.8427579121293863\n",
            "Iter: 1416 loss: 701043.85246371548\n",
            "Iter: 1417 loss: 702006.0449482383\n",
            "Iter: 1418 loss: 701042.70542264066\n",
            "Iter: 1419 loss: 700981.72025167732\n",
            "Iter: 1420 loss: 700952.0579904652\n",
            "Iter: 1421 loss: 700922.73191430664\n",
            "Iter: 1422 loss: 700834.62588959932\n",
            "Iter: 1423 loss: 701131.44276300387\n",
            "Iter: 1424 loss: 700810.72555217671\n",
            "Iter: 1425 loss: 700723.60658272123\n",
            "Iter: 1426 loss: 700840.97774538444\n",
            "Iter: 1427 loss: 700679.89367059874\n",
            "Iter: 1428 loss: 700586.94246576214\n",
            "Iter: 1429 loss: 700681.69949715771\n",
            "Iter: 1430 loss: 700534.92592996871\n",
            "tf.Tensor(\n",
            "[-0.00240469 -0.00520072  0.00127981 ...  0.22135737  0.18606803\n",
            " -0.18564079], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7807477136469028\n",
            "Validation loss: 0.8423516944788143\n",
            "Iter: 1431 loss: 700423.633117306\n",
            "Iter: 1432 loss: 700705.44435798738\n",
            "Iter: 1433 loss: 700384.98904461681\n",
            "Iter: 1434 loss: 700272.78538204823\n",
            "Iter: 1435 loss: 700530.42096256325\n",
            "Iter: 1436 loss: 700230.94723223732\n",
            "Iter: 1437 loss: 700116.48129384243\n",
            "Iter: 1438 loss: 700347.974651651\n",
            "Iter: 1439 loss: 700070.050758481\n",
            "Iter: 1440 loss: 699951.535455911\n",
            "Iter: 1441 loss: 700511.79155368824\n",
            "Iter: 1442 loss: 699929.99867985433\n",
            "Iter: 1443 loss: 699821.484211047\n",
            "Iter: 1444 loss: 700126.08566593577\n",
            "Iter: 1445 loss: 699786.79011908884\n",
            "tf.Tensor(\n",
            "[-0.00214906 -0.00524152  0.00166133 ...  0.22632     0.19008123\n",
            " -0.18716532], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.779613572726593\n",
            "Validation loss: 0.841910355274734\n",
            "Iter: 1446 loss: 699682.60071725561\n",
            "Iter: 1447 loss: 699944.47127075132\n",
            "Iter: 1448 loss: 699646.21663740522\n",
            "Iter: 1449 loss: 699563.97157221672\n",
            "Iter: 1450 loss: 700680.03056535427\n",
            "Iter: 1451 loss: 699563.58179054328\n",
            "Iter: 1452 loss: 699488.81665370264\n",
            "Iter: 1453 loss: 699600.30735167966\n",
            "Iter: 1454 loss: 699452.98132261564\n",
            "Iter: 1455 loss: 699377.797215165\n",
            "Iter: 1456 loss: 699434.38114148518\n",
            "Iter: 1457 loss: 699331.82202699315\n",
            "Iter: 1458 loss: 699240.147223608\n",
            "Iter: 1459 loss: 699561.24038891448\n",
            "Iter: 1460 loss: 699216.29578189063\n",
            "tf.Tensor(\n",
            "[-0.00198597 -0.00526727  0.00193889 ...  0.23028708  0.19365646\n",
            " -0.18843357], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7787380316574066\n",
            "Validation loss: 0.8417301185207374\n",
            "Iter: 1461 loss: 699128.637762042\n",
            "Iter: 1462 loss: 699205.66511996009\n",
            "Iter: 1463 loss: 699077.33100109908\n",
            "Iter: 1464 loss: 698975.22859961446\n",
            "Iter: 1465 loss: 699128.53854982334\n",
            "Iter: 1466 loss: 698926.47142457706\n",
            "Iter: 1467 loss: 698812.6434428785\n",
            "Iter: 1468 loss: 699101.3090249314\n",
            "Iter: 1469 loss: 698773.21995034383\n",
            "Iter: 1470 loss: 698657.64502293861\n",
            "Iter: 1471 loss: 698970.21908166457\n",
            "Iter: 1472 loss: 698619.59345767146\n",
            "Iter: 1473 loss: 698504.48557300691\n",
            "Iter: 1474 loss: 698715.607447179\n",
            "Iter: 1475 loss: 698455.06965431268\n",
            "tf.Tensor(\n",
            "[-0.00181934 -0.00531884  0.00227629 ...  0.23558329  0.19817038\n",
            " -0.18991677], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7776128547795581\n",
            "Validation loss: 0.8411972413780594\n",
            "Iter: 1476 loss: 698334.55166133714\n",
            "Iter: 1477 loss: 698706.65060283337\n",
            "Iter: 1478 loss: 698299.1670075492\n",
            "Iter: 1479 loss: 698183.76994017861\n",
            "Iter: 1480 loss: 698730.76084588142\n",
            "Iter: 1481 loss: 698162.88461459184\n",
            "Iter: 1482 loss: 698062.98722033086\n",
            "Iter: 1483 loss: 698440.067668847\n",
            "Iter: 1484 loss: 698038.99078739563\n",
            "Iter: 1485 loss: 697955.74559881759\n",
            "Iter: 1486 loss: 698964.4137628\n",
            "Iter: 1487 loss: 697954.69807945169\n",
            "Iter: 1488 loss: 697888.66478171374\n",
            "Iter: 1489 loss: 697840.86351904715\n",
            "Iter: 1490 loss: 697818.1840584965\n",
            "tf.Tensor(\n",
            "[-0.00169095 -0.00536661  0.00252046 ...  0.23995293  0.20207591\n",
            " -0.1911868 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7767491555704775\n",
            "Validation loss: 0.8411271302071828\n",
            "Iter: 1491 loss: 697726.12559529173\n",
            "Iter: 1492 loss: 698018.9119780201\n",
            "Iter: 1493 loss: 697699.8728678195\n",
            "Iter: 1494 loss: 697604.4837989338\n",
            "Iter: 1495 loss: 697831.27682312636\n",
            "Iter: 1496 loss: 697569.82308433973\n",
            "Iter: 1497 loss: 697473.38252465008\n",
            "Iter: 1498 loss: 697591.69180648227\n",
            "Iter: 1499 loss: 697423.14528708276\n",
            "Iter: 1500 loss: 697316.77677783824\n",
            "Iter: 1501 loss: 697472.00342130417\n",
            "Iter: 1502 loss: 697265.33384418534\n",
            "Iter: 1503 loss: 697146.88621313206\n",
            "Iter: 1504 loss: 697441.07370753109\n",
            "Iter: 1505 loss: 697105.28816254379\n",
            "tf.Tensor(\n",
            "[-0.00149428 -0.00539017  0.00277417 ...  0.24530196  0.20688386\n",
            " -0.19288112], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7757874781775662\n",
            "Validation loss: 0.8408268904803162\n",
            "Iter: 1506 loss: 696984.22009952331\n",
            "Iter: 1507 loss: 697310.21329542855\n",
            "Iter: 1508 loss: 696944.22712015419\n",
            "Iter: 1509 loss: 696821.52738960192\n",
            "Iter: 1510 loss: 697174.17580078612\n",
            "Iter: 1511 loss: 696783.19273433031\n",
            "Iter: 1512 loss: 696662.051850096\n",
            "Iter: 1513 loss: 696908.08321648743\n",
            "Iter: 1514 loss: 696613.19114486792\n",
            "Iter: 1515 loss: 696495.59407459991\n",
            "Iter: 1516 loss: 697017.93944851577\n",
            "Iter: 1517 loss: 696472.39741508337\n",
            "Iter: 1518 loss: 696378.93233777874\n",
            "Iter: 1519 loss: 697339.35902425461\n",
            "Iter: 1520 loss: 696376.26263680367\n",
            "tf.Tensor(\n",
            "[-0.00125517 -0.00536464  0.00298029 ...  0.25085977  0.21148704\n",
            " -0.19443196], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7748573671836796\n",
            "Validation loss: 0.8401875942112746\n",
            "Iter: 1521 loss: 696291.30106732983\n",
            "Iter: 1522 loss: 696529.67225083639\n",
            "Iter: 1523 loss: 696264.1413315041\n",
            "Iter: 1524 loss: 696190.39830293588\n",
            "Iter: 1525 loss: 696160.59157798381\n",
            "Iter: 1526 loss: 696121.41540334013\n",
            "Iter: 1527 loss: 696016.81872119848\n",
            "Iter: 1528 loss: 696477.31316216686\n",
            "Iter: 1529 loss: 695995.99809134041\n",
            "Iter: 1530 loss: 695899.766778507\n",
            "Iter: 1531 loss: 696089.495510812\n",
            "Iter: 1532 loss: 695860.2071708946\n",
            "Iter: 1533 loss: 695757.66993549769\n",
            "Iter: 1534 loss: 695900.53868963337\n",
            "Iter: 1535 loss: 695707.10362638114\n",
            "tf.Tensor(\n",
            "[-0.00105955 -0.00531299  0.00312217 ...  0.2560225   0.21613521\n",
            " -0.19571211], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7740630765492343\n",
            "Validation loss: 0.8400406822601874\n",
            "Iter: 1536 loss: 695593.04528740421\n",
            "Iter: 1537 loss: 695740.39929331536\n",
            "Iter: 1538 loss: 695534.86035013257\n",
            "Iter: 1539 loss: 695407.84660558752\n",
            "Iter: 1540 loss: 695689.95509585924\n",
            "Iter: 1541 loss: 695359.58427650784\n",
            "Iter: 1542 loss: 695227.788799972\n",
            "Iter: 1543 loss: 695590.75504596578\n",
            "Iter: 1544 loss: 695185.08831844316\n",
            "Iter: 1545 loss: 695056.42117601226\n",
            "Iter: 1546 loss: 695535.9524512589\n",
            "Iter: 1547 loss: 695025.28052090143\n",
            "Iter: 1548 loss: 694901.33376134757\n",
            "Iter: 1549 loss: 695150.46246785659\n",
            "Iter: 1550 loss: 694851.02401145152\n",
            "tf.Tensor(\n",
            "[-0.00089935 -0.00525693  0.00325017 ...  0.26278088  0.22181908\n",
            " -0.19752136], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7730558901207033\n",
            "Validation loss: 0.8396181160413083\n",
            "Iter: 1551 loss: 694729.2041963652\n",
            "Iter: 1552 loss: 695303.51091346133\n",
            "Iter: 1553 loss: 694707.03083026269\n",
            "Iter: 1554 loss: 694621.81573571754\n",
            "Iter: 1555 loss: 694621.69248866662\n",
            "Iter: 1556 loss: 694555.82291292\n",
            "Iter: 1557 loss: 694485.78854469338\n",
            "Iter: 1558 loss: 694474.26635128621\n",
            "Iter: 1559 loss: 694368.01030737918\n",
            "Iter: 1560 loss: 694612.14691728086\n",
            "Iter: 1561 loss: 694328.44450392155\n",
            "Iter: 1562 loss: 694216.03455401643\n",
            "Iter: 1563 loss: 694595.50038205832\n",
            "Iter: 1564 loss: 694185.82781795808\n",
            "tf.Tensor(\n",
            "[-0.00084998 -0.00523071  0.00330322 ...  0.26783523  0.22632162\n",
            " -0.19884427], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7723023619124466\n",
            "Validation loss: 0.8393504705665336\n",
            "Iter: 1565 loss: 694079.6357535345\n",
            "Iter: 1566 loss: 694266.84730544337\n",
            "Iter: 1567 loss: 694033.07557806047\n",
            "Iter: 1568 loss: 693919.751842913\n",
            "Iter: 1569 loss: 694117.30211942014\n",
            "Iter: 1570 loss: 693869.78871860425\n",
            "Iter: 1571 loss: 693747.89038837433\n",
            "Iter: 1572 loss: 693900.8137661108\n",
            "Iter: 1573 loss: 693685.03426527092\n",
            "Iter: 1574 loss: 693550.092793127\n",
            "Iter: 1575 loss: 693909.48154045444\n",
            "Iter: 1576 loss: 693505.24379196262\n",
            "Iter: 1577 loss: 693371.52208295639\n",
            "Iter: 1578 loss: 693715.0704595719\n",
            "Iter: 1579 loss: 693325.78594111616\n",
            "tf.Tensor(\n",
            "[-0.00083164 -0.00518652  0.00332301 ...  0.27453496  0.23239527\n",
            " -0.20031412], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7713340981130767\n",
            "Validation loss: 0.8390938116540628\n",
            "Iter: 1580 loss: 693188.148761455\n",
            "Iter: 1581 loss: 693541.476761108\n",
            "Iter: 1582 loss: 693141.08363117918\n",
            "Iter: 1583 loss: 693004.17979219463\n",
            "Iter: 1584 loss: 693504.48330499686\n",
            "Iter: 1585 loss: 692970.1865024718\n",
            "Iter: 1586 loss: 692861.80238001875\n",
            "Iter: 1587 loss: 693944.68919728661\n",
            "Iter: 1588 loss: 692858.22003595694\n",
            "Iter: 1589 loss: 692759.66313176125\n",
            "Iter: 1590 loss: 693178.13754242694\n",
            "Iter: 1591 loss: 692739.01970376738\n",
            "Iter: 1592 loss: 692666.12008353451\n",
            "Iter: 1593 loss: 692585.57382239436\n",
            "Iter: 1594 loss: 692574.09422848013\n",
            "tf.Tensor(\n",
            "[-0.00083995 -0.00509933  0.00329427 ...  0.28079366  0.23768808\n",
            " -0.20161473], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7704917114488202\n",
            "Validation loss: 0.8386069851022324\n",
            "Iter: 1595 loss: 692457.9600417919\n",
            "Iter: 1596 loss: 693126.67812916148\n",
            "Iter: 1597 loss: 692442.37733023788\n",
            "Iter: 1598 loss: 692337.19357243739\n",
            "Iter: 1599 loss: 692527.55958980648\n",
            "Iter: 1600 loss: 692291.76501210441\n",
            "Iter: 1601 loss: 692179.16457138222\n",
            "Iter: 1602 loss: 692351.47693599551\n",
            "Iter: 1603 loss: 692125.97999389237\n",
            "Iter: 1604 loss: 691998.853473462\n",
            "Iter: 1605 loss: 692247.21065653092\n",
            "Iter: 1606 loss: 691946.32558391767\n",
            "Iter: 1607 loss: 691809.39261360175\n",
            "Iter: 1608 loss: 692029.51603267482\n",
            "Iter: 1609 loss: 691746.30891505384\n",
            "tf.Tensor(\n",
            "[-0.00086734 -0.00492181  0.00321896 ...  0.28768835  0.24387205\n",
            " -0.20298348], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7696115034977578\n",
            "Validation loss: 0.8384319028266898\n",
            "Iter: 1610 loss: 691606.74547180382\n",
            "Iter: 1611 loss: 692000.16958608082\n",
            "Iter: 1612 loss: 691562.483986187\n",
            "Iter: 1613 loss: 691424.21746771992\n",
            "Iter: 1614 loss: 691845.054637025\n",
            "Iter: 1615 loss: 691383.08127534576\n",
            "Iter: 1616 loss: 691245.581621214\n",
            "Iter: 1617 loss: 691525.48580692289\n",
            "Iter: 1618 loss: 691190.20862612873\n",
            "Iter: 1619 loss: 691056.78098486294\n",
            "Iter: 1620 loss: 691655.70533337491\n",
            "Iter: 1621 loss: 691030.72532509244\n",
            "Iter: 1622 loss: 690946.251231807\n",
            "Iter: 1623 loss: 690943.70434358332\n",
            "tf.Tensor(\n",
            "[-0.00091358 -0.00468139  0.00311401 ...  0.29457011  0.24959013\n",
            " -0.20415416], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7687835310578517\n",
            "Validation loss: 0.8381664264120527\n",
            "Iter: 1624 loss: 690876.10292833787\n",
            "Iter: 1625 loss: 690789.15045641537\n",
            "Iter: 1626 loss: 690783.05058212567\n",
            "Iter: 1627 loss: 690670.07790730114\n",
            "Iter: 1628 loss: 690856.92341446667\n",
            "Iter: 1629 loss: 690618.83631525538\n",
            "Iter: 1630 loss: 690500.0645247146\n",
            "Iter: 1631 loss: 691060.05682017864\n",
            "Iter: 1632 loss: 690478.40774346713\n",
            "Iter: 1633 loss: 690370.60981343058\n",
            "Iter: 1634 loss: 690615.42805520608\n",
            "Iter: 1635 loss: 690330.1985059547\n",
            "Iter: 1636 loss: 690219.43225854414\n",
            "Iter: 1637 loss: 690318.92142887879\n",
            "Iter: 1638 loss: 690155.08975674957\n",
            "tf.Tensor(\n",
            "[-0.00097892 -0.00440705  0.00298086 ...  0.30119766  0.25536379\n",
            " -0.2051383 ], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7680038424302239\n",
            "Validation loss: 0.8380134116783533\n",
            "Iter: 1639 loss: 690024.24797126651\n",
            "Iter: 1640 loss: 690309.72249475226\n",
            "Iter: 1641 loss: 689973.83487547212\n",
            "Iter: 1642 loss: 689841.00888650864\n",
            "Iter: 1643 loss: 690247.89712281607\n",
            "Iter: 1644 loss: 689801.82225358649\n",
            "Iter: 1645 loss: 689669.44553906913\n",
            "Iter: 1646 loss: 689883.69893911644\n",
            "Iter: 1647 loss: 689608.58126196638\n",
            "Iter: 1648 loss: 689468.62195053743\n",
            "Iter: 1649 loss: 689875.5592448184\n",
            "Iter: 1650 loss: 689425.37835910951\n",
            "Iter: 1651 loss: 689289.36468792439\n",
            "Iter: 1652 loss: 689692.33731116191\n",
            "Iter: 1653 loss: 689247.94517269381\n",
            "tf.Tensor(\n",
            "[-0.00105329 -0.00405813  0.00279413 ...  0.30905631  0.26241168\n",
            " -0.20632068], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7671101663627146\n",
            "Validation loss: 0.8376950888052809\n",
            "Iter: 1654 loss: 689139.23802249122\n",
            "Iter: 1655 loss: 690119.347181447\n",
            "Iter: 1656 loss: 689134.13396780856\n",
            "Iter: 1657 loss: 689026.79579653672\n",
            "Iter: 1658 loss: 689616.88286346081\n",
            "Iter: 1659 loss: 689011.108859817\n",
            "Iter: 1660 loss: 688941.26473955379\n",
            "Iter: 1661 loss: 688835.56670560013\n",
            "Iter: 1662 loss: 688833.57549280208\n",
            "Iter: 1663 loss: 688703.2396117521\n",
            "Iter: 1664 loss: 689308.52807802986\n",
            "Iter: 1665 loss: 688679.04876537435\n",
            "Iter: 1666 loss: 688560.1903035643\n",
            "Iter: 1667 loss: 688937.61079595669\n",
            "Iter: 1668 loss: 688526.17421465856\n",
            "tf.Tensor(\n",
            "[-0.00108965 -0.00376135  0.00263194 ...  0.31511749  0.26755856\n",
            " -0.20718852], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7664630197630204\n",
            "Validation loss: 0.837488593514588\n",
            "Iter: 1669 loss: 688409.35535781016\n",
            "Iter: 1670 loss: 688720.69616891257\n",
            "Iter: 1671 loss: 688370.47088264045\n",
            "Iter: 1672 loss: 688260.2052906208\n",
            "Iter: 1673 loss: 688327.74930253637\n",
            "Iter: 1674 loss: 688189.49280337989\n",
            "Iter: 1675 loss: 688055.2904341222\n",
            "Iter: 1676 loss: 688378.62678833224\n",
            "Iter: 1677 loss: 688007.011142725\n",
            "Iter: 1678 loss: 687865.67203988216\n",
            "Iter: 1679 loss: 688337.94485511247\n",
            "Iter: 1680 loss: 687827.24374839582\n",
            "Iter: 1681 loss: 687695.739949394\n",
            "Iter: 1682 loss: 687969.08777757548\n",
            "Iter: 1683 loss: 687643.36163124652\n",
            "tf.Tensor(\n",
            "[-0.00110488 -0.00331528  0.00240897 ...  0.32298183  0.27468645\n",
            " -0.20806105], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7657025657180107\n",
            "Validation loss: 0.8369831497524001\n",
            "Iter: 1684 loss: 687507.41761673742\n",
            "Iter: 1685 loss: 687761.34536757856\n",
            "Iter: 1686 loss: 687449.64906992076\n",
            "Iter: 1687 loss: 687312.3825870204\n",
            "Iter: 1688 loss: 687918.79500859731\n",
            "Iter: 1689 loss: 687285.13167490694\n",
            "Iter: 1690 loss: 687212.11675424222\n",
            "Iter: 1691 loss: 687206.70501825574\n",
            "Iter: 1692 loss: 687136.04465418146\n",
            "Iter: 1693 loss: 687073.48750071158\n",
            "Iter: 1694 loss: 687055.20728666929\n",
            "Iter: 1695 loss: 686955.59605588822\n",
            "Iter: 1696 loss: 686976.22803124308\n",
            "Iter: 1697 loss: 686881.73192072322\n",
            "tf.Tensor(\n",
            "[-0.00110121 -0.00288617  0.0022084  ...  0.32958764  0.28015096\n",
            " -0.20870862], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7651177664830024\n",
            "Validation loss: 0.8367042542512145\n",
            "Iter: 1698 loss: 686756.39554522315\n",
            "Iter: 1699 loss: 687399.27803542512\n",
            "Iter: 1700 loss: 686736.17193273955\n",
            "Iter: 1701 loss: 686624.11611274909\n",
            "Iter: 1702 loss: 687051.65487220755\n",
            "Iter: 1703 loss: 686597.48417021718\n",
            "Iter: 1704 loss: 686490.751129833\n",
            "Iter: 1705 loss: 686612.27670228237\n",
            "Iter: 1706 loss: 686433.41134796757\n",
            "Iter: 1707 loss: 686317.00888461038\n",
            "Iter: 1708 loss: 686506.49800007057\n",
            "Iter: 1709 loss: 686263.65670478344\n",
            "Iter: 1710 loss: 686137.47102452745\n",
            "Iter: 1711 loss: 686513.03363219777\n",
            "Iter: 1712 loss: 686099.12515137531\n",
            "tf.Tensor(\n",
            "[-0.0010998  -0.0024153   0.00197472 ...  0.33667821  0.28618498\n",
            " -0.20936377], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7645396134514859\n",
            "Validation loss: 0.836476385712555\n",
            "Iter: 1713 loss: 685969.292144378\n",
            "Iter: 1714 loss: 686208.66886703961\n",
            "Iter: 1715 loss: 685913.72373343061\n",
            "Iter: 1716 loss: 685778.72612618294\n",
            "Iter: 1717 loss: 686133.50295206928\n",
            "Iter: 1718 loss: 685733.22706628137\n",
            "Iter: 1719 loss: 685597.45107571664\n",
            "Iter: 1720 loss: 685893.90629781759\n",
            "Iter: 1721 loss: 685545.07334642485\n",
            "Iter: 1722 loss: 685420.96798215783\n",
            "Iter: 1723 loss: 686475.68073639437\n",
            "Iter: 1724 loss: 685413.97631913435\n",
            "Iter: 1725 loss: 685320.75131583062\n",
            "Iter: 1726 loss: 686487.93319707678\n",
            "Iter: 1727 loss: 685319.90075609973\n",
            "tf.Tensor(\n",
            "[-0.00110231 -0.00197211  0.00172884 ...  0.34344816  0.29220796\n",
            " -0.20972985], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.763998394960049\n",
            "Validation loss: 0.8364272922546053\n",
            "Iter: 1728 loss: 685256.21008732065\n",
            "Iter: 1729 loss: 685155.741458172\n",
            "Iter: 1730 loss: 685154.68300787348\n",
            "Iter: 1731 loss: 685040.48805381218\n",
            "Iter: 1732 loss: 685160.54301831091\n",
            "Iter: 1733 loss: 684977.302265173\n",
            "Iter: 1734 loss: 684856.80988832563\n",
            "Iter: 1735 loss: 685847.523038672\n",
            "Iter: 1736 loss: 684849.418274097\n",
            "Iter: 1737 loss: 684739.12519236829\n",
            "Iter: 1738 loss: 684916.50221686251\n",
            "Iter: 1739 loss: 684688.2137250118\n",
            "Iter: 1740 loss: 684575.939781784\n",
            "Iter: 1741 loss: 684792.71740205027\n",
            "Iter: 1742 loss: 684529.10691568081\n",
            "tf.Tensor(\n",
            "[-0.00110127 -0.00152189  0.00146184 ...  0.35029495  0.29797947\n",
            " -0.20994309], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7634638801173677\n",
            "Validation loss: 0.8359419426340076\n",
            "Iter: 1743 loss: 684410.61799280625\n",
            "Iter: 1744 loss: 684634.65579473122\n",
            "Iter: 1745 loss: 684360.623552003\n",
            "Iter: 1746 loss: 684238.65126963949\n",
            "Iter: 1747 loss: 684510.26930889487\n",
            "Iter: 1748 loss: 684192.2734373624\n",
            "Iter: 1749 loss: 684066.00988680357\n",
            "Iter: 1750 loss: 684426.05515316559\n",
            "Iter: 1751 loss: 684026.23029092746\n",
            "Iter: 1752 loss: 683904.15177794558\n",
            "Iter: 1753 loss: 684220.7270468584\n",
            "Iter: 1754 loss: 683862.54361504014\n",
            "Iter: 1755 loss: 683740.73331514618\n",
            "Iter: 1756 loss: 684146.4887462589\n",
            "Iter: 1757 loss: 683707.41898871865\n",
            "tf.Tensor(\n",
            "[-0.00108086 -0.00104758  0.00117263 ...  0.35747017  0.30453518\n",
            " -0.21012405], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7628932871680644\n",
            "Validation loss: 0.8356632743536744\n",
            "Iter: 1758 loss: 683625.13574822957\n",
            "Iter: 1759 loss: 684938.28600085049\n",
            "Iter: 1760 loss: 683625.13355574687\n",
            "Iter: 1761 loss: 683539.138612856\n",
            "Iter: 1762 loss: 683624.16306835331\n",
            "Iter: 1763 loss: 683490.49563026638\n",
            "Iter: 1764 loss: 683417.66389048728\n",
            "Iter: 1765 loss: 683334.71794678876\n",
            "Iter: 1766 loss: 683324.22735337215\n",
            "Iter: 1767 loss: 683208.23675049318\n",
            "Iter: 1768 loss: 683768.57653520582\n",
            "Iter: 1769 loss: 683187.74813131033\n",
            "Iter: 1770 loss: 683086.64359667385\n",
            "Iter: 1771 loss: 683584.65034096723\n",
            "Iter: 1772 loss: 683069.3360667685\n",
            "tf.Tensor(\n",
            "[-0.00105473 -0.00065341  0.00093137 ...  0.36360289  0.30971594\n",
            " -0.21020455], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.762429186551147\n",
            "Validation loss: 0.8355920362739395\n",
            "Iter: 1773 loss: 682973.68418042711\n",
            "Iter: 1774 loss: 683189.75624635839\n",
            "Iter: 1775 loss: 682937.64747453842\n",
            "Iter: 1776 loss: 682842.45804439229\n",
            "Iter: 1777 loss: 682950.75863240729\n",
            "Iter: 1778 loss: 682791.34030426061\n",
            "Iter: 1779 loss: 682680.01095468\n",
            "Iter: 1780 loss: 682884.74913100409\n",
            "Iter: 1781 loss: 682632.27045244956\n",
            "Iter: 1782 loss: 682517.92232664081\n",
            "Iter: 1783 loss: 682794.16552233032\n",
            "Iter: 1784 loss: 682476.83027326432\n",
            "Iter: 1785 loss: 682363.83932950092\n",
            "Iter: 1786 loss: 682818.44886546338\n",
            "Iter: 1787 loss: 682338.64736496273\n",
            "tf.Tensor(\n",
            "[-1.01862416e-03 -2.15648194e-04  6.56700879e-04 ...  3.70974444e-01\n",
            "  3.15945839e-01 -2.10154717e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7618832108896404\n",
            "Validation loss: 0.8354480555561135\n",
            "Iter: 1788 loss: 682232.27367286081\n",
            "Iter: 1789 loss: 682424.18675248057\n",
            "Iter: 1790 loss: 682186.10665756953\n",
            "Iter: 1791 loss: 682083.49979916471\n",
            "Iter: 1792 loss: 682505.87711104145\n",
            "Iter: 1793 loss: 682061.11497941508\n",
            "Iter: 1794 loss: 681999.12573541328\n",
            "Iter: 1795 loss: 681994.02240410144\n",
            "Iter: 1796 loss: 681947.19150757208\n",
            "Iter: 1797 loss: 681857.10218866612\n",
            "Iter: 1798 loss: 683752.94748562784\n",
            "Iter: 1799 loss: 681856.6230920942\n",
            "Iter: 1800 loss: 681762.21324668266\n",
            "Iter: 1801 loss: 681917.11593371828\n",
            "Iter: 1802 loss: 681719.13798101177\n",
            "tf.Tensor(\n",
            "[-9.77076671e-04  1.32608125e-04  4.29437065e-04 ...  3.77442976e-01\n",
            "  3.21534555e-01 -2.10061180e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7614200928212821\n",
            "Validation loss: 0.8355284568759919\n",
            "Iter: 1803 loss: 681617.02946864\n",
            "Iter: 1804 loss: 681919.91347394977\n",
            "Iter: 1805 loss: 681585.909536029\n",
            "Iter: 1806 loss: 681491.72137873783\n",
            "Iter: 1807 loss: 682086.92238975829\n",
            "Iter: 1808 loss: 681481.06829144817\n",
            "Iter: 1809 loss: 681397.81605959823\n",
            "Iter: 1810 loss: 681567.36205155018\n",
            "Iter: 1811 loss: 681364.22773323348\n",
            "Iter: 1812 loss: 681279.10715449078\n",
            "Iter: 1813 loss: 681350.20579853165\n",
            "Iter: 1814 loss: 681228.50909114257\n",
            "Iter: 1815 loss: 681129.85565068922\n",
            "Iter: 1816 loss: 681353.8418979242\n",
            "Iter: 1817 loss: 681092.8038780177\n",
            "tf.Tensor(\n",
            "[-9.14023682e-04  4.71815741e-04  2.00865610e-04 ...  3.84353869e-01\n",
            "  3.27188031e-01 -2.09904894e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7609282308487471\n",
            "Validation loss: 0.835144144804962\n",
            "Iter: 1818 loss: 680991.80204244226\n",
            "Iter: 1819 loss: 681363.76970827975\n",
            "Iter: 1820 loss: 680966.88425295916\n",
            "Iter: 1821 loss: 680873.17766631511\n",
            "Iter: 1822 loss: 681056.18643302436\n",
            "Iter: 1823 loss: 680834.38591106515\n",
            "Iter: 1824 loss: 680738.46313361544\n",
            "Iter: 1825 loss: 681017.76960428723\n",
            "Iter: 1826 loss: 680708.79473234166\n",
            "Iter: 1827 loss: 680636.78445251507\n",
            "Iter: 1828 loss: 681488.44429189968\n",
            "Iter: 1829 loss: 680635.80019721249\n",
            "Iter: 1830 loss: 680561.609998826\n",
            "Iter: 1831 loss: 680809.933835925\n",
            "Iter: 1832 loss: 680541.4140851784\n",
            "tf.Tensor(\n",
            "[-8.39383470e-04  7.42284402e-04  1.02804542e-05 ...  3.90578656e-01\n",
            "  3.32783034e-01 -2.09592697e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7604663988396112\n",
            "Validation loss: 0.8349307148574734\n",
            "Iter: 1833 loss: 680489.28524799482\n",
            "Iter: 1834 loss: 680420.84089021094\n",
            "Iter: 1835 loss: 680416.58872790553\n",
            "Iter: 1836 loss: 680323.71056636411\n",
            "Iter: 1837 loss: 680530.59701390762\n",
            "Iter: 1838 loss: 680288.40786353964\n",
            "Iter: 1839 loss: 680193.97020151129\n",
            "Iter: 1840 loss: 680439.01715466648\n",
            "Iter: 1841 loss: 680161.83978109679\n",
            "Iter: 1842 loss: 680074.25223133632\n",
            "Iter: 1843 loss: 680750.91178027\n",
            "Iter: 1844 loss: 680067.89898043138\n",
            "Iter: 1845 loss: 679991.25887877075\n",
            "Iter: 1846 loss: 680074.67126411689\n",
            "Iter: 1847 loss: 679949.41148311121\n",
            "tf.Tensor(\n",
            "[-7.41446897e-04  9.88087105e-04 -1.75246377e-04 ...  3.97303629e-01\n",
            "  3.38555422e-01 -2.09069766e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7599513278378575\n",
            "Validation loss: 0.8348380821672522\n",
            "Iter: 1848 loss: 679868.35948950914\n",
            "Iter: 1849 loss: 680033.34190493112\n",
            "Iter: 1850 loss: 679835.66089874739\n",
            "Iter: 1851 loss: 679747.42763460206\n",
            "Iter: 1852 loss: 679892.82510703232\n",
            "Iter: 1853 loss: 679707.23070579837\n",
            "Iter: 1854 loss: 679613.43363366986\n",
            "Iter: 1855 loss: 679864.43406754092\n",
            "Iter: 1856 loss: 679582.27408208372\n",
            "Iter: 1857 loss: 679488.51766190329\n",
            "Iter: 1858 loss: 679739.79346329765\n",
            "Iter: 1859 loss: 679457.410273185\n",
            "Iter: 1860 loss: 679368.70127483108\n",
            "Iter: 1861 loss: 679684.42612631631\n",
            "Iter: 1862 loss: 679346.05581981468\n",
            "tf.Tensor(\n",
            "[-6.22466375e-04  1.20455880e-03 -3.54168441e-04 ...  4.04656484e-01\n",
            "  3.44865843e-01 -2.08501223e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7593963170416186\n",
            "Validation loss: 0.8350166087750053\n",
            "Iter: 1863 loss: 679299.11489949212\n",
            "Iter: 1864 loss: 679293.5204848412\n",
            "Iter: 1865 loss: 679250.12663882819\n",
            "Iter: 1866 loss: 679188.35762116511\n",
            "Iter: 1867 loss: 679186.23440512584\n",
            "Iter: 1868 loss: 679114.493740354\n",
            "Iter: 1869 loss: 679144.02084890939\n",
            "Iter: 1870 loss: 679065.08484101307\n",
            "Iter: 1871 loss: 678975.18475345732\n",
            "Iter: 1872 loss: 679243.06997350079\n",
            "Iter: 1873 loss: 678947.92358195293\n",
            "Iter: 1874 loss: 678863.4963917773\n",
            "Iter: 1875 loss: 679127.707783464\n",
            "Iter: 1876 loss: 678839.0053604251\n",
            "tf.Tensor(\n",
            "[-0.00051209  0.0013484  -0.00048976 ...  0.41103713  0.35039195\n",
            " -0.20796805], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7589064701438373\n",
            "Validation loss: 0.834926252039009\n",
            "Iter: 1877 loss: 678762.06566624\n",
            "Iter: 1878 loss: 679259.18700966379\n",
            "Iter: 1879 loss: 678753.73919865245\n",
            "Iter: 1880 loss: 678685.11729432619\n",
            "Iter: 1881 loss: 678765.06853618671\n",
            "Iter: 1882 loss: 678648.60776174814\n",
            "Iter: 1883 loss: 678573.872421674\n",
            "Iter: 1884 loss: 678706.38974042679\n",
            "Iter: 1885 loss: 678541.12444469542\n",
            "Iter: 1886 loss: 678458.00972216565\n",
            "Iter: 1887 loss: 678615.24813768\n",
            "Iter: 1888 loss: 678422.94525253715\n",
            "Iter: 1889 loss: 678336.83553245279\n",
            "Iter: 1890 loss: 678503.96988627024\n",
            "Iter: 1891 loss: 678301.03998492623\n",
            "tf.Tensor(\n",
            "[-3.82122122e-04  1.46902432e-03 -6.25482995e-04 ...  4.18250514e-01\n",
            "  3.56319789e-01 -2.07206794e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7583567239891468\n",
            "Validation loss: 0.8349648485703175\n",
            "Iter: 1892 loss: 678209.013883798\n",
            "Iter: 1893 loss: 678472.45143201912\n",
            "Iter: 1894 loss: 678180.09608659323\n",
            "Iter: 1895 loss: 678110.45335566124\n",
            "Iter: 1896 loss: 679006.413831122\n",
            "Iter: 1897 loss: 678109.94895205286\n",
            "Iter: 1898 loss: 678045.88269383518\n",
            "Iter: 1899 loss: 678398.585658218\n",
            "Iter: 1900 loss: 678036.58357437979\n",
            "Iter: 1901 loss: 677994.81758152577\n",
            "Iter: 1902 loss: 677932.23747197841\n",
            "Iter: 1903 loss: 677930.9248889744\n",
            "Iter: 1904 loss: 677853.15898811165\n",
            "Iter: 1905 loss: 678007.91352409043\n",
            "Iter: 1906 loss: 677821.33252041088\n",
            "tf.Tensor(\n",
            "[-2.58613224e-04  1.54310440e-03 -7.36048748e-04 ...  4.24904247e-01\n",
            "  3.62227007e-01 -2.06407564e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7578361095582328\n",
            "Validation loss: 0.834905698215485\n",
            "Iter: 1907 loss: 677742.0541477201\n",
            "Iter: 1908 loss: 677950.23146271822\n",
            "Iter: 1909 loss: 677715.33648359822\n",
            "Iter: 1910 loss: 677637.30686687946\n",
            "Iter: 1911 loss: 677978.41261384566\n",
            "Iter: 1912 loss: 677621.55808422924\n",
            "Iter: 1913 loss: 677550.53585207113\n",
            "Iter: 1914 loss: 677842.26003009768\n",
            "Iter: 1915 loss: 677535.085945664\n",
            "Iter: 1916 loss: 677468.54809497332\n",
            "Iter: 1917 loss: 677604.1572257774\n",
            "Iter: 1918 loss: 677441.73766606336\n",
            "Iter: 1919 loss: 677374.74246567651\n",
            "Iter: 1920 loss: 677452.73814995086\n",
            "Iter: 1921 loss: 677339.06017916626\n",
            "tf.Tensor(\n",
            "[-1.29419789e-04  1.58072363e-03 -8.34027439e-04 ...  4.31809349e-01\n",
            "  3.68211102e-01 -2.05555293e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7572810346999772\n",
            "Validation loss: 0.8348217331343548\n",
            "Iter: 1922 loss: 677261.75959397852\n",
            "Iter: 1923 loss: 677406.42637590971\n",
            "Iter: 1924 loss: 677228.92786027119\n",
            "Iter: 1925 loss: 677149.68315394106\n",
            "Iter: 1926 loss: 677364.26845681109\n",
            "Iter: 1927 loss: 677123.60976906063\n",
            "Iter: 1928 loss: 677046.04008798907\n",
            "Iter: 1929 loss: 677371.92678641272\n",
            "Iter: 1930 loss: 677029.55237349786\n",
            "Iter: 1931 loss: 676988.03979764145\n",
            "Iter: 1932 loss: 676985.2832074241\n",
            "Iter: 1933 loss: 676942.95500879036\n",
            "Iter: 1934 loss: 676896.38446804753\n",
            "Iter: 1935 loss: 676889.58654128714\n",
            "tf.Tensor(\n",
            "[-9.39667911e-06  1.57802405e-03 -9.08588269e-04 ...  4.38403803e-01\n",
            "  3.73999288e-01 -2.04650999e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.75673864210326\n",
            "Validation loss: 0.8346589223602786\n",
            "Iter: 1936 loss: 676832.17992520484\n",
            "Iter: 1937 loss: 676837.45923752768\n",
            "Iter: 1938 loss: 676787.822914033\n",
            "Iter: 1939 loss: 676711.2689550512\n",
            "Iter: 1940 loss: 676922.88699829846\n",
            "Iter: 1941 loss: 676686.50726667512\n",
            "Iter: 1942 loss: 676609.35682158149\n",
            "Iter: 1943 loss: 676830.41796577873\n",
            "Iter: 1944 loss: 676585.16398437589\n",
            "Iter: 1945 loss: 676512.19270126033\n",
            "Iter: 1946 loss: 676827.11797660938\n",
            "Iter: 1947 loss: 676497.22825031891\n",
            "Iter: 1948 loss: 676431.79677484662\n",
            "Iter: 1949 loss: 676710.89388828073\n",
            "Iter: 1950 loss: 676418.20383256732\n",
            "tf.Tensor(\n",
            "[ 1.17196969e-04  1.53724838e-03 -9.70606001e-04 ...  4.45807792e-01\n",
            "  3.80657659e-01 -2.03496576e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7561375234000861\n",
            "Validation loss: 0.8342827707861102\n",
            "Iter: 1951 loss: 676356.92983441439\n",
            "Iter: 1952 loss: 676435.47341029253\n",
            "Iter: 1953 loss: 676325.53894936107\n",
            "Iter: 1954 loss: 676258.95998096769\n",
            "Iter: 1955 loss: 676360.08014040184\n",
            "Iter: 1956 loss: 676227.34580163774\n",
            "Iter: 1957 loss: 676153.45021813177\n",
            "Iter: 1958 loss: 676317.44970940752\n",
            "Iter: 1959 loss: 676125.27707733\n",
            "Iter: 1960 loss: 676050.80776459468\n",
            "Iter: 1961 loss: 676249.66758362169\n",
            "Iter: 1962 loss: 676026.04498850775\n",
            "Iter: 1963 loss: 675961.84457367356\n",
            "Iter: 1964 loss: 676447.286695546\n",
            "Iter: 1965 loss: 675956.88301333028\n",
            "tf.Tensor(\n",
            "[ 2.35041865e-04  1.45801688e-03 -1.00992207e-03 ...  4.53393046e-01\n",
            "  3.87068381e-01 -2.02288025e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7555280882509012\n",
            "Validation loss: 0.834058588904266\n",
            "Iter: 1966 loss: 675904.58764994878\n",
            "Iter: 1967 loss: 676550.32377796911\n",
            "Iter: 1968 loss: 675904.05539432273\n",
            "Iter: 1969 loss: 675871.1282705\n",
            "Iter: 1970 loss: 675813.80412924616\n",
            "Iter: 1971 loss: 675813.783506657\n",
            "Iter: 1972 loss: 675751.59134124708\n",
            "Iter: 1973 loss: 675826.03094434121\n",
            "Iter: 1974 loss: 675718.83344449743\n",
            "Iter: 1975 loss: 675647.98470230273\n",
            "Iter: 1976 loss: 675876.97323452239\n",
            "Iter: 1977 loss: 675628.02161303349\n",
            "Iter: 1978 loss: 675559.93744543043\n",
            "Iter: 1979 loss: 675794.682993023\n",
            "Iter: 1980 loss: 675541.95895763254\n",
            "tf.Tensor(\n",
            "[ 3.34430531e-04  1.35195180e-03 -1.02378292e-03 ...  4.60567325e-01\n",
            "  3.93473936e-01 -2.01143106e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7549736554706435\n",
            "Validation loss: 0.8342139303643933\n",
            "Iter: 1981 loss: 675477.334529161\n",
            "Iter: 1982 loss: 675718.94846120034\n",
            "Iter: 1983 loss: 675461.65552399075\n",
            "Iter: 1984 loss: 675399.38743963267\n",
            "Iter: 1985 loss: 675625.17562533543\n",
            "Iter: 1986 loss: 675383.78670538822\n",
            "Iter: 1987 loss: 675324.587688853\n",
            "Iter: 1988 loss: 675405.55971533351\n",
            "Iter: 1989 loss: 675295.08591350936\n",
            "Iter: 1990 loss: 675229.86197304761\n",
            "Iter: 1991 loss: 675313.26766992174\n",
            "Iter: 1992 loss: 675196.399074096\n",
            "Iter: 1993 loss: 675125.36776178645\n",
            "Iter: 1994 loss: 675322.70124223176\n",
            "Iter: 1995 loss: 675102.48511796375\n",
            "tf.Tensor(\n",
            "[ 4.29296393e-04  1.20615065e-03 -1.01369047e-03 ...  4.68388218e-01\n",
            "  4.00271548e-01 -1.99770864e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7543687434322338\n",
            "Validation loss: 0.8339051197341169\n",
            "Iter: 1996 loss: 675034.03285380721\n",
            "Iter: 1997 loss: 675271.11161226477\n",
            "Iter: 1998 loss: 675016.05307198677\n",
            "Iter: 1999 loss: 674972.33140985237\n",
            "Iter: 2000 loss: 674971.708370408\n",
            "Iter: 2001 loss: 674928.41098647227\n",
            "Iter: 2002 loss: 674945.27354889386\n",
            "Iter: 2003 loss: 674898.40176066686\n",
            "Iter: 2004 loss: 674854.11367247172\n",
            "Iter: 2005 loss: 674817.8102868502\n",
            "Iter: 2006 loss: 674804.86258819152\n",
            "Iter: 2007 loss: 674737.04151627945\n",
            "Iter: 2008 loss: 674889.03847160144\n",
            "Iter: 2009 loss: 674711.33546836243\n",
            "tf.Tensor(\n",
            "[ 0.0004985   0.00105403 -0.00098146 ...  0.47522592  0.40633269\n",
            " -0.19846441], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.753835550839538\n",
            "Validation loss: 0.8336965189376296\n",
            "Iter: 2010 loss: 674640.62827309291\n",
            "Iter: 2011 loss: 674882.87189292011\n",
            "Iter: 2012 loss: 674621.82353585481\n",
            "Iter: 2013 loss: 674555.30718278326\n",
            "Iter: 2014 loss: 674753.59403332428\n",
            "Iter: 2015 loss: 674535.13763494138\n",
            "Iter: 2016 loss: 674473.49386819568\n",
            "Iter: 2017 loss: 674760.75334436051\n",
            "Iter: 2018 loss: 674462.05725658243\n",
            "Iter: 2019 loss: 674404.53540444141\n",
            "Iter: 2020 loss: 674595.74291381228\n",
            "Iter: 2021 loss: 674388.78577515075\n",
            "Iter: 2022 loss: 674333.848593252\n",
            "Iter: 2023 loss: 674385.979324403\n",
            "Iter: 2024 loss: 674302.4153723577\n",
            "tf.Tensor(\n",
            "[ 0.00055876  0.00087085 -0.00092552 ...  0.48268375  0.41315739\n",
            " -0.19715018], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7532746905524039\n",
            "Validation loss: 0.8333923326576084\n",
            "Iter: 2025 loss: 674239.83825315081\n",
            "Iter: 2026 loss: 674351.61316967465\n",
            "Iter: 2027 loss: 674212.531283489\n",
            "Iter: 2028 loss: 674148.07670900086\n",
            "Iter: 2029 loss: 674326.583417438\n",
            "Iter: 2030 loss: 674127.23722648155\n",
            "Iter: 2031 loss: 674066.99620070728\n",
            "Iter: 2032 loss: 674396.94591986574\n",
            "Iter: 2033 loss: 674058.24151402689\n",
            "Iter: 2034 loss: 674015.74362775509\n",
            "Iter: 2035 loss: 674015.48437426647\n",
            "Iter: 2036 loss: 673986.88909876719\n",
            "Iter: 2037 loss: 673936.52111792529\n",
            "Iter: 2038 loss: 673936.51802205062\n",
            "tf.Tensor(\n",
            "[ 0.00059871  0.00068959 -0.0008556  ...  0.48963509  0.4191721\n",
            " -0.19593568], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7527785191488673\n",
            "Validation loss: 0.8333846092015595\n",
            "Iter: 2039 loss: 673877.59602098668\n",
            "Iter: 2040 loss: 673950.32064283337\n",
            "Iter: 2041 loss: 673846.91251294327\n",
            "Iter: 2042 loss: 673780.98201081471\n",
            "Iter: 2043 loss: 673926.44245797128\n",
            "Iter: 2044 loss: 673755.73394886765\n",
            "Iter: 2045 loss: 673688.12243087112\n",
            "Iter: 2046 loss: 673916.74892295967\n",
            "Iter: 2047 loss: 673669.90367085859\n",
            "Iter: 2048 loss: 673604.53886298207\n",
            "Iter: 2049 loss: 673785.28438127646\n",
            "Iter: 2050 loss: 673583.39945974224\n",
            "Iter: 2051 loss: 673523.34898307116\n",
            "Iter: 2052 loss: 673846.309602512\n",
            "Iter: 2053 loss: 673514.32595116086\n",
            "tf.Tensor(\n",
            "[ 6.26860793e-04  4.68258813e-04 -7.54363813e-04 ...  4.97913883e-01\n",
            "  4.26604863e-01 -1.94412910e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7522076797717393\n",
            "Validation loss: 0.8335575782636672\n",
            "Iter: 2054 loss: 673459.70031193981\n",
            "Iter: 2055 loss: 673616.60706681281\n",
            "Iter: 2056 loss: 673442.60251588048\n",
            "Iter: 2057 loss: 673389.72947921418\n",
            "Iter: 2058 loss: 673434.71774375427\n",
            "Iter: 2059 loss: 673358.46283213049\n",
            "Iter: 2060 loss: 673296.33652208815\n",
            "Iter: 2061 loss: 673396.73646132788\n",
            "Iter: 2062 loss: 673267.74490896729\n",
            "Iter: 2063 loss: 673202.57456761284\n",
            "Iter: 2064 loss: 673427.99905985442\n",
            "Iter: 2065 loss: 673185.37402701681\n",
            "Iter: 2066 loss: 673143.12632212753\n",
            "Iter: 2067 loss: 673142.915965973\n",
            "tf.Tensor(\n",
            "[ 6.36673393e-04  2.63525185e-04 -6.47956069e-04 ...  5.05543350e-01\n",
            "  4.33255588e-01 -1.93005264e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7517024941312775\n",
            "Validation loss: 0.833567128623723\n",
            "Iter: 2068 loss: 673099.6052719705\n",
            "Iter: 2069 loss: 673150.83288793568\n",
            "Iter: 2070 loss: 673076.64122106228\n",
            "Iter: 2071 loss: 673037.91971695737\n",
            "Iter: 2072 loss: 673005.357335263\n",
            "Iter: 2073 loss: 672994.47260634042\n",
            "Iter: 2074 loss: 672934.48161818343\n",
            "Iter: 2075 loss: 673064.09616809012\n",
            "Iter: 2076 loss: 672911.16262514121\n",
            "Iter: 2077 loss: 672849.507421855\n",
            "Iter: 2078 loss: 673037.25162809645\n",
            "Iter: 2079 loss: 672831.1672907446\n",
            "Iter: 2080 loss: 672770.53965841478\n",
            "Iter: 2081 loss: 672921.9752645191\n",
            "Iter: 2082 loss: 672749.27263902547\n",
            "tf.Tensor(\n",
            "[ 6.30436142e-04  4.21477623e-05 -5.19645921e-04 ...  5.13876505e-01\n",
            "  4.40590191e-01 -1.91416276e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7511602193350873\n",
            "Validation loss: 0.8331853862973545\n",
            "Iter: 2083 loss: 672688.15607901\n",
            "Iter: 2084 loss: 672892.65664164792\n",
            "Iter: 2085 loss: 672671.52142339991\n",
            "Iter: 2086 loss: 672617.42165221588\n",
            "Iter: 2087 loss: 672920.84418250981\n",
            "Iter: 2088 loss: 672609.82280097518\n",
            "Iter: 2089 loss: 672560.24122204026\n",
            "Iter: 2090 loss: 672655.47265379934\n",
            "Iter: 2091 loss: 672539.51332444244\n",
            "Iter: 2092 loss: 672487.99408178078\n",
            "Iter: 2093 loss: 672536.23714413878\n",
            "Iter: 2094 loss: 672458.39565198938\n",
            "Iter: 2095 loss: 672397.96508178976\n",
            "Iter: 2096 loss: 672581.34813326015\n",
            "Iter: 2097 loss: 672379.93996457872\n",
            "tf.Tensor(\n",
            "[ 6.08356871e-04 -1.62684632e-04 -3.88090793e-04 ...  5.21848946e-01\n",
            "  4.47849205e-01 -1.89766370e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7506515872421428\n",
            "Validation loss: 0.832997764142749\n",
            "Iter: 2098 loss: 672322.5392939169\n",
            "Iter: 2099 loss: 672472.10225405812\n",
            "Iter: 2100 loss: 672303.01102309348\n",
            "Iter: 2101 loss: 672272.91719502036\n",
            "Iter: 2102 loss: 672267.70394\n",
            "Iter: 2103 loss: 672239.04386864\n",
            "Iter: 2104 loss: 672193.05650610593\n",
            "Iter: 2105 loss: 672192.69041204883\n",
            "Iter: 2106 loss: 672141.20641576825\n",
            "Iter: 2107 loss: 672189.1836004759\n",
            "Iter: 2108 loss: 672111.59569821227\n",
            "Iter: 2109 loss: 672053.39027080615\n",
            "Iter: 2110 loss: 672179.18727364426\n",
            "Iter: 2111 loss: 672030.77482840233\n",
            "tf.Tensor(\n",
            "[ 5.73134107e-04 -3.48760714e-04 -2.56647294e-04 ...  5.29563504e-01\n",
            "  4.54631214e-01 -1.88065767e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7501749848237039\n",
            "Validation loss: 0.8329546377849196\n",
            "Iter: 2112 loss: 671970.66165620694\n",
            "Iter: 2113 loss: 672127.02430288238\n",
            "Iter: 2114 loss: 671950.24966474331\n",
            "Iter: 2115 loss: 671889.62652276619\n",
            "Iter: 2116 loss: 672072.1721957752\n",
            "Iter: 2117 loss: 671871.40262103756\n",
            "Iter: 2118 loss: 671812.72377356933\n",
            "Iter: 2119 loss: 672004.01777284744\n",
            "Iter: 2120 loss: 671796.336264395\n",
            "Iter: 2121 loss: 671742.60419012781\n",
            "Iter: 2122 loss: 672044.72850519407\n",
            "Iter: 2123 loss: 671735.08175630914\n",
            "Iter: 2124 loss: 671684.82947057183\n",
            "Iter: 2125 loss: 671772.08281626937\n",
            "Iter: 2126 loss: 671662.56900633429\n",
            "tf.Tensor(\n",
            "[ 5.21930855e-04 -5.33128561e-04 -1.13579439e-04 ...  5.38027539e-01\n",
            "  4.62357150e-01 -1.86168706e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7496777033270526\n",
            "Validation loss: 0.8329277041600229\n",
            "Iter: 2127 loss: 671612.31390729791\n",
            "Iter: 2128 loss: 671639.89681768382\n",
            "Iter: 2129 loss: 671579.33834500751\n",
            "Iter: 2130 loss: 671518.82217637333\n",
            "Iter: 2131 loss: 671815.82662922342\n",
            "Iter: 2132 loss: 671508.4126205818\n",
            "Iter: 2133 loss: 671463.36504602584\n",
            "Iter: 2134 loss: 671792.123981667\n",
            "Iter: 2135 loss: 671459.56452252739\n",
            "Iter: 2136 loss: 671414.87073500012\n",
            "Iter: 2137 loss: 671687.010354976\n",
            "Iter: 2138 loss: 671409.44491339067\n",
            "Iter: 2139 loss: 671381.58299093554\n",
            "Iter: 2140 loss: 671332.69489855214\n",
            "Iter: 2141 loss: 671332.68795374292\n",
            "tf.Tensor(\n",
            "[ 4.65567401e-04 -6.79800356e-04  1.25368010e-05 ...  5.45744662e-01\n",
            "  4.69175735e-01 -1.84379648e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.749237458831247\n",
            "Validation loss: 0.8326617961632743\n",
            "Iter: 2142 loss: 671275.46477086435\n",
            "Iter: 2143 loss: 671421.88901981991\n",
            "Iter: 2144 loss: 671255.7755546649\n",
            "Iter: 2145 loss: 671198.32110135292\n",
            "Iter: 2146 loss: 671339.67279570072\n",
            "Iter: 2147 loss: 671177.93933028926\n",
            "Iter: 2148 loss: 671118.63166103931\n",
            "Iter: 2149 loss: 671274.14573874942\n",
            "Iter: 2150 loss: 671098.62155530718\n",
            "Iter: 2151 loss: 671041.97576107213\n",
            "Iter: 2152 loss: 671187.4989583994\n",
            "Iter: 2153 loss: 671022.539852616\n",
            "Iter: 2154 loss: 670964.31091535592\n",
            "Iter: 2155 loss: 671199.84937480115\n",
            "Iter: 2156 loss: 670951.40313295741\n",
            "tf.Tensor(\n",
            "[ 3.87383705e-04 -8.31186739e-04  1.58453531e-04 ...  5.55124781e-01\n",
            "  4.77494777e-01 -1.82087050e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7487059627456032\n",
            "Validation loss: 0.8325201680417685\n",
            "Iter: 2157 loss: 670899.97753730917\n",
            "Iter: 2158 loss: 671125.98398162331\n",
            "Iter: 2159 loss: 670889.6665910217\n",
            "Iter: 2160 loss: 670840.23689917778\n",
            "Iter: 2161 loss: 670946.29072819743\n",
            "Iter: 2162 loss: 670820.959188385\n",
            "Iter: 2163 loss: 670772.49570831354\n",
            "Iter: 2164 loss: 670836.24017391319\n",
            "Iter: 2165 loss: 670747.91554155585\n",
            "Iter: 2166 loss: 670693.09631965624\n",
            "Iter: 2167 loss: 670860.14197359048\n",
            "Iter: 2168 loss: 670676.848427567\n",
            "Iter: 2169 loss: 670643.37678842864\n",
            "Iter: 2170 loss: 670642.60430594906\n",
            "tf.Tensor(\n",
            "[ 3.17354471e-04 -9.30444030e-04  2.68894720e-04 ...  5.62722209e-01\n",
            "  4.84468675e-01 -1.80230295e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7482648955397274\n",
            "Validation loss: 0.8325724088715756\n",
            "Iter: 2171 loss: 670608.70147787558\n",
            "Iter: 2172 loss: 670593.67448427947\n",
            "Iter: 2173 loss: 670576.510174998\n",
            "Iter: 2174 loss: 670537.7265317376\n",
            "Iter: 2175 loss: 670512.54069618\n",
            "Iter: 2176 loss: 670497.610093554\n",
            "Iter: 2177 loss: 670438.16883262363\n",
            "Iter: 2178 loss: 670608.03280528053\n",
            "Iter: 2179 loss: 670419.47973588784\n",
            "Iter: 2180 loss: 670361.97715427354\n",
            "Iter: 2181 loss: 670525.44737407367\n",
            "Iter: 2182 loss: 670343.79216565867\n",
            "Iter: 2183 loss: 670286.75174298149\n",
            "Iter: 2184 loss: 670445.77266373287\n",
            "Iter: 2185 loss: 670268.41518797888\n",
            "tf.Tensor(\n",
            "[ 2.26045911e-04 -1.02145170e-03  3.91484137e-04 ...  5.72011067e-01\n",
            "  4.92758618e-01 -1.77955521e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7477462889589835\n",
            "Validation loss: 0.8324841549354777\n",
            "Iter: 2186 loss: 670212.990494065\n",
            "Iter: 2187 loss: 670361.29515738483\n",
            "Iter: 2188 loss: 670194.57024476444\n",
            "Iter: 2189 loss: 670140.69611314859\n",
            "Iter: 2190 loss: 670389.95666436036\n",
            "Iter: 2191 loss: 670130.61434310768\n",
            "Iter: 2192 loss: 670080.18326082116\n",
            "Iter: 2193 loss: 670254.80430789315\n",
            "Iter: 2194 loss: 670066.90408716933\n",
            "Iter: 2195 loss: 670018.72307892039\n",
            "Iter: 2196 loss: 670122.746324881\n",
            "Iter: 2197 loss: 670000.00880229264\n",
            "Iter: 2198 loss: 669950.75585841073\n",
            "Iter: 2199 loss: 670017.05261355825\n",
            "Iter: 2200 loss: 669926.0094504517\n",
            "tf.Tensor(\n",
            "[ 1.37172791e-04 -1.07653327e-03  4.92130806e-04 ...  5.80806212e-01\n",
            "  5.00977993e-01 -1.75762767e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7472802487312067\n",
            "Validation loss: 0.8324612779835545\n",
            "Iter: 2201 loss: 669875.09589582775\n",
            "Iter: 2202 loss: 670165.923758295\n",
            "Iter: 2203 loss: 669868.221735465\n",
            "Iter: 2204 loss: 669832.02793106844\n",
            "Iter: 2205 loss: 669832.00567648467\n",
            "Iter: 2206 loss: 669807.4047749642\n",
            "Iter: 2207 loss: 669755.50295995956\n",
            "Iter: 2208 loss: 670608.14710153989\n",
            "Iter: 2209 loss: 669754.04342837806\n",
            "Iter: 2210 loss: 669700.61819889559\n",
            "Iter: 2211 loss: 669803.98631903168\n",
            "Iter: 2212 loss: 669678.3546452967\n",
            "Iter: 2213 loss: 669622.35093088227\n",
            "Iter: 2214 loss: 669820.03522350139\n",
            "Iter: 2215 loss: 669607.9034228567\n",
            "tf.Tensor(\n",
            "[ 5.32678720e-05 -1.10135646e-03  5.72000770e-04 ...  5.89168067e-01\n",
            "  5.08538559e-01 -1.73690497e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7468623132944233\n",
            "Validation loss: 0.8325431682756046\n",
            "Iter: 2216 loss: 669553.87325446471\n",
            "Iter: 2217 loss: 669641.93815365946\n",
            "Iter: 2218 loss: 669529.10408297821\n",
            "Iter: 2219 loss: 669470.95572060847\n",
            "Iter: 2220 loss: 669665.71862187609\n",
            "Iter: 2221 loss: 669455.13639517967\n",
            "Iter: 2222 loss: 669398.40916704549\n",
            "Iter: 2223 loss: 669558.12208316079\n",
            "Iter: 2224 loss: 669380.31549391\n",
            "Iter: 2225 loss: 669326.4203913688\n",
            "Iter: 2226 loss: 669590.04942985042\n",
            "Iter: 2227 loss: 669317.08147450187\n",
            "Iter: 2228 loss: 669268.54670130811\n",
            "Iter: 2229 loss: 669446.40554796485\n",
            "Iter: 2230 loss: 669256.49878521846\n",
            "tf.Tensor(\n",
            "[-3.92349328e-05 -1.09894264e-03  6.43454688e-04 ...  5.98707307e-01\n",
            "  5.17160579e-01 -1.71426386e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7464044949978222\n",
            "Validation loss: 0.8324566143874663\n",
            "Iter: 2231 loss: 669210.90519856324\n",
            "Iter: 2232 loss: 669277.15501975641\n",
            "Iter: 2233 loss: 669188.8032408756\n",
            "Iter: 2234 loss: 669139.2663812181\n",
            "Iter: 2235 loss: 669235.65148508793\n",
            "Iter: 2236 loss: 669118.66835217737\n",
            "Iter: 2237 loss: 669084.85878095182\n",
            "Iter: 2238 loss: 669084.30343844369\n",
            "Iter: 2239 loss: 669050.53820212837\n",
            "Iter: 2240 loss: 669057.82295734924\n",
            "Iter: 2241 loss: 669025.57147136144\n",
            "Iter: 2242 loss: 668990.48564553889\n",
            "Iter: 2243 loss: 668962.14463549678\n",
            "Iter: 2244 loss: 668951.67590169038\n",
            "tf.Tensor(\n",
            "[-1.17522971e-04 -1.07130903e-03  6.89663509e-04 ...  6.07198897e-01\n",
            "  5.25003735e-01 -1.69407966e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7460095326681092\n",
            "Validation loss: 0.8324213327409358\n",
            "Iter: 2245 loss: 668897.23108818138\n",
            "Iter: 2246 loss: 669004.17813362624\n",
            "Iter: 2247 loss: 668874.75388040976\n",
            "Iter: 2248 loss: 668816.84430884966\n",
            "Iter: 2249 loss: 669034.35641105461\n",
            "Iter: 2250 loss: 668802.8672027142\n",
            "Iter: 2251 loss: 668747.22526773438\n",
            "Iter: 2252 loss: 668877.50897495449\n",
            "Iter: 2253 loss: 668726.760022027\n",
            "Iter: 2254 loss: 668671.322482981\n",
            "Iter: 2255 loss: 668803.18806136469\n",
            "Iter: 2256 loss: 668651.17892603809\n",
            "Iter: 2257 loss: 668594.17933129042\n",
            "Iter: 2258 loss: 668812.62548231275\n",
            "Iter: 2259 loss: 668580.713173981\n",
            "tf.Tensor(\n",
            "[-2.07135812e-04 -1.00729207e-03  7.24503966e-04 ...  6.17660399e-01\n",
            "  5.34454668e-01 -1.66863046e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7455321497428056\n",
            "Validation loss: 0.8323505919365544\n",
            "Iter: 2260 loss: 668528.96156131278\n",
            "Iter: 2261 loss: 668737.10108993226\n",
            "Iter: 2262 loss: 668517.39990844042\n",
            "Iter: 2263 loss: 668470.17406253773\n",
            "Iter: 2264 loss: 668660.915659089\n",
            "Iter: 2265 loss: 668459.65971555677\n",
            "Iter: 2266 loss: 668416.06609729945\n",
            "Iter: 2267 loss: 668479.009242686\n",
            "Iter: 2268 loss: 668394.8796433392\n",
            "Iter: 2269 loss: 668349.70017211186\n",
            "Iter: 2270 loss: 668481.60413127649\n",
            "Iter: 2271 loss: 668335.68998764665\n",
            "Iter: 2272 loss: 668302.21485450643\n",
            "Iter: 2273 loss: 668301.45746929129\n",
            "tf.Tensor(\n",
            "[-2.69071548e-04 -9.38738971e-04  7.35034071e-04 ...  6.25631111e-01\n",
            "  5.41964330e-01 -1.64876523e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7451745023071644\n",
            "Validation loss: 0.832344822434607\n",
            "Iter: 2274 loss: 668277.82007045683\n",
            "Iter: 2275 loss: 668229.02054656134\n",
            "Iter: 2276 loss: 669086.56095388322\n",
            "Iter: 2277 loss: 668228.00902427116\n",
            "Iter: 2278 loss: 668177.79848734359\n",
            "Iter: 2279 loss: 668270.99604255706\n",
            "Iter: 2280 loss: 668156.36807659571\n",
            "Iter: 2281 loss: 668101.31225648336\n",
            "Iter: 2282 loss: 668220.233751308\n",
            "Iter: 2283 loss: 668079.90826430568\n",
            "Iter: 2284 loss: 668023.21256479435\n",
            "Iter: 2285 loss: 668199.388757456\n",
            "Iter: 2286 loss: 668006.648120807\n",
            "Iter: 2287 loss: 667951.41724591586\n",
            "Iter: 2288 loss: 668105.92148508911\n",
            "Iter: 2289 loss: 667933.71155877\n",
            "tf.Tensor(\n",
            "[-3.41016221e-04 -8.22963279e-04  7.27118176e-04 ...  6.36328326e-01\n",
            "  5.51817005e-01 -1.62142635e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7447110664718838\n",
            "Validation loss: 0.8321709249832193\n",
            "Iter: 2290 loss: 667879.135236311\n",
            "Iter: 2291 loss: 668038.60088129248\n",
            "Iter: 2292 loss: 667862.295456306\n",
            "Iter: 2293 loss: 667809.19517550408\n",
            "Iter: 2294 loss: 667971.479830728\n",
            "Iter: 2295 loss: 667793.4430036546\n",
            "Iter: 2296 loss: 667743.622829825\n",
            "Iter: 2297 loss: 667990.49333067308\n",
            "Iter: 2298 loss: 667735.154577696\n",
            "Iter: 2299 loss: 667689.9454783597\n",
            "Iter: 2300 loss: 667818.18675914186\n",
            "Iter: 2301 loss: 667675.612374914\n",
            "Iter: 2302 loss: 667631.1958697869\n",
            "Iter: 2303 loss: 667705.44673424563\n",
            "Iter: 2304 loss: 667611.14382717421\n",
            "tf.Tensor(\n",
            "[-3.93968524e-04 -7.01368924e-04  7.01011882e-04 ...  6.45977077e-01\n",
            "  5.60704683e-01 -1.59542938e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7443086226336636\n",
            "Validation loss: 0.8318985051731548\n",
            "Iter: 2305 loss: 667573.89641632512\n",
            "Iter: 2306 loss: 667991.107293441\n",
            "Iter: 2307 loss: 667573.19270882825\n",
            "Iter: 2308 loss: 667535.02472042851\n",
            "Iter: 2309 loss: 667595.99251513625\n",
            "Iter: 2310 loss: 667517.38158817135\n",
            "Iter: 2311 loss: 667485.76741632307\n",
            "Iter: 2312 loss: 667444.89229381154\n",
            "Iter: 2313 loss: 667442.11084684753\n",
            "Iter: 2314 loss: 667387.13479719451\n",
            "Iter: 2315 loss: 667534.89332956239\n",
            "Iter: 2316 loss: 667368.93201180419\n",
            "Iter: 2317 loss: 667313.54627217446\n",
            "Iter: 2318 loss: 667457.84163337806\n",
            "Iter: 2319 loss: 667294.73581897758\n",
            "tf.Tensor(\n",
            "[-4.33546873e-04 -5.69119575e-04  6.58440976e-04 ...  6.55435748e-01\n",
            "  5.69475132e-01 -1.56885686e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7439329583609731\n",
            "Validation loss: 0.8319951676884569\n",
            "Iter: 2320 loss: 667239.507609822\n",
            "Iter: 2321 loss: 667396.29741280491\n",
            "Iter: 2322 loss: 667222.0229231366\n",
            "Iter: 2323 loss: 667168.63562412735\n",
            "Iter: 2324 loss: 667323.59201254882\n",
            "Iter: 2325 loss: 667152.0396350415\n",
            "Iter: 2326 loss: 667099.16591206612\n",
            "Iter: 2327 loss: 667249.800225829\n",
            "Iter: 2328 loss: 667082.48539570393\n",
            "Iter: 2329 loss: 667030.64914683229\n",
            "Iter: 2330 loss: 667233.40836584487\n",
            "Iter: 2331 loss: 667018.67870695912\n",
            "Iter: 2332 loss: 666970.686177468\n",
            "Iter: 2333 loss: 667152.251045276\n",
            "Iter: 2334 loss: 666959.19190097693\n",
            "tf.Tensor(\n",
            "[-4.63286518e-04 -4.15738174e-04  5.96347528e-04 ...  6.65681455e-01\n",
            "  5.78759307e-01 -1.53976536e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7435402503893668\n",
            "Validation loss: 0.8318589530678986\n",
            "Iter: 2335 loss: 666913.09169500042\n",
            "Iter: 2336 loss: 667057.96362335421\n",
            "Iter: 2337 loss: 666899.73649381369\n",
            "Iter: 2338 loss: 666859.21006553853\n",
            "Iter: 2339 loss: 666948.35535614169\n",
            "Iter: 2340 loss: 666843.69311981264\n",
            "Iter: 2341 loss: 666808.25958459429\n",
            "Iter: 2342 loss: 666808.22910595941\n",
            "Iter: 2343 loss: 666783.46905169834\n",
            "Iter: 2344 loss: 666739.45613286563\n",
            "Iter: 2345 loss: 667834.92875366891\n",
            "Iter: 2346 loss: 666739.45612943929\n",
            "Iter: 2347 loss: 666690.27386302908\n",
            "Iter: 2348 loss: 666757.25236571615\n",
            "Iter: 2349 loss: 666665.70144998166\n",
            "tf.Tensor(\n",
            "[-4.77750984e-04 -2.75547425e-04  5.29585344e-04 ...  6.74641724e-01\n",
            "  5.87196303e-01 -1.51396577e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7432034928004352\n",
            "Validation loss: 0.8317487292869166\n",
            "Iter: 2350 loss: 666611.48375736759\n",
            "Iter: 2351 loss: 666732.69301734411\n",
            "Iter: 2352 loss: 666590.9017402092\n",
            "Iter: 2353 loss: 666534.69767764059\n",
            "Iter: 2354 loss: 666697.63739090145\n",
            "Iter: 2355 loss: 666517.22009634657\n",
            "Iter: 2356 loss: 666461.92256489745\n",
            "Iter: 2357 loss: 666607.602089678\n",
            "Iter: 2358 loss: 666443.31480869662\n",
            "Iter: 2359 loss: 666388.12905351014\n",
            "Iter: 2360 loss: 666558.99937069148\n",
            "Iter: 2361 loss: 666371.94515585585\n",
            "Iter: 2362 loss: 666318.87345646357\n",
            "Iter: 2363 loss: 666485.10984462488\n",
            "Iter: 2364 loss: 666303.49539714539\n",
            "tf.Tensor(\n",
            "[-4.81170534e-04 -9.82224734e-05  4.33431350e-04 ...  6.85824378e-01\n",
            "  5.97528247e-01 -1.48127442e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7427872198160379\n",
            "Validation loss: 0.8316022454447286\n",
            "Iter: 2365 loss: 666252.96746008855\n",
            "Iter: 2366 loss: 666460.53953819384\n",
            "Iter: 2367 loss: 666241.9402734891\n",
            "Iter: 2368 loss: 666195.95687228709\n",
            "Iter: 2369 loss: 666393.314510443\n",
            "Iter: 2370 loss: 666186.46406458155\n",
            "Iter: 2371 loss: 666143.62976562476\n",
            "Iter: 2372 loss: 666211.59449062287\n",
            "Iter: 2373 loss: 666123.69003740861\n",
            "Iter: 2374 loss: 666087.71698797413\n",
            "Iter: 2375 loss: 666551.0784362246\n",
            "Iter: 2376 loss: 666087.45598857908\n",
            "Iter: 2377 loss: 666052.41743859486\n",
            "Iter: 2378 loss: 666078.74848516588\n",
            "Iter: 2379 loss: 666030.95460886927\n",
            "tf.Tensor(\n",
            "[-4.73081185e-04  3.23600813e-05  3.54275218e-04 ...  6.94215910e-01\n",
            "  6.05333174e-01 -1.45694938e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.742477729251903\n",
            "Validation loss: 0.8313900484308364\n",
            "Iter: 2380 loss: 665998.441389838\n",
            "Iter: 2381 loss: 665965.69037309848\n",
            "Iter: 2382 loss: 665959.16437856411\n",
            "Iter: 2383 loss: 665905.64710386621\n",
            "Iter: 2384 loss: 666063.17174783\n",
            "Iter: 2385 loss: 665889.22797201411\n",
            "Iter: 2386 loss: 665836.59691195691\n",
            "Iter: 2387 loss: 665958.65076140908\n",
            "Iter: 2388 loss: 665817.117313659\n",
            "Iter: 2389 loss: 665762.66342197289\n",
            "Iter: 2390 loss: 665873.14146548347\n",
            "Iter: 2391 loss: 665740.61372046371\n",
            "Iter: 2392 loss: 665681.90853963036\n",
            "Iter: 2393 loss: 665869.31790104858\n",
            "Iter: 2394 loss: 665665.18738139234\n",
            "tf.Tensor(\n",
            "[-4.48732388e-04  2.07242374e-04  2.37629214e-04 ...  7.06024370e-01\n",
            "  6.16342885e-01 -1.42392508e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7420633745666393\n",
            "Validation loss: 0.8313830079822832\n",
            "Iter: 2395 loss: 665609.95386221516\n",
            "Iter: 2396 loss: 665798.02107296383\n",
            "Iter: 2397 loss: 665595.15307293972\n",
            "Iter: 2398 loss: 665544.39192673191\n",
            "Iter: 2399 loss: 665723.36256440682\n",
            "Iter: 2400 loss: 665531.28909452318\n",
            "Iter: 2401 loss: 665484.1161962396\n",
            "Iter: 2402 loss: 665680.163756425\n",
            "Iter: 2403 loss: 665473.96445902856\n",
            "Iter: 2404 loss: 665429.89912495448\n",
            "Iter: 2405 loss: 665594.31400293787\n",
            "Iter: 2406 loss: 665419.19837023306\n",
            "Iter: 2407 loss: 665379.93033821834\n",
            "Iter: 2408 loss: 665488.47294050083\n",
            "Iter: 2409 loss: 665367.19322729763\n",
            "tf.Tensor(\n",
            "[-4.18168531e-04  3.40988480e-04  1.39022269e-04 ...  7.15765912e-01\n",
            "  6.25209859e-01 -1.39706813e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7417248211647347\n",
            "Validation loss: 0.8313775835692131\n",
            "Iter: 2410 loss: 665330.91565549211\n",
            "Iter: 2411 loss: 665787.78990956838\n",
            "Iter: 2412 loss: 665330.60012300825\n",
            "Iter: 2413 loss: 665306.69389357208\n",
            "Iter: 2414 loss: 665264.2236019792\n",
            "Iter: 2415 loss: 665264.22357725131\n",
            "Iter: 2416 loss: 665216.83356833912\n",
            "Iter: 2417 loss: 665290.02375039237\n",
            "Iter: 2418 loss: 665194.51614391955\n",
            "Iter: 2419 loss: 665141.4640829144\n",
            "Iter: 2420 loss: 665259.78901962074\n",
            "Iter: 2421 loss: 665121.296042521\n",
            "Iter: 2422 loss: 665066.64446763741\n",
            "Iter: 2423 loss: 665224.7634322017\n",
            "Iter: 2424 loss: 665049.62351303012\n",
            "tf.Tensor(\n",
            "[-3.75387190e-04  4.71464827e-04  3.26228440e-05 ...  7.26240661e-01\n",
            "  6.35046988e-01 -1.36737437e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7413622345962532\n",
            "Validation loss: 0.8311394751481588\n",
            "Iter: 2425 loss: 664996.29576165369\n",
            "Iter: 2426 loss: 665119.11515839444\n",
            "Iter: 2427 loss: 664976.4615011086\n",
            "Iter: 2428 loss: 664922.15248085943\n",
            "Iter: 2429 loss: 665092.27251536527\n",
            "Iter: 2430 loss: 664906.41413343966\n",
            "Iter: 2431 loss: 664853.06695252273\n",
            "Iter: 2432 loss: 665010.62212888012\n",
            "Iter: 2433 loss: 664836.7476337878\n",
            "Iter: 2434 loss: 664786.03172590386\n",
            "Iter: 2435 loss: 664996.55969095032\n",
            "Iter: 2436 loss: 664775.13599904487\n",
            "Iter: 2437 loss: 664729.0278607785\n",
            "Iter: 2438 loss: 664922.09753733058\n",
            "Iter: 2439 loss: 664719.19125366956\n",
            "tf.Tensor(\n",
            "[-3.20967852e-04  5.92928008e-04 -7.79114970e-05 ...  7.37342209e-01\n",
            "  6.45325231e-01 -1.33569154e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7409728264017807\n",
            "Validation loss: 0.8310180034540575\n",
            "Iter: 2440 loss: 664676.14307099464\n",
            "Iter: 2441 loss: 664803.6239227436\n",
            "Iter: 2442 loss: 664663.04454831849\n",
            "Iter: 2443 loss: 664629.04102276429\n",
            "Iter: 2444 loss: 664992.86508937785\n",
            "Iter: 2445 loss: 664628.23028426152\n",
            "Iter: 2446 loss: 664595.93700461008\n",
            "Iter: 2447 loss: 664598.62524106738\n",
            "Iter: 2448 loss: 664570.91695945326\n",
            "Iter: 2449 loss: 664535.59166908474\n",
            "Iter: 2450 loss: 664516.989952059\n",
            "Iter: 2451 loss: 664500.8655741585\n",
            "Iter: 2452 loss: 664449.87725034775\n",
            "Iter: 2453 loss: 664574.40518873488\n",
            "Iter: 2454 loss: 664431.70064991713\n",
            "tf.Tensor(\n",
            "[-2.67585457e-04  6.81374557e-04 -1.69225506e-04 ...  7.46962254e-01\n",
            "  6.54404380e-01 -1.30834959e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7406335514413809\n",
            "Validation loss: 0.8310982037548301\n",
            "Iter: 2455 loss: 664379.32851383928\n",
            "Iter: 2456 loss: 664514.67000504059\n",
            "Iter: 2457 loss: 664361.442401655\n",
            "Iter: 2458 loss: 664307.89003264485\n",
            "Iter: 2459 loss: 664436.60573924275\n",
            "Iter: 2460 loss: 664288.57066811225\n",
            "Iter: 2461 loss: 664235.75231810613\n",
            "Iter: 2462 loss: 664363.42757752107\n",
            "Iter: 2463 loss: 664216.7750855796\n",
            "Iter: 2464 loss: 664162.36704531068\n",
            "Iter: 2465 loss: 664352.69354611938\n",
            "Iter: 2466 loss: 664148.2115988282\n",
            "Iter: 2467 loss: 664096.00686830538\n",
            "Iter: 2468 loss: 664249.59733237419\n",
            "Iter: 2469 loss: 664079.96632372856\n",
            "tf.Tensor(\n",
            "[-1.94926813e-04  7.68587485e-04 -2.75022217e-04 ...  7.59102038e-01\n",
            "  6.65790947e-01 -1.27296492e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7402245834161801\n",
            "Validation loss: 0.831020095914006\n",
            "Iter: 2470 loss: 664030.60615312867\n",
            "Iter: 2471 loss: 664249.649083221\n",
            "Iter: 2472 loss: 664020.85105421836\n",
            "Iter: 2473 loss: 663976.72397538053\n",
            "Iter: 2474 loss: 664179.53323379112\n",
            "Iter: 2475 loss: 663968.35469743086\n",
            "Iter: 2476 loss: 663931.12629867531\n",
            "Iter: 2477 loss: 664093.433934618\n",
            "Iter: 2478 loss: 663923.60607363319\n",
            "Iter: 2479 loss: 663887.58133362525\n",
            "Iter: 2480 loss: 664112.28289437538\n",
            "Iter: 2481 loss: 663883.3781765278\n",
            "Iter: 2482 loss: 663857.34408270207\n",
            "Iter: 2483 loss: 663822.05513350328\n",
            "Iter: 2484 loss: 663820.28213156457\n",
            "tf.Tensor(\n",
            "[-1.38621581e-04  8.14645623e-04 -3.45008177e-04 ...  7.68119721e-01\n",
            "  6.74087059e-01 -1.24583102e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7399311718596463\n",
            "Validation loss: 0.8308835498842925\n",
            "Iter: 2485 loss: 663774.21371359238\n",
            "Iter: 2486 loss: 663840.67699608183\n",
            "Iter: 2487 loss: 663751.79663881531\n",
            "Iter: 2488 loss: 663700.28831539478\n",
            "Iter: 2489 loss: 663803.20359788707\n",
            "Iter: 2490 loss: 663679.23872107011\n",
            "Iter: 2491 loss: 663624.91140875791\n",
            "Iter: 2492 loss: 663788.5694645833\n",
            "Iter: 2493 loss: 663608.58050935529\n",
            "Iter: 2494 loss: 663555.03793118976\n",
            "Iter: 2495 loss: 663700.78530086041\n",
            "Iter: 2496 loss: 663537.48100867157\n",
            "Iter: 2497 loss: 663485.63160972192\n",
            "Iter: 2498 loss: 663616.55175009079\n",
            "Iter: 2499 loss: 663467.6004480127\n",
            "tf.Tensor(\n",
            "[-5.88799560e-05  8.52803425e-04 -4.29034672e-04 ...  7.80687988e-01\n",
            "  6.85895813e-01 -1.20782860e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7395212256787521\n",
            "Validation loss: 0.8307301970146087\n",
            "Iter: 2500 loss: 663414.89177548373\n",
            "Iter: 2501 loss: 663595.45990359993\n",
            "Iter: 2502 loss: 663400.86419785337\n",
            "Iter: 2503 loss: 663350.86497891252\n",
            "Iter: 2504 loss: 663502.47667524987\n",
            "Iter: 2505 loss: 663335.92011192674\n",
            "Iter: 2506 loss: 663287.97281171882\n",
            "Iter: 2507 loss: 663490.70660137\n",
            "Iter: 2508 loss: 663277.90730669152\n",
            "Iter: 2509 loss: 663235.504615196\n",
            "Iter: 2510 loss: 663484.94501679938\n",
            "Iter: 2511 loss: 663229.98818135879\n",
            "Iter: 2512 loss: 663196.16883337824\n",
            "Iter: 2513 loss: 663423.58511601621\n",
            "Iter: 2514 loss: 663192.78514041589\n",
            "tf.Tensor(\n",
            "[ 3.34970660e-06  8.62066433e-04 -4.83172656e-04 ...  7.90532509e-01\n",
            "  6.94977780e-01 -1.17791982e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7392005661995609\n",
            "Validation loss: 0.830631004581771\n",
            "Iter: 2515 loss: 663160.28762030357\n",
            "Iter: 2516 loss: 663165.31230094517\n",
            "Iter: 2517 loss: 663135.71268235671\n",
            "Iter: 2518 loss: 663099.72467948822\n",
            "Iter: 2519 loss: 663088.01147889718\n",
            "Iter: 2520 loss: 663067.104249224\n",
            "Iter: 2521 loss: 663015.81214431522\n",
            "Iter: 2522 loss: 663137.63129788346\n",
            "Iter: 2523 loss: 662997.14457162423\n",
            "Iter: 2524 loss: 662945.33354800777\n",
            "Iter: 2525 loss: 663051.26590569946\n",
            "Iter: 2526 loss: 662924.47603541892\n",
            "Iter: 2527 loss: 662870.72463823238\n",
            "Iter: 2528 loss: 663041.00055018032\n",
            "Iter: 2529 loss: 662855.30041789555\n",
            "tf.Tensor(\n",
            "[ 7.82886109e-05  8.49808831e-04 -5.35316673e-04 ...  8.02718555e-01\n",
            "  7.06480592e-01 -1.13972447e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7387917299318202\n",
            "Validation loss: 0.8308207700516143\n",
            "Iter: 2530 loss: 662802.8901815369\n",
            "Iter: 2531 loss: 662943.39739456552\n",
            "Iter: 2532 loss: 662785.49966786127\n",
            "Iter: 2533 loss: 662734.46796959138\n",
            "Iter: 2534 loss: 662898.43457956472\n",
            "Iter: 2535 loss: 662720.013288458\n",
            "Iter: 2536 loss: 662670.22157554969\n",
            "Iter: 2537 loss: 662792.03129662026\n",
            "Iter: 2538 loss: 662652.48742392159\n",
            "Iter: 2539 loss: 662601.62229391921\n",
            "Iter: 2540 loss: 662745.8185051647\n",
            "Iter: 2541 loss: 662585.49174766254\n",
            "Iter: 2542 loss: 662538.28724749747\n",
            "Iter: 2543 loss: 662866.46023936663\n",
            "Iter: 2544 loss: 662533.91313573939\n",
            "tf.Tensor(\n",
            "[ 1.46553192e-04  8.13936014e-04 -5.69044331e-04 ...  8.14540305e-01\n",
            "  7.17554535e-01 -1.10244308e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7383964617774357\n",
            "Validation loss: 0.8307775142063827\n",
            "Iter: 2545 loss: 662496.62678730418\n",
            "Iter: 2546 loss: 662750.47931519977\n",
            "Iter: 2547 loss: 662492.9693001816\n",
            "Iter: 2548 loss: 662460.79087597865\n",
            "Iter: 2549 loss: 662571.24019993679\n",
            "Iter: 2550 loss: 662452.27225549787\n",
            "Iter: 2551 loss: 662422.447298058\n",
            "Iter: 2552 loss: 662394.46226644819\n",
            "Iter: 2553 loss: 662387.5041687882\n",
            "Iter: 2554 loss: 662343.37144449109\n",
            "Iter: 2555 loss: 662407.30401505809\n",
            "Iter: 2556 loss: 662321.94009872421\n",
            "Iter: 2557 loss: 662271.91388935107\n",
            "Iter: 2558 loss: 662357.33464991418\n",
            "Iter: 2559 loss: 662249.53129997593\n",
            "tf.Tensor(\n",
            "[ 2.01895620e-04  7.63645945e-04 -5.84565772e-04 ...  8.25052728e-01\n",
            "  7.27354730e-01 -1.06974560e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7380549254583112\n",
            "Validation loss: 0.830721518824291\n",
            "Iter: 2560 loss: 662194.883574108\n",
            "Iter: 2561 loss: 662338.1299217894\n",
            "Iter: 2562 loss: 662176.4168857967\n",
            "Iter: 2563 loss: 662121.2196116593\n",
            "Iter: 2564 loss: 662303.251748302\n",
            "Iter: 2565 loss: 662105.96378434147\n",
            "Iter: 2566 loss: 662053.74668684031\n",
            "Iter: 2567 loss: 662217.17480513523\n",
            "Iter: 2568 loss: 662038.57846668735\n",
            "Iter: 2569 loss: 661988.701141511\n",
            "Iter: 2570 loss: 662122.07552892179\n",
            "Iter: 2571 loss: 661972.11948081164\n",
            "Iter: 2572 loss: 661921.5906029524\n",
            "Iter: 2573 loss: 662041.82898054738\n",
            "Iter: 2574 loss: 661903.23513444245\n",
            "tf.Tensor(\n",
            "[ 2.62335224e-04  6.81173687e-04 -5.86159553e-04 ...  8.38102347e-01\n",
            "  7.39607331e-01 -1.02961444e-01], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.737645320236206\n",
            "Validation loss: 0.8307524774551582\n",
            "Iter: 2575 loss: 661854.43790645048\n",
            "Iter: 2576 loss: 662034.68304022541\n",
            "Iter: 2577 loss: 661842.40263166337\n",
            "Iter: 2578 loss: 661802.04812801024\n",
            "Iter: 2579 loss: 662199.58005440794\n",
            "Iter: 2580 loss: 661800.69125491334\n",
            "Iter: 2581 loss: 661766.74250009866\n",
            "Iter: 2582 loss: 661925.20854670741\n",
            "Iter: 2583 loss: 661760.43113898463\n",
            "Iter: 2584 loss: 661730.64837408462\n",
            "Iter: 2585 loss: 661755.01397401688\n",
            "Iter: 2586 loss: 661712.86402777757\n",
            "Iter: 2587 loss: 661678.62347745523\n",
            "Iter: 2588 loss: 661667.06714704074\n",
            "Iter: 2589 loss: 661647.42344615445\n",
            "tf.Tensor(\n",
            "[ 3.00381635e-04  6.06632878e-04 -5.74551138e-04 ...  8.47809488e-01\n",
            "  7.48535359e-01 -9.99230120e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7373485205264104\n",
            "Validation loss: 0.8306064884736927\n",
            "Iter: 2590 loss: 661600.63705551822\n",
            "Iter: 2591 loss: 661690.630804744\n",
            "Iter: 2592 loss: 661581.08461213124\n",
            "Iter: 2593 loss: 661529.3180029802\n",
            "Iter: 2594 loss: 661635.32767647528\n",
            "Iter: 2595 loss: 661508.48882822355\n",
            "Iter: 2596 loss: 661454.50063155382\n",
            "Iter: 2597 loss: 661601.7344588479\n",
            "Iter: 2598 loss: 661436.82649394381\n",
            "Iter: 2599 loss: 661384.075021112\n",
            "Iter: 2600 loss: 661558.2143483893\n",
            "Iter: 2601 loss: 661369.5081814588\n",
            "Iter: 2602 loss: 661316.889192542\n",
            "Iter: 2603 loss: 661465.87970776518\n",
            "Iter: 2604 loss: 661300.19295214966\n",
            "tf.Tensor(\n",
            "[ 3.41998131e-04  4.89721247e-04 -5.42133858e-04 ...  8.61049234e-01\n",
            "  7.61007777e-01 -9.57030009e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7369570534510832\n",
            "Validation loss: 0.8307527486750597\n",
            "Iter: 2605 loss: 661250.05504556675\n",
            "Iter: 2606 loss: 661358.73459052853\n",
            "Iter: 2607 loss: 661230.62139996386\n",
            "Iter: 2608 loss: 661177.60550828383\n",
            "Iter: 2609 loss: 661324.84421891766\n",
            "Iter: 2610 loss: 661160.53895628685\n",
            "Iter: 2611 loss: 661112.05931416154\n",
            "Iter: 2612 loss: 661388.766843194\n",
            "Iter: 2613 loss: 661105.40368506359\n",
            "Iter: 2614 loss: 661067.54758266883\n",
            "Iter: 2615 loss: 661530.56322549749\n",
            "Iter: 2616 loss: 661067.135262415\n",
            "Iter: 2617 loss: 661037.55408715585\n",
            "Iter: 2618 loss: 661065.28499351861\n",
            "Iter: 2619 loss: 661020.53877839178\n",
            "tf.Tensor(\n",
            "[ 3.66755728e-04  3.85881909e-04 -5.03735484e-04 ...  8.71728621e-01\n",
            "  7.70996441e-01 -9.23154062e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7366352269276109\n",
            "Validation loss: 0.8304228298116524\n",
            "Iter: 2620 loss: 660985.91068228416\n",
            "Iter: 2621 loss: 660993.51850366115\n",
            "Iter: 2622 loss: 660960.383245005\n",
            "Iter: 2623 loss: 660916.28629819164\n",
            "Iter: 2624 loss: 660963.80119402532\n",
            "Iter: 2625 loss: 660892.11576888524\n",
            "Iter: 2626 loss: 660843.05478819378\n",
            "Iter: 2627 loss: 660949.91562331724\n",
            "Iter: 2628 loss: 660824.09987258574\n",
            "Iter: 2629 loss: 660773.227602415\n",
            "Iter: 2630 loss: 660919.09619350964\n",
            "Iter: 2631 loss: 660757.26099247765\n",
            "Iter: 2632 loss: 660706.21002154611\n",
            "Iter: 2633 loss: 660830.11065949069\n",
            "Iter: 2634 loss: 660687.91842437373\n",
            "tf.Tensor(\n",
            "[ 3.86271259e-04  2.53337285e-04 -4.45210606e-04 ...  8.84679479e-01\n",
            "  7.83149139e-01 -8.81351663e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7362406367586933\n",
            "Validation loss: 0.8306052131935058\n",
            "Iter: 2635 loss: 660637.05091822136\n",
            "Iter: 2636 loss: 660793.85937464365\n",
            "Iter: 2637 loss: 660622.08642823016\n",
            "Iter: 2638 loss: 660573.32812038972\n",
            "Iter: 2639 loss: 660664.21871979663\n",
            "Iter: 2640 loss: 660552.55060590548\n",
            "Iter: 2641 loss: 660500.68156353373\n",
            "Iter: 2642 loss: 660625.16070241434\n",
            "Iter: 2643 loss: 660481.95535100042\n",
            "Iter: 2644 loss: 660429.56151139422\n",
            "Iter: 2645 loss: 660625.52580706333\n",
            "Iter: 2646 loss: 660416.88216808543\n",
            "Iter: 2647 loss: 660378.02959770639\n",
            "Iter: 2648 loss: 660859.31287593488\n",
            "Iter: 2649 loss: 660377.63539864135\n",
            "tf.Tensor(\n",
            "[ 3.93227890e-04  1.25428869e-04 -3.79386243e-04 ...  8.96884639e-01\n",
            "  7.94662340e-01 -8.40977023e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7358760919609895\n",
            "Validation loss: 0.8305828717985105\n",
            "Iter: 2650 loss: 660341.62053926068\n",
            "Iter: 2651 loss: 660472.25315227651\n",
            "Iter: 2652 loss: 660332.6022094225\n",
            "Iter: 2653 loss: 660302.736629145\n",
            "Iter: 2654 loss: 660315.9265212199\n",
            "Iter: 2655 loss: 660282.38184620359\n",
            "Iter: 2656 loss: 660243.52842847165\n",
            "Iter: 2657 loss: 660269.0419604152\n",
            "Iter: 2658 loss: 660218.988880677\n",
            "Iter: 2659 loss: 660174.15977902256\n",
            "Iter: 2660 loss: 660253.95540882566\n",
            "Iter: 2661 loss: 660154.56238001911\n",
            "Iter: 2662 loss: 660105.59335341\n",
            "Iter: 2663 loss: 660203.09496804816\n",
            "Iter: 2664 loss: 660085.5484358822\n",
            "tf.Tensor(\n",
            "[ 3.89775217e-04  4.72028728e-06 -3.09383150e-04 ...  9.08432808e-01\n",
            "  8.05341210e-01 -8.02683191e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7355534235015003\n",
            "Validation loss: 0.8306541913448339\n",
            "Iter: 2665 loss: 660034.965611969\n",
            "Iter: 2666 loss: 660162.515072366\n",
            "Iter: 2667 loss: 660017.366806546\n",
            "Iter: 2668 loss: 659964.59740163584\n",
            "Iter: 2669 loss: 660125.35003268393\n",
            "Iter: 2670 loss: 659948.88774287188\n",
            "Iter: 2671 loss: 659898.13522812235\n",
            "Iter: 2672 loss: 660017.993494743\n",
            "Iter: 2673 loss: 659879.60138443194\n",
            "Iter: 2674 loss: 659827.68663031515\n",
            "Iter: 2675 loss: 659974.42728777626\n",
            "Iter: 2676 loss: 659811.18244814768\n",
            "Iter: 2677 loss: 659761.64451220143\n",
            "Iter: 2678 loss: 659879.90070747479\n",
            "Iter: 2679 loss: 659743.67678803112\n",
            "tf.Tensor(\n",
            "[ 3.74189902e-04 -1.35050282e-04 -2.19206095e-04 ...  9.22155070e-01\n",
            "  8.18347146e-01 -7.57852469e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7351944824760778\n",
            "Validation loss: 0.8306056443098007\n",
            "Iter: 2680 loss: 659694.46696043317\n",
            "Iter: 2681 loss: 659953.7094014826\n",
            "Iter: 2682 loss: 659686.86664676829\n",
            "Iter: 2683 loss: 659654.0064964823\n",
            "Iter: 2684 loss: 659654.006448286\n",
            "Iter: 2685 loss: 659624.11823284067\n",
            "Iter: 2686 loss: 659617.80391843652\n",
            "Iter: 2687 loss: 659598.226573908\n",
            "Iter: 2688 loss: 659561.625706619\n",
            "Iter: 2689 loss: 659600.14619069709\n",
            "Iter: 2690 loss: 659541.39237119083\n",
            "Iter: 2691 loss: 659496.87811785075\n",
            "Iter: 2692 loss: 659613.28778390924\n",
            "Iter: 2693 loss: 659481.8233382646\n",
            "tf.Tensor(\n",
            "[ 3.54143285e-04 -2.36492938e-04 -1.46882904e-04 ...  9.32616546e-01\n",
            "  8.28111186e-01 -7.22858155e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7349376327730939\n",
            "Validation loss: 0.8308771744277166\n",
            "Iter: 2694 loss: 659438.078119881\n",
            "Iter: 2695 loss: 659486.14282381744\n",
            "Iter: 2696 loss: 659414.26717232028\n",
            "Iter: 2697 loss: 659364.20339448354\n",
            "Iter: 2698 loss: 659441.66188846331\n",
            "Iter: 2699 loss: 659340.64110400539\n",
            "Iter: 2700 loss: 659287.51827661111\n",
            "Iter: 2701 loss: 659447.67359599273\n",
            "Iter: 2702 loss: 659271.56501155044\n",
            "Iter: 2703 loss: 659219.05153452442\n",
            "Iter: 2704 loss: 659358.84424918285\n",
            "Iter: 2705 loss: 659201.52906935755\n",
            "Iter: 2706 loss: 659148.91522732994\n",
            "Iter: 2707 loss: 659278.990120552\n",
            "Iter: 2708 loss: 659130.32860835444\n",
            "tf.Tensor(\n",
            "[ 3.17520342e-04 -3.63498288e-04 -4.72649360e-05 ...  9.46791247e-01\n",
            "  8.41516119e-01 -6.74681256e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7345863154335786\n",
            "Validation loss: 0.8306554997740839\n",
            "Iter: 2709 loss: 659078.30118296167\n",
            "Iter: 2710 loss: 659237.52195992845\n",
            "Iter: 2711 loss: 659062.88558122632\n",
            "Iter: 2712 loss: 659012.0451329411\n",
            "Iter: 2713 loss: 659159.25379524822\n",
            "Iter: 2714 loss: 658996.20470904827\n",
            "Iter: 2715 loss: 658955.92793599959\n",
            "Iter: 2716 loss: 659409.159448459\n",
            "Iter: 2717 loss: 658955.19204647513\n",
            "Iter: 2718 loss: 658918.47282534523\n",
            "Iter: 2719 loss: 659104.2561216969\n",
            "Iter: 2720 loss: 658912.39210795634\n",
            "Iter: 2721 loss: 658884.87505350274\n",
            "Iter: 2722 loss: 658863.13751416735\n",
            "Iter: 2723 loss: 658854.67991913564\n",
            "tf.Tensor(\n",
            "[ 2.81207675e-04 -4.53675940e-04  3.15802061e-05 ...  9.58153806e-01\n",
            "  8.52251222e-01 -6.36712085e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7343076231577285\n",
            "Validation loss: 0.830665838550947\n",
            "Iter: 2724 loss: 658812.40897552378\n",
            "Iter: 2725 loss: 658933.715194233\n",
            "Iter: 2726 loss: 658799.16234299273\n",
            "Iter: 2727 loss: 658756.08852685\n",
            "Iter: 2728 loss: 658848.3872635006\n",
            "Iter: 2729 loss: 658739.27360289823\n",
            "Iter: 2730 loss: 658695.4680642843\n",
            "Iter: 2731 loss: 658745.6399403715\n",
            "Iter: 2732 loss: 658672.00125696161\n",
            "Iter: 2733 loss: 658620.89429331641\n",
            "Iter: 2734 loss: 658723.24074352346\n",
            "Iter: 2735 loss: 658600.05065712286\n",
            "Iter: 2736 loss: 658548.49332613836\n",
            "Iter: 2737 loss: 658715.451086741\n",
            "Iter: 2738 loss: 658534.00612374151\n",
            "tf.Tensor(\n",
            "[ 2.32307166e-04 -5.44408814e-04  1.20641436e-04 ...  9.71503721e-01\n",
            "  8.64669537e-01 -5.92900994e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.733991574844075\n",
            "Validation loss: 0.8304617236663597\n",
            "Iter: 2739 loss: 658484.26247832074\n",
            "Iter: 2740 loss: 658614.75459798565\n",
            "Iter: 2741 loss: 658467.45869009988\n",
            "Iter: 2742 loss: 658416.25278060022\n",
            "Iter: 2743 loss: 658539.7436371214\n",
            "Iter: 2744 loss: 658397.84111111041\n",
            "Iter: 2745 loss: 658347.14194854326\n",
            "Iter: 2746 loss: 658512.79645811976\n",
            "Iter: 2747 loss: 658333.01356638945\n",
            "Iter: 2748 loss: 658283.762334076\n",
            "Iter: 2749 loss: 658395.63638000644\n",
            "Iter: 2750 loss: 658265.2398948645\n",
            "Iter: 2751 loss: 658234.74584866129\n",
            "Iter: 2752 loss: 658233.32491917419\n",
            "tf.Tensor(\n",
            "[ 1.80787664e-04 -6.14524467e-04  2.00271275e-04 ...  9.84236234e-01\n",
            "  8.76716144e-01 -5.50409118e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7337093572867837\n",
            "Validation loss: 0.8306526669828785\n",
            "Iter: 2753 loss: 658202.26185748889\n",
            "Iter: 2754 loss: 658205.159771597\n",
            "Iter: 2755 loss: 658178.24070528836\n",
            "Iter: 2756 loss: 658145.61367874057\n",
            "Iter: 2757 loss: 658131.018688109\n",
            "Iter: 2758 loss: 658114.57052619359\n",
            "Iter: 2759 loss: 658068.97608187259\n",
            "Iter: 2760 loss: 658361.91315109353\n",
            "Iter: 2761 loss: 658063.973306747\n",
            "Iter: 2762 loss: 658024.26154209813\n",
            "Iter: 2763 loss: 658071.50000172667\n",
            "Iter: 2764 loss: 658003.28782655345\n",
            "Iter: 2765 loss: 657959.75789580785\n",
            "Iter: 2766 loss: 658006.56377130176\n",
            "Iter: 2767 loss: 657935.88137592084\n",
            "tf.Tensor(\n",
            "[ 1.25695944e-04 -6.67850157e-04  2.73353312e-04 ...  9.96996821e-01\n",
            "  8.88574733e-01 -5.07923196e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7334413526150502\n",
            "Validation loss: 0.8306440120594394\n",
            "Iter: 2768 loss: 657884.34597361623\n",
            "Iter: 2769 loss: 658018.61143288948\n",
            "Iter: 2770 loss: 657866.85599102126\n",
            "Iter: 2771 loss: 657815.69620342914\n",
            "Iter: 2772 loss: 657922.2309095572\n",
            "Iter: 2773 loss: 657795.34124518372\n",
            "Iter: 2774 loss: 657742.15756035282\n",
            "Iter: 2775 loss: 657948.32605474023\n",
            "Iter: 2776 loss: 657729.75384096848\n",
            "Iter: 2777 loss: 657681.12626148143\n",
            "Iter: 2778 loss: 657799.89706608269\n",
            "Iter: 2779 loss: 657663.80287239933\n",
            "Iter: 2780 loss: 657614.40945826389\n",
            "Iter: 2781 loss: 657760.4726423\n",
            "Iter: 2782 loss: 657599.32950572181\n",
            "tf.Tensor(\n",
            "[ 6.00981656e-05 -7.07170045e-04  3.46896416e-04 ...  1.01164883e+00\n",
            "  9.02427482e-01 -4.60215781e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7331521857623369\n",
            "Validation loss: 0.8308246070092253\n",
            "Iter: 2783 loss: 657554.04575473431\n",
            "Iter: 2784 loss: 657766.336913613\n",
            "Iter: 2785 loss: 657545.67214676924\n",
            "Iter: 2786 loss: 657511.7006256103\n",
            "Iter: 2787 loss: 657511.55295777088\n",
            "Iter: 2788 loss: 657489.42883231817\n",
            "Iter: 2789 loss: 657445.8411723543\n",
            "Iter: 2790 loss: 658307.31083621481\n",
            "Iter: 2791 loss: 657445.43404639058\n",
            "Iter: 2792 loss: 657399.12611233315\n",
            "Iter: 2793 loss: 657543.31187304109\n",
            "Iter: 2794 loss: 657385.62122436566\n",
            "Iter: 2795 loss: 657341.16451329994\n",
            "Iter: 2796 loss: 657562.42294097471\n",
            "Iter: 2797 loss: 657333.65894232958\n",
            "tf.Tensor(\n",
            "[ 7.83509268e-06 -7.20847304e-04  3.95651332e-04 ...  1.02326546e+00\n",
            "  9.13323551e-01 -4.22270001e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7329272702917085\n",
            "Validation loss: 0.8307546736367084\n",
            "Iter: 2798 loss: 657293.04114340874\n",
            "Iter: 2799 loss: 657323.96358066145\n",
            "Iter: 2800 loss: 657268.28648467292\n",
            "Iter: 2801 loss: 657222.99210250634\n",
            "Iter: 2802 loss: 657294.83470587479\n",
            "Iter: 2803 loss: 657201.94862770161\n",
            "Iter: 2804 loss: 657151.82928175479\n",
            "Iter: 2805 loss: 657295.34459037916\n",
            "Iter: 2806 loss: 657136.09394028888\n",
            "Iter: 2807 loss: 657086.55489475559\n",
            "Iter: 2808 loss: 657201.01831418835\n",
            "Iter: 2809 loss: 657068.18248521618\n",
            "Iter: 2810 loss: 657017.65280444222\n",
            "Iter: 2811 loss: 657154.62762543024\n",
            "Iter: 2812 loss: 657001.04338820733\n",
            "tf.Tensor(\n",
            "[-5.74367510e-05 -7.17132137e-04  4.44949158e-04 ...  1.03816620e+00\n",
            "  9.27178462e-01 -3.72552971e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7326436701963448\n",
            "Validation loss: 0.8306634273228688\n",
            "Iter: 2813 loss: 656950.45385885867\n",
            "Iter: 2814 loss: 657120.7917723367\n",
            "Iter: 2815 loss: 656936.76878240576\n",
            "Iter: 2816 loss: 656888.89359205961\n",
            "Iter: 2817 loss: 657026.78812117153\n",
            "Iter: 2818 loss: 656873.96840804117\n",
            "Iter: 2819 loss: 656841.12673524837\n",
            "Iter: 2820 loss: 656841.03061456408\n",
            "Iter: 2821 loss: 656807.89461283351\n",
            "Iter: 2822 loss: 656825.09446838917\n",
            "Iter: 2823 loss: 656785.9564666365\n",
            "Iter: 2824 loss: 656753.76116154762\n",
            "Iter: 2825 loss: 656730.11775853834\n",
            "Iter: 2826 loss: 656719.25159937609\n",
            "tf.Tensor(\n",
            "[-1.09632553e-04 -6.95196796e-04  4.73799817e-04 ...  1.05075147e+00\n",
            "  9.38984279e-01 -3.30856192e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7324099736604289\n",
            "Validation loss: 0.8306592618078169\n",
            "Iter: 2827 loss: 656672.49791935878\n",
            "Iter: 2828 loss: 656898.60715384933\n",
            "Iter: 2829 loss: 656664.26910260343\n",
            "Iter: 2830 loss: 656620.44145358785\n",
            "Iter: 2831 loss: 656779.02269620262\n",
            "Iter: 2832 loss: 656609.43302727025\n",
            "Iter: 2833 loss: 656570.18358727929\n",
            "Iter: 2834 loss: 656596.37440806231\n",
            "Iter: 2835 loss: 656545.48163429822\n",
            "Iter: 2836 loss: 656497.93179336912\n",
            "Iter: 2837 loss: 656598.95878847688\n",
            "Iter: 2838 loss: 656479.25862023316\n",
            "Iter: 2839 loss: 656429.943834703\n",
            "Iter: 2840 loss: 656567.09186480008\n",
            "Iter: 2841 loss: 656414.078238991\n",
            "tf.Tensor(\n",
            "[-1.63113490e-04 -6.53170073e-04  4.92462457e-04 ...  1.06465367e+00\n",
            "  9.51792094e-01 -2.84826498e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7321787321787602\n",
            "Validation loss: 0.83077410636304\n",
            "Iter: 2842 loss: 656364.48714570922\n",
            "Iter: 2843 loss: 656499.09158408525\n",
            "Iter: 2844 loss: 656348.19560235436\n",
            "Iter: 2845 loss: 656299.131432002\n",
            "Iter: 2846 loss: 656445.12465611484\n",
            "Iter: 2847 loss: 656284.219158936\n",
            "Iter: 2848 loss: 656236.12349693466\n",
            "Iter: 2849 loss: 656349.218120775\n",
            "Iter: 2850 loss: 656218.5015438518\n",
            "Iter: 2851 loss: 656170.402925625\n",
            "Iter: 2852 loss: 656351.46178860159\n",
            "Iter: 2853 loss: 656158.85568542\n",
            "Iter: 2854 loss: 656133.55080628756\n",
            "Iter: 2855 loss: 656130.71406119072\n",
            "tf.Tensor(\n",
            "[-2.07377397e-04 -5.98381472e-04  4.96757545e-04 ...  1.07748085e+00\n",
            "  9.63859498e-01 -2.40441359e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7319866319515531\n",
            "Validation loss: 0.8308134793101398\n",
            "Iter: 2856 loss: 656108.66461521864\n",
            "Iter: 2857 loss: 656064.14361449936\n",
            "Iter: 2858 loss: 656885.58269349986\n",
            "Iter: 2859 loss: 656063.48194468592\n",
            "Iter: 2860 loss: 656017.640503237\n",
            "Iter: 2861 loss: 656105.57314395823\n",
            "Iter: 2862 loss: 655998.45251555729\n",
            "Iter: 2863 loss: 655951.60897249449\n",
            "Iter: 2864 loss: 656162.03981408442\n",
            "Iter: 2865 loss: 655942.47666276176\n",
            "Iter: 2866 loss: 655898.80039773858\n",
            "Iter: 2867 loss: 656061.26229352935\n",
            "Iter: 2868 loss: 655888.15107736841\n",
            "Iter: 2869 loss: 655848.16768822086\n",
            "Iter: 2870 loss: 655885.51764502248\n",
            "Iter: 2871 loss: 655825.18616152345\n",
            "tf.Tensor(\n",
            "[-2.48045540e-04 -5.24870695e-04  4.87786588e-04 ...  1.09118381e+00\n",
            "  9.76613150e-01 -1.92288092e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7317915900149001\n",
            "Validation loss: 0.8308685034486789\n",
            "Iter: 2872 loss: 655779.08551074227\n",
            "Iter: 2873 loss: 655888.48745809321\n",
            "Iter: 2874 loss: 655762.29698780924\n",
            "Iter: 2875 loss: 655714.02485676855\n",
            "Iter: 2876 loss: 655812.06106226658\n",
            "Iter: 2877 loss: 655694.51766939112\n",
            "Iter: 2878 loss: 655645.14442897891\n",
            "Iter: 2879 loss: 655774.17117901193\n",
            "Iter: 2880 loss: 655628.43342238571\n",
            "Iter: 2881 loss: 655578.30528916256\n",
            "Iter: 2882 loss: 655704.06559324812\n",
            "Iter: 2883 loss: 655560.7860663227\n",
            "Iter: 2884 loss: 655510.57998311578\n",
            "Iter: 2885 loss: 655663.12294563255\n",
            "Iter: 2886 loss: 655495.59618570539\n",
            "tf.Tensor(\n",
            "[-2.83958043e-04 -4.29360743e-04  4.62810091e-04 ...  1.10633369e+00\n",
            "  9.90704745e-01 -1.39521234e-02], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.731582381405843\n",
            "Validation loss: 0.8308430045119642\n",
            "Iter: 2887 loss: 655457.64097673469\n",
            "Iter: 2888 loss: 655935.36695898138\n",
            "Iter: 2889 loss: 655457.312139872\n",
            "Iter: 2890 loss: 655419.71778935427\n",
            "Iter: 2891 loss: 655548.57391558948\n",
            "Iter: 2892 loss: 655409.69732119271\n",
            "Iter: 2893 loss: 655384.64624347177\n",
            "Iter: 2894 loss: 655342.76500383043\n",
            "Iter: 2895 loss: 655342.64418501209\n",
            "Iter: 2896 loss: 655294.26091798046\n",
            "Iter: 2897 loss: 655492.74319732829\n",
            "Iter: 2898 loss: 655283.71395434206\n",
            "Iter: 2899 loss: 655239.26678898488\n",
            "Iter: 2900 loss: 655452.86789143027\n",
            "Iter: 2901 loss: 655231.37414568779\n",
            "tf.Tensor(\n",
            "[-3.05839972e-04 -3.42660227e-04  4.31702164e-04 ...  1.11875666e+00\n",
            "  1.00230197e+00 -9.60675039e-03], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7314097666758316\n",
            "Validation loss: 0.8310832606189771\n",
            "Iter: 2902 loss: 655191.01073718257\n",
            "Iter: 2903 loss: 655281.05622258375\n",
            "Iter: 2904 loss: 655175.68144706741\n",
            "Iter: 2905 loss: 655133.95265697327\n",
            "Iter: 2906 loss: 655192.24812306243\n",
            "Iter: 2907 loss: 655113.35440981551\n",
            "Iter: 2908 loss: 655068.82860473683\n",
            "Iter: 2909 loss: 655192.60521351022\n",
            "Iter: 2910 loss: 655054.50102376856\n",
            "Iter: 2911 loss: 655009.63811317133\n",
            "Iter: 2912 loss: 655093.99041343667\n",
            "Iter: 2913 loss: 654990.63521785149\n",
            "Iter: 2914 loss: 654943.51938025327\n",
            "Iter: 2915 loss: 655058.20396447589\n",
            "Iter: 2916 loss: 654926.70116071624\n",
            "tf.Tensor(\n",
            "[-3.22078962e-04 -2.34774007e-04  3.84343842e-04 ...  1.13320509e+00\n",
            "  1.01552941e+00 -4.38856752e-03], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.731214611924359\n",
            "Validation loss: 0.8309807393497668\n",
            "Iter: 2917 loss: 654878.94172741263\n",
            "Iter: 2918 loss: 655035.48304961133\n",
            "Iter: 2919 loss: 654865.68475884316\n",
            "Iter: 2920 loss: 654820.72270187072\n",
            "Iter: 2921 loss: 654962.69490692578\n",
            "Iter: 2922 loss: 654807.74598139292\n",
            "Iter: 2923 loss: 654782.9310517488\n",
            "Iter: 2924 loss: 654780.54590220109\n",
            "Iter: 2925 loss: 654756.55872080964\n",
            "Iter: 2926 loss: 654723.0142013852\n",
            "Iter: 2927 loss: 654721.66653485352\n",
            "Iter: 2928 loss: 654683.64352578949\n",
            "Iter: 2929 loss: 654704.13851053477\n",
            "Iter: 2930 loss: 654658.63220239663\n",
            "tf.Tensor(\n",
            "[-3.27633337e-04 -1.35486149e-04  3.33369692e-04 ...  1.14592486e+00\n",
            "  1.02741844e+00  2.58436714e-04], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7310629026667063\n",
            "Validation loss: 0.8310699703112233\n",
            "Iter: 2931 loss: 654612.1039315362\n",
            "Iter: 2932 loss: 654763.58172331122\n",
            "Iter: 2933 loss: 654599.0881775443\n",
            "Iter: 2934 loss: 654554.957979593\n",
            "Iter: 2935 loss: 654707.89464363339\n",
            "Iter: 2936 loss: 654543.3467649736\n",
            "Iter: 2937 loss: 654501.90451980231\n",
            "Iter: 2938 loss: 654693.25694866665\n",
            "Iter: 2939 loss: 654494.129906422\n",
            "Iter: 2940 loss: 654455.33798847569\n",
            "Iter: 2941 loss: 654492.20829487941\n",
            "Iter: 2942 loss: 654433.16172901262\n",
            "Iter: 2943 loss: 654390.3227231988\n",
            "Iter: 2944 loss: 654453.04126026924\n",
            "Iter: 2945 loss: 654369.62442691484\n",
            "tf.Tensor(\n",
            "[-3.24892339e-04 -2.53717012e-05  2.69832108e-04 ...  1.15984676e+00\n",
            "  1.04028492e+00  5.30477171e-03], shape=(6367440,), dtype=float64)\n",
            "Real training loss: 0.7309156798977012\n",
            "Validation loss: 0.8309688834090088\n",
            "Iter: 2946 loss: 654321.09409131412\n",
            "Iter: 2947 loss: 654436.4440998924\n",
            "Iter: 2948 loss: 654303.43672349548\n",
            "Iter: 2949 loss: 654254.22558650747\n",
            "Iter: 2950 loss: 654377.13479788962\n",
            "Iter: 2951 loss: 654236.98304887651\n",
            "Iter: 2952 loss: 654188.198128012\n",
            "Iter: 2953 loss: 654369.501166435\n",
            "Iter: 2954 loss: 654176.3021074998\n",
            "Iter: 2955 loss: 654138.33140379621\n",
            "Iter: 2956 loss: 654519.45704004576\n",
            "Iter: 2957 loss: 654137.11771338456\n",
            "Iter: 2958 loss: 654102.52540560067\n",
            "Iter: 2959 loss: 654313.470577174\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7fd8beb6a138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# We just call optimize here. The adapter will handle actually updating our variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0moptim_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# The rest of the code is to just output actual training score and validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1a939fb5bce7>\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minitial_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         self.results = tfp.optimizer.lbfgs_minimize(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mvalue_and_gradients_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0minitial_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/lbfgs.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(value_and_gradients_function, initial_position, previous_optimizer_results, num_correction_pairs, tolerance, x_tolerance, f_relative_tolerance, initial_inverse_hessian_estimate, max_iterations, parallel_iterations, stopping_condition, max_line_search_iterations, f_absolute_tolerance, name)\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_optimizer_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     return tf.while_loop(\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m   \"\"\"\n\u001b[0;32m-> 2507\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2508\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2752\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2753\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2754\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/lbfgs.py\u001b[0m in \u001b[0;36m_body\u001b[0;34m(current_state)\u001b[0m\n\u001b[1;32m    257\u001b[0m       \u001b[0;31m# search direction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       next_state = bfgs_utils.line_search_step(\n\u001b[0m\u001b[1;32m    260\u001b[0m           \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_and_gradients_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_direction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m           \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_relative_tolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_condition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/bfgs_utils.py\u001b[0m in \u001b[0;36mline_search_step\u001b[0;34m(state, value_and_gradients_function, search_direction, grad_tolerance, f_relative_tolerance, x_tolerance, stopping_condition, max_iterations, f_absolute_tolerance)\u001b[0m\n\u001b[1;32m    207\u001b[0m                            full_gradient=state.objective_gradient)\n\u001b[1;32m    208\u001b[0m   \u001b[0minactive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m   ls_result = linesearch.hager_zhang(\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0mline_search_value_grad_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0minitial_step_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py\u001b[0m in \u001b[0;36mhager_zhang\u001b[0;34m(value_and_gradients_function, initial_step_size, value_at_initial_step, value_at_zero, converged, threshold_use_approximate_wolfe_condition, shrinkage_param, expansion_param, sufficient_decrease_param, curvature_param, max_iterations, name)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minit_active\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0minit_interval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0minit_interval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     return prefer_static.cond(\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0m_apply_bracket_and_search\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/internal/prefer_static.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py\u001b[0m in \u001b[0;36m_apply_bracket_and_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_bracket_and_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m       \u001b[0;34m\"\"\"Bracketing and searching to do for valid inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m       return _bracket_and_search(\n\u001b[0m\u001b[1;32m    269\u001b[0m           \u001b[0mvalue_and_gradients_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mshrinkage_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msufficient_decrease_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py\u001b[0m in \u001b[0;36m_bracket_and_search\u001b[0;34m(value_and_gradients_function, init_interval, f_lim, max_iterations, shrinkage_param, expansion_param, sufficient_decrease_param, curvature_param)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mright\u001b[0m \u001b[0mend\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mbracketing\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \"\"\"\n\u001b[0;32m--> 353\u001b[0;31m   bracket_result = hzl.bracket(value_and_gradients_function, init_interval,\n\u001b[0m\u001b[1;32m    354\u001b[0m                                f_lim, max_iterations, expansion_param)\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/linesearch/internal/hager_zhang_lib.py\u001b[0m in \u001b[0;36mbracket\u001b[0;34m(value_and_gradients_function, search_interval, f_lim, max_iterations, expansion_param)\u001b[0m\n\u001b[1;32m    544\u001b[0m         right=right)]\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m   bracket_result = tf.while_loop(\n\u001b[0m\u001b[1;32m    547\u001b[0m       cond=_loop_cond, body=_loop_body, loop_vars=[initial_args])[0]\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m   \"\"\"\n\u001b[0;32m-> 2507\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2508\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2752\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2753\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2754\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/linesearch/internal/hager_zhang_lib.py\u001b[0m in \u001b[0;36m_loop_body\u001b[0;34m(curr)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# actually a valid left end-point, and we need to expand to guess another\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# right end-point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m     \u001b[0mnew_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_gradients_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpansion_param\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/optimizer/bfgs_utils.py\u001b[0m in \u001b[0;36m_restricted_func\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0mpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mobjective_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_gradients_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     return ValueAndGradient(\n\u001b[1;32m    312\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# To check with what gpu we are training\n",
        "! nvidia-smi\n",
        "# We define our optimizer. We will need to unpack every variable for the optimizer in a list. We will use 5 steps per minimize call.\n",
        "opt = LBFGSOptimizer(loss_train, [*weights, *in_vectors, *out_vectors, *biases], steps = 5)\n",
        "\n",
        "# We iterate for 300 epochs * 5 * 3 steps but we may and should probably break earlier as needed.\n",
        "epochs = 300\n",
        "for i in range(epochs):\n",
        "  \n",
        "  # We just call optimize here. The adapter will handle actually updating our variables. \n",
        "  optim_results = opt.minimize()\n",
        "  \n",
        "  # The rest of the code is to just output actual training score and validation.\n",
        "  # By actual we mean without the regularization part.\n",
        "  loss1 = calc_loss().numpy()\n",
        "  loss2 = calc_loss(out_matrix = valid_matrix).numpy()\n",
        "  print(\"Real training loss:\", loss1)\n",
        "  print(\"Validation loss:\", loss2)\n",
        "\n",
        "  # Once every 50 iterations we will also save the model.\n",
        "  if i % 50 == 0:\n",
        "    save_model(\"train\"+(\"%.2f\" % loss1) + \" valid\"+(\"%.2f\" % loss2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7R33U0DG8Wn"
      },
      "source": [
        "Using this we just calculate the error on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaODyax_PWoa"
      },
      "outputs": [],
      "source": [
        "calc_loss(out_matrix = test_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYcZ4c2VG_Sk"
      },
      "source": [
        "# Outputting our solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vvAX-6JHCJk"
      },
      "source": [
        "We will just predict on the train matrix, get each review into a numpy array and perform a clip on the values as values below 1 or above 5 make no sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUqdNjpARQhN"
      },
      "outputs": [],
      "source": [
        "resulting_matrix = predict(train_matrix)\n",
        "preds = np.array([resulting_matrix[i[1]-1,i[0]-1] for i in output_data])\n",
        "preds = np.array([min(5, max(1,i)) for i in preds])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5hhYLa6HKsw"
      },
      "source": [
        "We now just output our predictions to submit.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAal-vRZRhN9"
      },
      "outputs": [],
      "source": [
        "result = np.array(list(zip(list(range(1,1 + len(preds))),(preds))))\n",
        "data_types_dict = {'Id': int, 'Rating':float}\n",
        "pd.DataFrame(result, columns=['Id', 'Rating']).astype(data_types_dict).to_csv(\"submit.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MdR9O_QD-ifC",
        "huobyBT0-8YT",
        "Oh2Ou8mvCDP0",
        "TcjWLd2ZDdGw",
        "rBxfuBvZDXRY",
        "ZfkrMS9yFc08",
        "oYcZ4c2VG_Sk"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
